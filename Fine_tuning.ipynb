{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNk31ED3XRuDRzBz2JUySox"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Two main types\n",
        "*   *instruction fine-tuning*\n",
        "*   *classification fine-tuning*\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FzAzOJ8JjhO-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing dataset**"
      ],
      "metadata": {
        "id": "T_Tb_dTSkTVf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YogAPuSjIvP",
        "outputId": "445dbf79-44bf-41d8-f3d0-254ba5e62277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\n",
            "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "def download_and_unzip_spam_data(\n",
        " url, zip_path, extracted_path, data_file_path):\n",
        " if data_file_path.exists():\n",
        "  print(f\"{data_file_path} already exists. Skipping download \"\n",
        "  \"and extraction.\"\n",
        "  )\n",
        "  return\n",
        "\n",
        "with urllib.request.urlopen(url) as response: #Download File\n",
        " with open(zip_path, \"wb\") as out_file:\n",
        "  out_file.write(response.read())\n",
        "\n",
        " with zipfile.ZipFile(zip_path, \"r\") as zip_ref: # Unzips the file\n",
        "  zip_ref.extractall(extracted_path)\n",
        "\n",
        " original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        " os.rename(original_file_path, data_file_path)  #Adds a .tsv extension\n",
        " print(f\"File downloaded and saved as {data_file_path}\")\n",
        "\n",
        "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading dataset into pandas dataframe"
      ],
      "metadata": {
        "id": "wKsglqTYmTNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\n",
        " data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"]\n",
        ")\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxcGMznwmF8o",
        "outputId": "1859bea4-bec1-429a-b0e7-bf058fd1a830"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Label                                               Text\n",
            "0      ham  Go until jurong point, crazy.. Available only ...\n",
            "1      ham                      Ok lar... Joking wif u oni...\n",
            "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3      ham  U dun say so early hor... U c already then say...\n",
            "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
            "...    ...                                                ...\n",
            "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
            "5568   ham               Will ü b going to esplanade fr home?\n",
            "5569   ham  Pity, * was in mood for that. So...any other s...\n",
            "5570   ham  The guy did some bitching but I acted like i'd...\n",
            "5571   ham                         Rofl. Its true to its name\n",
            "\n",
            "[5572 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Class Label distribution**"
      ],
      "metadata": {
        "id": "P9fi0Sd2o8Ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCv1yylfmlHg",
        "outputId": "82e2c0ce-b7a2-4084-ff7e-5b388495fad2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a balanced dataset"
      ],
      "metadata": {
        "id": "bnJgD1gCqBMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_balanced_dataset(df):\n",
        " num_spam = df[df[\"Label\"] == \"spam\"].shape[0] # Counts spam instances\n",
        " ham_subset = df[df[\"Label\"] == \"ham\"].sample(\n",
        " num_spam, random_state=123\n",
        " )\n",
        "\n",
        " balanced_df = pd.concat([\n",
        " ham_subset, df[df[\"Label\"] == \"spam\"]\n",
        " ])\n",
        " return balanced_df\n",
        "\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "print(balanced_df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjULGUgkpDCW",
        "outputId": "2c7558e5-83d7-484b-cd18-77abbc847514"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     747\n",
            "spam    747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting string class labels into integer class labels (0 & 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "BmTJmSavqmbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
      ],
      "metadata": {
        "id": "eGUZVGkmqfzc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting dataset into Training, validation and testing"
      ],
      "metadata": {
        "id": "h6c-_IS8rLVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_split(df, train_frac, validation_frac):\n",
        "\n",
        " df = df.sample(\n",
        " frac=1, random_state=123\n",
        " ).reset_index(drop=True) #Shuffles the entire dataframe\n",
        " train_end = int(len(df) * train_frac) #Calculate split indices\n",
        " validation_end = train_end + int(len(df) * validation_frac)\n",
        "\n",
        " #Split dataframe\n",
        " train_df = df[:train_end]\n",
        " validation_df = df[train_end:validation_end]\n",
        " test_df = df[validation_end:]\n",
        " return train_df, validation_df, test_df\n",
        "\n",
        "train_df, validation_df, test_df = random_split(\n",
        " balanced_df, 0.7, 0.1)"
      ],
      "metadata": {
        "id": "c4GsrmbjrEDA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save dataset as csv file"
      ],
      "metadata": {
        "id": "IjLTh3wXr7od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ],
      "metadata": {
        "id": "fkctXKgxr3ny"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Dataloaders**"
      ],
      "metadata": {
        "id": "vNpLzIK0IkQf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pad the shortest message to the length of longest message"
      ],
      "metadata": {
        "id": "hYlXNgQ2Jlpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgrnRdbgJ18-",
        "outputId": "c6157dbf-905c-4daf-8ed0-4ae16bf959ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ],
      "metadata": {
        "id": "IxDeTlEhr-mM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e728499d-cec6-4337-fabe-c13201d070c4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Will use <|endoftext|> for padding"
      ],
      "metadata": {
        "id": "1ku3tkDuJ9ky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define dataset class"
      ],
      "metadata": {
        "id": "X0SRsOLlLQgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "9ygfXRnSNPeU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpamDataset(Dataset):\n",
        " def __init__(self, csv_file, tokenizer, max_length=None,\n",
        " pad_token_id=50256):\n",
        "  self.data = pd.read_csv(csv_file)\n",
        "\n",
        " #Pretokenizes text\n",
        "  self.encoded_texts = [\n",
        "  tokenizer.encode(text) for text in self.data[\"Text\"]\n",
        "  ]\n",
        "\n",
        "  if max_length is None:\n",
        "    self.max_length = self._longest_encoded_length()\n",
        "  else:\n",
        "    self.max_length = max_length\n",
        "\n",
        "  #Truncates sequences if they are longer than max length\n",
        "  self.encoded_texts = [\n",
        "  encoded_text[:self.max_length]\n",
        "  for encoded_text in self.encoded_texts\n",
        "  ]\n",
        "\n",
        "  self.encoded_texts = [\n",
        "    encoded_text + [pad_token_id] *\n",
        "    (self.max_length - len(encoded_text))\n",
        "    for encoded_text in self.encoded_texts\n",
        "    ]\n",
        "\n",
        " def __getitem__(self, index):\n",
        "  encoded = self.encoded_texts[index]\n",
        "  label = self.data.iloc[index][\"Label\"]\n",
        "  return (\n",
        "    torch.tensor(encoded, dtype=torch.long),\n",
        "    torch.tensor(label, dtype=torch.long)\n",
        "    )\n",
        "\n",
        " def __len__(self):\n",
        "  return len(self.data)\n",
        "\n",
        " def _longest_encoded_length(self):\n",
        "  max_length = 0\n",
        "  for encoded_text in self.encoded_texts:\n",
        "    encoded_length = len(encoded_text)\n",
        "    if encoded_length > max_length:\n",
        "      max_length = encoded_length\n",
        "  return max_length"
      ],
      "metadata": {
        "id": "SYhwqooVJy_L"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SpamDataset(\n",
        " csv_file=\"train.csv\",\n",
        " max_length=None,\n",
        " tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "-7bN01h6NXNg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset.max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpYbQMW_QQLm",
        "outputId": "ae741e22-5778-4292-8ade-dced62aca967"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pad the validation and test sets to match the length of the longest train\u0002ing sequence"
      ],
      "metadata": {
        "id": "Nk_tyzFcTlS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = SpamDataset(\n",
        " csv_file=\"validation.csv\",\n",
        " max_length=train_dataset.max_length,\n",
        " tokenizer=tokenizer\n",
        ")\n",
        "test_dataset = SpamDataset(\n",
        " csv_file=\"test.csv\",\n",
        " max_length=train_dataset.max_length,\n",
        " tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "giH5Uj8WR8jP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Dataloader"
      ],
      "metadata": {
        "id": "ZZNTzvwAgND_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "torch.manual_seed(123)\n",
        "train_loader = DataLoader(\n",
        " dataset=train_dataset,\n",
        " batch_size=batch_size,\n",
        " shuffle=True,\n",
        " num_workers=num_workers,\n",
        " drop_last=True,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        " dataset=val_dataset,\n",
        " batch_size=batch_size,\n",
        " num_workers=num_workers,\n",
        " drop_last=False,\n",
        ")\n",
        "test_loader = DataLoader(\n",
        " dataset=test_dataset,\n",
        " batch_size=batch_size,\n",
        " num_workers=num_workers,\n",
        " drop_last=False,\n",
        ")"
      ],
      "metadata": {
        "id": "Q6XdGPz8gL9p"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_batch, target_batch in train_loader:\n",
        " pass\n",
        "print(\"Input batch dimensions:\", input_batch.shape)\n",
        "print(\"Label batch dimensions\", target_batch.shape)"
      ],
      "metadata": {
        "id": "tBd8_HmQTsDM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "879a69e8-31a1-4dde-8065-b643ca0b1cdd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch dimensions: torch.Size([8, 120])\n",
            "Label batch dimensions torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIghieGMgo4u",
        "outputId": "0a7787ac-4a4d-467e-900a-c5e68ca0ec06"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 training batches\n",
            "19 validation batches\n",
            "38 test batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BnZ3GHTBhCDK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}