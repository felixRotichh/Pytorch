{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZazdPikzUYn+BVTTdtR9X"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AW8W8YmeDSBG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention_v2(nn.Module):\n",
        "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        queries = self.W_query(x)\n",
        "        keys = self.W_key(x)\n",
        "        values = self.W_value(x)\n",
        "        attn_scores = queries @ keys.T\n",
        "        attn_weights = torch.softmax(\n",
        "            attn_scores / keys.shape[-1] ** 0.5, dim=-1\n",
        "        )\n",
        "        context_vector = attn_weights @ values\n",
        "        return context_vector"
      ],
      "metadata": {
        "id": "iQhkiCLuDf7i"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {\"Your\": 0, \"journey\": 1, \"starts\": 2, \"with\": 3, \"one\": 4, \"step\": 5}\n",
        "embedding_dim = 3\n",
        "tokenized_input = [\"Your\", \"journey\", \"starts\", \"with\", \"one\", \"step\"]"
      ],
      "metadata": {
        "id": "1WRQQPRFE_iu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random embeddings\n",
        "torch.manual_seed(789)\n",
        "embeddings = torch.randn(len(vocab), embedding_dim)"
      ],
      "metadata": {
        "id": "uzmbWwvsFARP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert tokens to embeddings\n",
        "inputs = torch.stack([embeddings[vocab[word]] for word in tokenized_input])"
      ],
      "metadata": {
        "id": "ZFhkA2YdFD24"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and apply self-attention\n",
        "sa_v2 = SelfAttention_v2(d_in=3,d_out=2)\n",
        "print(sa_v2(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW1VvGDjFGj5",
        "outputId": "6561c400-724c-4ce3-ad60-948d8552545a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0427,  0.0316],\n",
            "        [-0.0348,  0.0876],\n",
            "        [-0.0490, -0.0365],\n",
            "        [-0.0355,  0.1067],\n",
            "        [-0.0369,  0.1218],\n",
            "        [-0.0342,  0.0994]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N_YCtfBDFS1S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}