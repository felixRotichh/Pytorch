{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPeVBJRFrlBcFSkWzboorHN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AW8W8YmeDSBG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention_v2(nn.Module):\n",
        "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        queries = self.W_query(x)\n",
        "        keys = self.W_key(x)\n",
        "        values = self.W_value(x)\n",
        "        attn_scores = queries @ keys.T\n",
        "        attn_weights = torch.softmax(\n",
        "            attn_scores / keys.shape[-1] ** 0.5, dim=-1\n",
        "        )\n",
        "        context_vector = attn_weights @ values\n",
        "        return context_vector"
      ],
      "metadata": {
        "id": "iQhkiCLuDf7i"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {\"Your\": 0, \"journey\": 1, \"starts\": 2, \"with\": 3, \"one\": 4, \"step\": 5}\n",
        "embedding_dim = 3\n",
        "tokenized_input = [\"Your\", \"journey\", \"starts\", \"with\", \"one\", \"step\"]"
      ],
      "metadata": {
        "id": "1WRQQPRFE_iu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random embeddings\n",
        "torch.manual_seed(789)\n",
        "embeddings = torch.randn(len(vocab), embedding_dim)"
      ],
      "metadata": {
        "id": "uzmbWwvsFARP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert tokens to embeddings\n",
        "inputs = torch.stack([embeddings[vocab[word]] for word in tokenized_input])"
      ],
      "metadata": {
        "id": "ZFhkA2YdFD24"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and apply self-attention\n",
        "sa_v2 = SelfAttention_v2(d_in=3,d_out=2)\n",
        "print(sa_v2(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW1VvGDjFGj5",
        "outputId": "6561c400-724c-4ce3-ad60-948d8552545a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0427,  0.0316],\n",
            "        [-0.0348,  0.0876],\n",
            "        [-0.0490, -0.0365],\n",
            "        [-0.0355,  0.1067],\n",
            "        [-0.0369,  0.1218],\n",
            "        [-0.0342,  0.0994]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying causal attention\n",
        "queries = sa_v2.W_query(inputs)\n",
        "keys = sa_v2.W_key(inputs)\n",
        "attn_scores = queries @ keys.T\n",
        "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_YCtfBDFS1S",
        "outputId": "c49f7c01-9efb-45ea-ddfc-4524c1aacf59"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1670, 0.1690, 0.1660, 0.1656, 0.1644, 0.1679],\n",
            "        [0.1379, 0.1451, 0.1693, 0.2051, 0.1718, 0.1708],\n",
            "        [0.2051, 0.1875, 0.1616, 0.1281, 0.1620, 0.1557],\n",
            "        [0.1309, 0.1469, 0.1672, 0.2135, 0.1641, 0.1773],\n",
            "        [0.1259, 0.1504, 0.1648, 0.2189, 0.1561, 0.1840],\n",
            "        [0.1330, 0.1433, 0.1688, 0.2121, 0.1699, 0.1729]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a mask where values above diagonals are zero\n",
        "context_length = attn_scores.shape[0]\n",
        "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
        "print(mask_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lzi3hhQJQaF",
        "outputId": "60f47579-20e5-425c-e451-b0cc2c166e77"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Zero out attention weights above diagonals\n",
        "masked_simple = attn_weights*mask_simple\n",
        "print(masked_simple)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZHC-T66JnD7",
        "outputId": "3a7dbf5d-86b6-4d5a-994a-bb35141f0ca0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1670, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1379, 0.1451, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2051, 0.1875, 0.1616, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1309, 0.1469, 0.1672, 0.2135, 0.0000, 0.0000],\n",
            "        [0.1259, 0.1504, 0.1648, 0.2189, 0.1561, 0.0000],\n",
            "        [0.1330, 0.1433, 0.1688, 0.2121, 0.1699, 0.1729]],\n",
            "       grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#renormalize attn weight\n",
        "row_sums = masked_simple.sum(dim=-1, keepdim=True)\n",
        "masked_simple_norm = masked_simple / row_sums\n",
        "print(masked_simple_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POqCJS0tKAhh",
        "outputId": "905fc0c5-115a-4e64-edda-bd4e8cfd3fa2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.4873, 0.5127, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3701, 0.3384, 0.2915, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1988, 0.2231, 0.2539, 0.3242, 0.0000, 0.0000],\n",
            "        [0.1543, 0.1843, 0.2020, 0.2682, 0.1913, 0.0000],\n",
            "        [0.1330, 0.1433, 0.1688, 0.2121, 0.1699, 0.1729]],\n",
            "       grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using infinity trick to implement more efficient masking"
      ],
      "metadata": {
        "id": "GzkhbBpdLu3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#applying softmax\n",
        "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
        "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
        "print(masked)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlQ7zWkxKo4x",
        "outputId": "4bc8f1d7-7efa-4aee-d9bf-85a52268f27a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0025,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
            "        [-0.2798, -0.2078,    -inf,    -inf,    -inf,    -inf],\n",
            "        [ 0.3394,  0.2129,  0.0021,    -inf,    -inf,    -inf],\n",
            "        [-0.3581, -0.1953, -0.0126,  0.3334,    -inf,    -inf],\n",
            "        [-0.4171, -0.1660, -0.0364,  0.3649, -0.1134,    -inf],\n",
            "        [-0.3330, -0.2270,  0.0043,  0.3274,  0.0140,  0.0385]],\n",
            "       grad_fn=<MaskedFillBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59DU3ve-LpnB",
        "outputId": "d9f0c803-4247-4d38-9a9e-ba0f1d243a67"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.4873, 0.5127, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3701, 0.3384, 0.2915, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1988, 0.2231, 0.2539, 0.3242, 0.0000, 0.0000],\n",
            "        [0.1543, 0.1843, 0.2020, 0.2682, 0.1913, 0.0000],\n",
            "        [0.1330, 0.1433, 0.1688, 0.2121, 0.1699, 0.1729]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wQvqW7RgMEXH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}