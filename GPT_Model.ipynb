{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOtHqZvRwGsXtpVtwQ275/j"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyLEgAZs3-Be",
        "outputId": "1abdfb1e-dccf-4a96-a5ba-832c12810013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tp8rop76re4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        " \"vocab_size\": 50257, # Vocabulary size\n",
        " \"context_length\": 1024, # Context length\n",
        " \"emb_dim\": 768, # Embedding dimension\n",
        " \"n_heads\": 12, # Number of attention heads\n",
        " \"n_layers\": 12, # Number of layers\n",
        " \"drop_rate\": 0.1, # Dropout rate\n",
        " \"qkv_bias\": False # Query-Key-Value bias\n",
        "}"
      ],
      "metadata": {
        "id": "D_5syb9L-g7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length,\n",
        "                 dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads) == 0, \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.tril(torch.ones(context_length, context_length)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        keys = keys.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "\n",
        "        attn_scores = queries @ keys.transpose(2,3)\n",
        "\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "        attn_scores.masked_fill_(~mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(\n",
        "                attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = (attn_weights @ values).transpose(1,2)\n",
        "        context_vec = context_vec.contiguous().view(\n",
        "                b, num_tokens, self.d_out\n",
        "            )\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "        return context_vec\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        " def __init__(self, emb_dim):\n",
        "  super().__init__()\n",
        "  self.eps = 1e-6\n",
        "  self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "  self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        " def forward(self, x):\n",
        "  mean = x.mean(dim=-1, keepdim=True)\n",
        "  var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "  norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "  return self.scale * norm_x + self.shift\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "    nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "    nn.GELU(),\n",
        "    nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.att = MultiHeadAttention(\n",
        "    d_in=cfg[\"emb_dim\"],\n",
        "    d_out=cfg[\"emb_dim\"],\n",
        "    context_length=cfg[\"context_length\"],\n",
        "    num_heads=cfg[\"n_heads\"],\n",
        "    dropout=cfg[\"drop_rate\"],\n",
        "    qkv_bias=cfg[\"qkv_bias\"])\n",
        "    self.ff = FeedForward(cfg)\n",
        "    self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "  def forward(self, x):\n",
        "    shortcut = x\n",
        "    x = self.norm1(x)\n",
        "    x = self.att(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "    shortcut = x\n",
        "    x = self.norm2(x)\n",
        "    x = self.ff(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "    return x\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        " def __init__(self, cfg):\n",
        "  super().__init__()\n",
        "  self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "  self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "  self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "  self.trf_blocks = nn.Sequential(\n",
        "  *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "  self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "  self.out_head = nn.Linear(\n",
        "  cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "  )\n",
        " def forward(self, in_idx):\n",
        "  batch_size, seq_len = in_idx.shape\n",
        "  tok_embeds = self.tok_emb(in_idx)\n",
        "\n",
        "  pos_embeds = self.pos_emb(\n",
        "  torch.arange(seq_len, device=in_idx.device)\n",
        "  )\n",
        "  x = tok_embeds + pos_embeds\n",
        "  x = self.drop_emb(x)\n",
        "  x = self.trf_blocks(x)\n",
        "  x = self.final_norm(x)\n",
        "  logits = self.out_head(x)\n",
        "  return logits"
      ],
      "metadata": {
        "id": "OKWY9VWZ-Kx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "batch = torch.randint(0, GPT_CONFIG_124M[\"vocab_size\"], (2, GPT_CONFIG_124M[\"context_length\"]))\n",
        "out = model(batch)\n",
        "print(\"Input batch:\\n\", batch)\n",
        "print(\"\\nOutput shape:\", out.shape)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_dX18cq-TG1",
        "outputId": "5e5e0da6-3904-4fba-c977-3fd0437db29e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch:\n",
            " tensor([[29218, 30885,  7000,  ..., 12182, 45152, 35663],\n",
            "        [10835, 16857, 35218,  ..., 44337, 10291, 31534]])\n",
            "\n",
            "Output shape: torch.Size([2, 1024, 50257])\n",
            "tensor([[[-3.5903e-01, -2.0192e-01,  2.0841e-01,  ...,  4.4752e-01,\n",
            "          -8.1040e-01,  2.3472e-01],\n",
            "         [ 2.9102e-02, -2.5164e-01,  8.9435e-01,  ...,  6.1827e-01,\n",
            "           3.3258e-01, -1.3072e-01],\n",
            "         [ 6.7724e-01, -3.6021e-03,  1.0919e+00,  ...,  6.1255e-01,\n",
            "          -5.0170e-01,  1.3974e+00],\n",
            "         ...,\n",
            "         [-1.0816e-01,  9.3304e-01, -3.5024e-01,  ..., -3.1605e-01,\n",
            "          -7.5377e-01,  4.9886e-01],\n",
            "         [-3.6676e-01, -5.6777e-01, -1.4125e-01,  ...,  8.9984e-02,\n",
            "           8.8732e-02, -5.7068e-01],\n",
            "         [-4.3469e-01,  9.3574e-02, -2.1258e-01,  ..., -4.2584e-01,\n",
            "           5.6166e-01, -5.3010e-01]],\n",
            "\n",
            "        [[-3.7225e-01,  3.2211e-01,  1.2770e-01,  ...,  1.7645e-02,\n",
            "          -1.1180e+00,  1.6322e-01],\n",
            "         [ 8.9064e-01,  7.1649e-01,  7.2707e-01,  ..., -3.3893e-01,\n",
            "           3.7027e-01, -6.1465e-01],\n",
            "         [ 6.7443e-02, -2.2644e-02,  8.1566e-01,  ...,  6.4976e-01,\n",
            "           3.9117e-01,  4.5330e-01],\n",
            "         ...,\n",
            "         [-1.3465e-01,  8.4859e-01, -2.1185e-01,  ..., -7.8543e-01,\n",
            "          -4.1090e-01,  2.0432e-02],\n",
            "         [-8.0332e-01,  2.2928e-02, -2.6810e-01,  ..., -2.1109e-02,\n",
            "           1.7727e-01,  7.8461e-02],\n",
            "         [-6.2821e-01, -3.7356e-01,  2.9748e-02,  ..., -5.4398e-04,\n",
            "           1.2452e+00, -7.4273e-02]]], grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters: {total_params:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG5OZmArEha5",
        "outputId": "c98c4ab6-7df4-44cf-e1aa-67ff34e4a820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 163,018,752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
        "print(\"Output layer shape:\", model.out_head.weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIiQpP7swD7J",
        "outputId": "3d8450ca-fa0a-47fe-ff95-9405f72a082d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token embedding layer shape: torch.Size([50257, 768])\n",
            "Output layer shape: torch.Size([50257, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Weight tying reduces the overall memory footprint and computational complexity\n",
        "of the model**"
      ],
      "metadata": {
        "id": "Icrq3hn5yMG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_params_gpt2 = (\n",
        " total_params - sum(p.numel()\n",
        " for p in model.out_head.parameters())\n",
        ")\n",
        "print(f\"Number of trainable parameters \"\n",
        " f\"considering weight tying: {total_params_gpt2:,}\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRKPB9HExpUA",
        "outputId": "24e08262-5fb9-4a31-9159-a2c146e79249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters considering weight tying: 124,421,376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory requirements of the 163 million parameters in our GPTModel object\n",
        "\n",
        "total_size_bytes = total_params * 4\n",
        "total_size_mb = total_size_bytes / (1024 * 1024)\n",
        "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du1TTVHOx00L",
        "outputId": "fbc053e5-753b-44d7-bfaf-9ab9e5dc33d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total size of the model: 621.87 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generating Texts**"
      ],
      "metadata": {
        "id": "l2XEg2HJ2o5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_simple(model, idx,\n",
        "  max_new_tokens, context_size):\n",
        "  for _ in range(max_new_tokens):\n",
        "    idx_cond = idx[:, -context_size:]\n",
        "    with torch.no_grad():\n",
        "      logits = model(idx_cond)\n",
        "\n",
        "    logits = logits[:, -1, :]\n",
        "    probas = torch.softmax(logits, dim=-1)\n",
        "    idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "    idx = torch.cat((idx, idx_next), dim=1)\n",
        "    return idx"
      ],
      "metadata": {
        "id": "PgdFoEIxyhxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "start_context = \"Hello, I am\"\n",
        "encoded = tokenizer.encode(start_context)\n",
        "print(\"encoded:\", encoded)\n",
        "\n",
        "encoded_tensor = torch.tensor(encoded).unsqueeze(0) #Add batch dimension\n",
        "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQwQqxrt2xSY",
        "outputId": "04c47bfd-4f27-4298-d244-12a8362ef0a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoded: [15496, 11, 314, 716]\n",
            "encoded_tensor.shape: torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Put the model into .eval() mode. This disables random components like\n",
        "dropout, which are only used during training**"
      ],
      "metadata": {
        "id": "rdRGexi44x8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "out = generate_text_simple(\n",
        " model=model,\n",
        " idx=encoded_tensor,\n",
        " max_new_tokens=6,\n",
        " context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "print(\"Output:\", out)\n",
        "print(\"Output length:\", len(out[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPc3Yc1b4MbT",
        "outputId": "2d0901ba-1898-431f-8a96-b391b3dc10ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: tensor([[15496,    11,   314,   716, 13411]])\n",
            "Output length: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using the .decode method of the tokenizer, we can convert the IDs back into text**"
      ],
      "metadata": {
        "id": "qW7vAUma5Lvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
        "print(decoded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9_SfNTk5ETc",
        "outputId": "45d7ab2a-3613-4e1f-dcbb-cb8aa3456999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, I amobi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using GPT to generate text"
      ],
      "metadata": {
        "id": "RcbclCD77Qvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        " \"vocab_size\": 50257,\n",
        " \"context_length\": 256, #Reduced Context length to 256\n",
        " \"emb_dim\": 768,\n",
        " \"n_heads\": 12,\n",
        " \"n_layers\": 12,\n",
        " \"drop_rate\": 0.1,\n",
        " \"qkv_bias\": False\n",
        "}\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxKART6-5RI_",
        "outputId": "a67198f7-ac24-4bd5-ea18-443d64c06c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Utility functions for text to token ids conversion**"
      ],
      "metadata": {
        "id": "gGtqrPc0PO6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_token_ids(text, tokenizer):\n",
        " encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        " encoded_tensor = torch.tensor(encoded).unsqueeze(0) #.unsqueeze(0) adds batch dimension\n",
        " return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        " flat = token_ids.squeeze(0) #removes batch dimension\n",
        " return tokenizer.decode(flat.tolist())"
      ],
      "metadata": {
        "id": "CgIZJEEN7jqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_context = \"Every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        " model=model,\n",
        " idx=text_to_token_ids(start_context, tokenizer),\n",
        " max_new_tokens=10,\n",
        " context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")"
      ],
      "metadata": {
        "id": "NChGX4wQNwq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQANOU6OOUNo",
        "outputId": "008e2a50-58bc-4611-f225-56ed8d797fe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves youLee\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Evaluation"
      ],
      "metadata": {
        "id": "qlqeMPaqWiWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inputs have been mapped to token IDs\n",
        "inputs = torch.tensor([[16833, 3626, 6100], # [\"every effort moves\",\n",
        "                          [40, 1107, 588]]) # \"I really like\"]"
      ],
      "metadata": {
        "id": "qxxHpRYfOgjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Targets contain Token IDs we want the model to produce\n",
        "targets = torch.tensor([[3626, 6100, 345 ], # [\" effort moves you\",\n",
        " [1107, 588, 11311]]) # \" really like chocolate\"]"
      ],
      "metadata": {
        "id": "elmObceaJjy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feed the inputs into model to calculate logits vectors for the inputs\n",
        "**"
      ],
      "metadata": {
        "id": "Yi6BBpddOlcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        " logits = model(inputs)\n",
        "probas = torch.softmax(logits, dim=-1)  #Probability of each token in the vocabulary\n",
        "print(probas.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myk9PF4DKb_Y",
        "outputId": "99c908fa-813c-4fa0-8a0f-bf9099d9b3da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 50257])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Applying argmax function to the probability scores to get token IDs**"
      ],
      "metadata": {
        "id": "rQ8GBKorLeZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "print(\"Token IDs:\\n\", token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It5hS3wFK1_M",
        "outputId": "d94a403c-18f3-44e5-d5dd-852d5817fbb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[[13195],\n",
            "         [41034],\n",
            "         [ 8429]],\n",
            "\n",
            "        [[19385],\n",
            "         [40202],\n",
            "         [23677]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Convert token IDs back into text. The model produces random text that is different from the target text because it has\n",
        "not been trained yet**\n",
        "\n"
      ],
      "metadata": {
        "id": "xRpc22mTL2lK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
        "print(f\"Outputs batch 1:\"\n",
        " f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZQbfDihLsDh",
        "outputId": "91a68f7e-e544-4477-8e49-d2b5151e2836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Targets batch 1:  effort moves you\n",
            "Outputs batch 1: War probing sword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**initial softmax probability scores cor\u0002responding to the target tokens**"
      ],
      "metadata": {
        "id": "lPV_9EM0N7CV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_idx = 0\n",
        "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 1:\", target_probas_1)\n",
        "\n",
        "text_idx = 1\n",
        "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 2:\", target_probas_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GycObu7-MEsc",
        "outputId": "5780474e-4962-4d2a-9a0e-29e960f9405d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1: tensor([1.4403e-05, 1.6720e-05, 8.6229e-06])\n",
            "Text 2: tensor([1.2030e-05, 4.5597e-05, 6.2099e-05])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**calculate the loss for the probability scores of the two example batches. We apply logarithm to the probability scores**"
      ],
      "metadata": {
        "id": "Oh1jMz67Pm7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
        "print(log_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw3_Q2e9N5UO",
        "outputId": "78e3cbec-6502-4d70-f2cc-063ef34fdfe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-11.1481, -10.9989, -11.6611, -11.3281,  -9.9957,  -9.6868])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combine these log probabilities into a single score by computing the aver\u0002age**"
      ],
      "metadata": {
        "id": "o-eajB7FQX5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_log_probas = torch.mean(log_probas)\n",
        "print(avg_log_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5LhXhVcP3wN",
        "outputId": "815ad7bb-a396-437f-8738-1bcc544d9b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-10.8031)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating the average negative log probability**"
      ],
      "metadata": {
        "id": "IdUOeJjdQ4r9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neg_avg_log_probas = avg_log_probas * -1\n",
        "print(neg_avg_log_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFZTtPgDQgFU",
        "outputId": "06735aa1-e3e5-4da2-f3d0-ef4117b2dd7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.8031)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The term for turning -10.8031 to 10.8031 is called cross entropy loss"
      ],
      "metadata": {
        "id": "lKgSfca4R-NV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Logits shape:\", logits.shape)\n",
        "print(\"Targets shape:\", targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMKuDcH4R84d",
        "outputId": "d0abed13-4ac6-42d7-8c66-0e4938db9342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape: torch.Size([2, 3, 50257])\n",
            "Targets shape: torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the cross_entropy loss function in PyTorch, we want to flatten these tensors\n",
        "by combining them over the batch dimension"
      ],
      "metadata": {
        "id": "1hHwzdbpTRnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits_flat = logits.flatten(0, 1)\n",
        "targets_flat = targets.flatten()\n",
        "print(\"Flattened logits:\", logits_flat.shape)\n",
        "print(\"Flattened targets:\", targets_flat.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj-DOEGMS1Fp",
        "outputId": "4bea5534-be61-436d-a765-0e2de7d728e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flattened logits: torch.Size([6, 50257])\n",
            "Flattened targets: torch.Size([6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using PyTorch's cross entropy function to calculate loss**"
      ],
      "metadata": {
        "id": "9zvdPzVsTxW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN6nJpnNTPyj",
        "outputId": "43943444-be54-44c8-b34e-ca3b887cec38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.8031)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating Perplexity"
      ],
      "metadata": {
        "id": "4vsKYLR8VIPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity = torch.exp(loss)\n",
        "print(perplexity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mNQP5ywTv0H",
        "outputId": "9afe28b7-5cd4-442e-e436-eed5c064adc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(49173.1719)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perplexity can provide a more interpre\u0002table way to understand the uncertainty of a model in predicting the next token in a\n",
        "sequence**"
      ],
      "metadata": {
        "id": "ShyyMuZKVTeG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating the training and validation set losses"
      ],
      "metadata": {
        "id": "wbfOMv2BWJrb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train on \"The Verdict\" short story"
      ],
      "metadata": {
        "id": "ef-hfnkBdLu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
        " \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
        " \"the-verdict.txt\")\n",
        "file_path = \"the-verdict.txt\"\n",
        "urllib.request.urlretrieve(url, file_path)"
      ],
      "metadata": {
        "id": "AKyVSLyZVMcN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da342f8f-7ac2-4e63-f9c3-2ae1cd599db3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('the-verdict.txt', <http.client.HTTPMessage at 0x7d19ec77a4d0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"the-verdict.txt\"\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        " text_data = file.read()"
      ],
      "metadata": {
        "id": "Fu3wnVKHdyJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check number of characters and tokens in the dataset"
      ],
      "metadata": {
        "id": "dMUmamCyeqil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_characters = len(text_data)\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "print(\"Characters:\", total_characters)\n",
        "print(\"Tokens:\", total_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAToJQIpelIE",
        "outputId": "5da9f09b-50de-404e-806d-e3165f3bf07b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Characters: 20479\n",
            "Tokens: 5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dividing dataset into a training and a validation set**"
      ],
      "metadata": {
        "id": "WGk4wrnqfkdg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataloader"
      ],
      "metadata": {
        "id": "Z9YxzUUmg2UM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "1zpn9gP1hgLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        token_ids = tokenizer.encode(txt) #tokenizes the entire text\n",
        "\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i+max_length]\n",
        "            target_chunk = token_ids[i+1:i+max_length+1]\n",
        "\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "     #Returns total number of rows in the dataset\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    #Returns a single row from the dataset\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "    #Dataloader to generate batches with input pairs\n",
        "    def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128,\n",
        "                             shuffle=True, drop_last=True, num_workers=0):\n",
        "        tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "        dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "        dataloader = DataLoader(\n",
        "            dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=shuffle,\n",
        "            drop_last=drop_last,\n",
        "            num_workers=num_workers\n",
        "        )\n",
        "\n",
        "\n",
        "        return dataloader"
      ],
      "metadata": {
        "id": "fnfCkgnag1sO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a train_ratio"
      ],
      "metadata": {
        "id": "H3b7eXwNf2iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]"
      ],
      "metadata": {
        "id": "CZ_8xm_oe0bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating dataloaders for train_data and val_data"
      ],
      "metadata": {
        "id": "9K8cTuYpiEWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = GPTDatasetV1.create_dataloader_v1(\n",
        " train_data,\n",
        " batch_size=2,\n",
        " max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        " stride=GPT_CONFIG_124M[\"context_length\"],\n",
        " drop_last=True,\n",
        " shuffle=True,\n",
        " num_workers=0\n",
        ")\n",
        "val_loader = GPTDatasetV1.create_dataloader_v1(\n",
        " val_data,\n",
        " batch_size=2,\n",
        " max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        " stride=GPT_CONFIG_124M[\"context_length\"],\n",
        " drop_last=False,\n",
        " shuffle=False,\n",
        " num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "UypJpdu_gDxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if dataloaders were created"
      ],
      "metadata": {
        "id": "fluJNds2mFQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader:\")\n",
        "for x, y in train_loader:\n",
        " print(x.shape, y.shape)\n",
        "\n",
        "print(\"\\nValidation loader:\")\n",
        "for x, y in val_loader:\n",
        " print(x.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OBHKi7ok8mY",
        "outputId": "06a13044-51c4-4910-f1fb-41e88e88957e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            "Validation loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement utility function to calculate cross entropy loss of a given batch"
      ],
      "metadata": {
        "id": "dsS8mYkWiYL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        " input_batch = input_batch.to(device)\n",
        " target_batch = target_batch.to(device)\n",
        " logits = model(input_batch)\n",
        " loss = torch.nn.functional.cross_entropy(\n",
        " logits.flatten(0, 1), target_batch.flatten()\n",
        " )\n",
        " return loss"
      ],
      "metadata": {
        "id": "etYoTe6EmJpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to compute training and validation loss**"
      ],
      "metadata": {
        "id": "v7NI94KQiqIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        " total_loss = 0.\n",
        " if len(data_loader) == 0:\n",
        "  return float(\"nan\")\n",
        " elif num_batches is None:\n",
        "  num_batches = len(data_loader)\n",
        " else:\n",
        "  num_batches = min(num_batches, len(data_loader))\n",
        " for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "  if i < num_batches:\n",
        "    loss = calc_loss_batch(\n",
        "      input_batch, target_batch, model, device\n",
        "    )\n",
        "    total_loss += loss.item() # Sums loss for each batch\n",
        "  else:\n",
        "    break\n",
        " return total_loss / num_batches  #Avgs loss over all the batches"
      ],
      "metadata": {
        "id": "9J6Ws5iAik4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "with torch.no_grad():\n",
        " train_loss = calc_loss_loader(train_loader, model, device)\n",
        " val_loss = calc_loss_loader(val_loader, model, device)\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdAI6QwHjcTJ",
        "outputId": "b0653f4e-dcce-4901-848d-d6058b41a680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 11.002762158711752\n",
            "Validation loss: 11.052907943725586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training an LLM"
      ],
      "metadata": {
        "id": "OlhlHZPWk9LO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing LLM training flow"
      ],
      "metadata": {
        "id": "X4EJNFJUmgkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        " model.eval()\n",
        " with torch.no_grad():\n",
        "  train_loss = calc_loss_loader(\n",
        "    train_loader, model, device, num_batches=eval_iter\n",
        "    )\n",
        "  val_loss = calc_loss_loader(\n",
        "    val_loader, model, device, num_batches=eval_iter\n",
        "  )\n",
        " model.train()\n",
        " return train_loss, val_loss"
      ],
      "metadata": {
        "id": "jG_J8Ij6oYZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        " model.eval()\n",
        " context_size = model.pos_emb.weight.shape[0]\n",
        " encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        " with torch.no_grad():\n",
        "  token_ids = generate_text_simple(\n",
        "  model=model, idx=encoded,\n",
        "  max_new_tokens=50, context_size=context_size\n",
        "  )\n",
        " decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        " print(decoded_text.replace(\"\\n\", \" \"))\n",
        " model.train()"
      ],
      "metadata": {
        "id": "i50CYcfdo6fB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_simple(model, train_loader, val_loader,\n",
        " optimizer, device, num_epochs,\n",
        " eval_freq, eval_iter, start_context, tokenizer):\n",
        " train_losses, val_losses, track_tokens_seen = [], [], []\n",
        " tokens_seen, global_step = 0, -1\n",
        " for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  for input_batch, target_batch in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    loss = calc_loss_batch(\n",
        "      input_batch, target_batch, model, device\n",
        "      )\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    tokens_seen += input_batch.numel()\n",
        "    global_step += 1\n",
        "    if global_step % eval_freq == 0:\n",
        "      train_loss, val_loss = evaluate_model(\n",
        "        model, train_loader, val_loader, device, eval_iter)\n",
        "      train_losses.append(train_loss)\n",
        "      val_losses.append(val_loss)\n",
        "      track_tokens_seen.append(tokens_seen)\n",
        "      print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "      f\"Train loss {train_loss:.3f}, \"\n",
        "      f\"Val loss {val_loss:.3f}\"\n",
        "      )\n",
        "  generate_and_print_sample(\n",
        "    model, tokenizer, device, start_context\n",
        "  )\n",
        " return train_losses, val_losses, track_tokens_seen"
      ],
      "metadata": {
        "id": "hcLa5AD1kdgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(\n",
        " model.parameters(),\n",
        " lr=0.0004, weight_decay=0.1\n",
        ")\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        " model, train_loader, val_loader, optimizer, device,\n",
        " num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        " start_context=\"Every effort moves you, \", tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laOQ8VhDo_fO",
        "outputId": "df0b160a-2cd9-46d1-bcc9-4233cce89a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 10.035, Val loss 10.108\n",
            "Ep 1 (Step 000005): Train loss 7.988, Val loss 8.256\n",
            "Every effort moves you, ,\n",
            "Ep 2 (Step 000010): Train loss 6.758, Val loss 7.015\n",
            "Ep 2 (Step 000015): Train loss 6.000, Val loss 6.565\n",
            "Every effort moves you, ,\n",
            "Ep 3 (Step 000020): Train loss 5.519, Val loss 6.466\n",
            "Ep 3 (Step 000025): Train loss 5.481, Val loss 6.499\n",
            "Every effort moves you,  \n",
            "Ep 4 (Step 000030): Train loss 4.951, Val loss 6.277\n",
            "Ep 4 (Step 000035): Train loss 4.631, Val loss 6.599\n",
            "Every effort moves you, is\n",
            "Ep 5 (Step 000040): Train loss 4.308, Val loss 6.366\n",
            "Every effort moves you,  the\n",
            "Ep 6 (Step 000045): Train loss 3.967, Val loss 6.191\n",
            "Ep 6 (Step 000050): Train loss 3.439, Val loss 6.238\n",
            "Every effort moves you,  was\n",
            "Ep 7 (Step 000055): Train loss 2.639, Val loss 6.191\n",
            "Ep 7 (Step 000060): Train loss 2.322, Val loss 6.248\n",
            "Every effort moves you,  through\n",
            "Ep 8 (Step 000065): Train loss 1.875, Val loss 6.218\n",
            "Ep 8 (Step 000070): Train loss 1.531, Val loss 6.180\n",
            "Every effort moves you,  through\n",
            "Ep 9 (Step 000075): Train loss 1.270, Val loss 6.300\n",
            "Ep 9 (Step 000080): Train loss 1.006, Val loss 6.300\n",
            "Every effort moves you,  through\n",
            "Ep 10 (Step 000085): Train loss 0.749, Val loss 6.324\n",
            "Every effort moves you,  through\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot to show training and validation losses"
      ],
      "metadata": {
        "id": "sU62bhh6lE0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator"
      ],
      "metadata": {
        "id": "p4hMpp-An0Bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis for tokens seen\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for alignment\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "xi2NLfJRpNOs",
        "outputId": "e200a4f5-8987-459d-cba4-b643419b66ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWABJREFUeJzt3Xd4FFXbwOHfbuqm90YKAQKBEGoAQwQLkSIiRcTCqyB2QEQUERVELKgg8qq8qPgJNgQbiEgLiNQAoSSAhF4SShJaKiQku+f7Y2DDSpFAwm7Cc1/XXNmdOTPz7CHk2TnnzBmdUkohhBBCCJukt3YAQgghhLg8SdRCCCGEDZNELYQQQtgwSdRCCCGEDZNELYQQQtgwSdRCCCGEDZNELYQQQtgwSdRCCCGEDZNELYQQQtgwSdRC1AAHDhxAp9ORmppq7VCEEJVMErUQNkKn011xGTNmjLVDFEJYgb21AxBCaI4ePWp+PWvWLEaPHs3OnTvN69zc3KwRlhDCyuSKWggbERQUZF48PT3R6XTm9wEBAUycOJHQ0FCcnJxo1qwZCxcuvOyxjEYjAwYMIDo6moyMDAB+++03WrRogbOzM3Xq1OHNN9+krKzMvI9Op+PLL7+kZ8+euLi4EBUVxdy5c83bT506Rd++ffH398dgMBAVFcW0adMuG8PPP/9MbGwsBoMBX19fEhMTKSoqMm//8ssvadiwIc7OzkRHR/O///3PYv/MzEz69OmDl5cXPj4+dO/enQMHDpi39+/fnx49ejBhwgSCg4Px9fVl0KBBlJaWXnWdC1EtKCGEzZk2bZry9PQ0v584caLy8PBQP/zwg9qxY4d6+eWXlYODg9q1a5dSSqn9+/crQG3evFkVFxernj17qubNm6ucnByllFIrVqxQHh4eavr06Wrv3r1q8eLFqnbt2mrMmDHmcwAqNDRUzZgxQ+3evVsNGTJEubm5qRMnTiillBo0aJBq1qyZSklJUfv371dJSUlq7ty5l4z/yJEjyt7eXk2cOFHt379fbdmyRU2ePFkVFBQopZT67rvvVHBwsPrll1/Uvn371C+//KJ8fHzU9OnTlVJKnT17VjVs2FANGDBAbdmyRW3fvl09/PDDqkGDBqqkpEQppVS/fv2Uh4eHeuaZZ1R6err6/ffflYuLi/riiy8q9x9DCCuTRC2EDfpnog4JCVHvvPOORZlWrVqpgQMHKqXKE/XKlStVhw4d1K233qpyc3PNZTt06KDeffddi/2//fZbFRwcbH4PqNdff938vrCwUAFqwYIFSimlunXrph577LGrin/jxo0KUAcOHLjk9rp166oZM2ZYrHvrrbdUfHy8ObYGDRook8lk3l5SUqIMBoNatGiRUkpL1BEREaqsrMxc5v7771cPPPDAVcUoRHUhfdRC2Lj8/HyOHDlCQkKCxfqEhATS0tIs1j300EOEhoby559/YjAYzOvT0tJYvXo177zzjnmd0WikuLiY06dP4+LiAkCTJk3M211dXfHw8CAnJweAZ599lvvuu49NmzbRsWNHevToQdu2bS8Zc9OmTenQoQOxsbF06tSJjh070rt3b7y9vSkqKmLv3r08/vjjPPnkk+Z9ysrK8PT0NMe7Z88e3N3dLY5bXFzM3r17ze9jYmKws7Mzvw8ODmbr1q1XqE0hqh9J1ELUIHfffTffffcdycnJ3Hnnneb1hYWFvPnmm/Tq1euifZydnc2vHRwcLLbpdDpMJhMAXbp04eDBg8yfP5+kpCQ6dOjAoEGDmDBhwkXHtLOzIykpiTVr1rB48WI++eQTXnvtNdatW2f+UjB16lTatGlz0X7n423ZsiXff//9Rcf29/e/qniFqCkkUQth4zw8PAgJCWH16tXcdttt5vWrV6+mdevWFmWfffZZGjduzL333ssff/xhLt+iRQt27txJvXr1risWf39/+vXrR79+/WjXrh3Dhw+/ZKIGLWkmJCSQkJDA6NGjiYiIYPbs2QwbNoyQkBD27dtH3759L7lvixYtmDVrFgEBAXh4eFxXzEJUd5KohagGhg8fzhtvvEHdunVp1qwZ06ZNIzU19ZJXnM899xxGo5F77rmHBQsWcOuttzJ69GjuuecewsPD6d27N3q9nrS0NLZt28bbb799VTGMHj2ali1bEhMTQ0lJCfPmzaNhw4aXLLtu3TqWLl1Kx44dCQgIYN26dRw7dsxc/s0332TIkCF4enrSuXNnSkpK2LBhA6dOnWLYsGH07duX8ePH0717d8aOHUtoaCgHDx7k119/5eWXXyY0NPTaK1OIakYStRDVwJAhQ8jLy+PFF18kJyeHRo0aMXfuXKKioi5ZfujQoZhMJu6++24WLlxIp06dmDdvHmPHjuX999/HwcGB6OhonnjiiauOwdHRkZEjR3LgwAEMBgPt2rVj5syZlyzr4eHBihUrmDRpEvn5+URERPDhhx/SpUsXAJ544glcXFwYP348w4cPx9XVldjYWIYOHQqAi4sLK1asYMSIEfTq1YuCggJq1apFhw4d5Apb3HR0Sill7SCEEEIIcWky4YkQQghhwyRRCyGEEDZMErUQQghhwyRRCyGEEDZMErUQQghhwyRRCyGEEDZMEvVlTJ48mdq1a+Ps7EybNm1Yv369tUOyCStWrKBbt26EhISg0+mYM2eOxXalFKNHjyY4OBiDwUBiYiK7d++2KHPy5En69u2Lh4cHXl5ePP744xQWFlqU2bJlC+3atcPZ2ZmwsDA++OCDi2L56aefiI6OxtnZmdjYWObPn1/pn/dGGjduHK1atcLd3Z2AgAB69Ohh8Txq0Oa6HjRoEL6+vri5uXHfffeRnZ1tUSYjI4OuXbvi4uJCQEAAw4cPt3icJcBff/1FixYtcHJyol69ekyfPv2ieGri/4EpU6bQpEkTPDw88PDwID4+ngULFpi3S/1Wrvfeew+dTme+Px6kjq+JlR8KYpNmzpypHB0d1VdffaX+/vtv9eSTTyovLy+VnZ1t7dCsbv78+eq1115Tv/76qwLU7NmzLba/9957ytPTU82ZM0elpaWpe++9V0VGRqozZ86Yy3Tu3Fk1bdpUrV27Vq1cuVLVq1dPPfTQQ+bteXl5KjAwUPXt21dt27ZN/fDDD8pgMKjPP//cXGb16tXKzs5OffDBB2r79u3q9ddfVw4ODmrr1q1VXgdVpVOnTmratGlq27ZtKjU1Vd19990qPDxcFRYWmss888wzKiwsTC1dulRt2LBB3XLLLapt27bm7WVlZapx48YqMTFRbd68Wc2fP1/5+fmpkSNHmsvs27dPubi4qGHDhqnt27erTz75RNnZ2amFCxeay9TU/wNz585Vf/zxh9q1a5fauXOnevXVV5WDg4Patm2bUkrqtzKtX79e1a5dWzVp0kQ9//zz5vVSxxUnifoSWrdurQYNGmR+bzQaVUhIiBo3bpwVo7I9/0zUJpNJBQUFqfHjx5vX5ebmKicnJ/XDDz8opZTavn27AlRKSoq5zIIFC5ROp1OHDx9WSin1v//9T3l7e5ufO6yUUiNGjFANGjQwv+/Tp4/q2rWrRTxt2rRRTz/9dKV+RmvKyclRgFq+fLlSSqtLBwcH9dNPP5nLpKenK0AlJycrpbQvUnq9XmVlZZnLTJkyRXl4eJjr8+WXX1YxMTEW53rggQdUp06dzO9vpv8D3t7e6ssvv5T6rUQFBQUqKipKJSUlqdtuu82cqKWOr400ff/D2bNn2bhxI4mJieZ1er2exMREkpOTrRiZ7du/fz9ZWVkWdefp6UmbNm3MdZecnIyXlxdxcXHmMomJiej1etatW2cu0759exwdHc1lOnXqxM6dOzl16pS5zIXnOV+mJv0b5eXlAeDj4wPAxo0bKS0ttfjc0dHRhIeHW9RvbGwsgYGB5jKdOnUiPz+fv//+21zmSnV3s/wfMBqNzJw5k6KiIuLj46V+K9GgQYPo2rXrRfUgdXxtZK7vfzh+/DhGo9HilwQgMDCQHTt2WCmq6iErKwvgknV3fltWVhYBAQEW2+3t7fHx8bEoExkZedExzm/z9vYmKyvriuep7kwmE0OHDiUhIYHGjRsD2md3dHTEy8vLouw/6/dS9XJ+25XK5Ofnc+bMGU6dOlWj/w9s3bqV+Ph4iouLcXNzY/bs2TRq1IjU1FSp30owc+ZMNm3aREpKykXb5Hf42kiiFsIGDRo0iG3btrFq1Sprh1LjNGjQgNTUVPLy8vj555/p168fy5cvt3ZYNUJmZibPP/88SUlJFs85F9dHmr7/wc/PDzs7u4tGIWZnZxMUFGSlqKqH8/VzpboLCgoiJyfHYntZWRknT560KHOpY1x4jsuVqQn/RoMHD2bevHksW7bM4nGOQUFBnD17ltzcXIvy/6zfa607Dw8PDAZDjf8/4OjoSL169WjZsiXjxo2jadOm/Pe//5X6rQQbN24kJyeHFi1aYG9vj729PcuXL+fjjz/G3t6ewMBAqeNrIIn6HxwdHWnZsiVLly41rzOZTCxdupT4+HgrRmb7IiMjCQoKsqi7/Px81q1bZ667+Ph4cnNz2bhxo7nMn3/+iclkok2bNuYyK1asoLS01FwmKSmJBg0a4O3tbS5z4XnOl6nO/0ZKKQYPHszs2bP5888/L2r+b9myJQ4ODhafe+fOnWRkZFjU79atWy2+DCUlJeHh4UGjRo3MZa5Udzfb/wGTyURJSYnUbyXo0KEDW7duJTU11bzExcXRt29f82up42tg7dFstmjmzJnKyclJTZ8+XW3fvl099dRTysvLy2IU4s2qoKBAbd68WW3evFkBauLEiWrz5s3q4MGDSint9iwvLy/122+/qS1btqju3btf8vas5s2bq3Xr1qlVq1apqKgoi9uzcnNzVWBgoHrkkUfUtm3b1MyZM5WLi8tFt2fZ29urCRMmqPT0dPXGG29U+9uznn32WeXp6an++usvdfToUfNy+vRpc5lnnnlGhYeHqz///FNt2LBBxcfHq/j4ePP287e2dOzYUaWmpqqFCxcqf3//S97aMnz4cJWenq4mT558yVtbauL/gVdeeUUtX75c7d+/X23ZskW98sorSqfTqcWLFyulpH6rwoWjvpWSOr4Wkqgv45NPPlHh4eHK0dFRtW7dWq1du9baIdmEZcuWKeCipV+/fkop7RatUaNGqcDAQOXk5KQ6dOigdu7caXGMEydOqIceeki5ubkpDw8P9dhjj6mCggKLMmlpaerWW29VTk5OqlatWuq99967KJYff/xR1a9fXzk6OqqYmBj1xx9/VNnnvhEuVa+AmjZtmrnMmTNn1MCBA5W3t7dycXFRPXv2VEePHrU4zoEDB1SXLl2UwWBQfn5+6sUXX1SlpaUWZZYtW6aaNWumHB0dVZ06dSzOcV5N/D8wYMAAFRERoRwdHZW/v7/q0KGDOUkrJfVbFf6ZqKWOK06nlFLWuZYXQgghxL+RPmohhBDChkmiFkIIIWyYJGohhBDChkmiFkIIIWyYJGohhBDChkmiFkIIIWyYJOorKCkpYcyYMZSUlFg7lBpJ6rdqSf1WPanjqiX1q5H7qK8gPz8fT09P8vLy8PDwsHY4NY7Ub9WS+q16UsdVS+pXI1fUQgghhA2TRC2EEELYsBr/POqysjI2b95MYGAgen3FvpcUFBQAcPjwYfLz86sivJua1G/VkvqtelLHVasm16/JZCI7O5vmzZtjb3/lVFzj+6hTUlJo3bq1tcMQQgghLrJ+/XpatWp1xTI1/oo6MDAQ0CojODjYytEIIYQQcPToUVq3bm3OUVdS4xP1+ebu4OBgQkNDrRyNEEIIUe5qumRlMJkQQghhwyRRCyGEEDZMErUQQghhw6zaR71ixQrGjx/Pxo0bOXr0KLNnz6ZHjx7m7Uop3njjDaZOnUpubi4JCQlMmTKFqKgo6wUthKjRjEYjpaWl1g5DVHMODg7Y2dlVyrGsmqiLiopo2rQpAwYMoFevXhdt/+CDD/j444/5+uuviYyMZNSoUXTq1Int27fj7OxshYiFEDWVUoqsrCxyc3OtHYqoIby8vAgKCkKn013XcayaqLt06UKXLl0uuU0pxaRJk3j99dfp3r07AN988w2BgYHMmTOHBx988EaGqsVUdpbcxe/h3bgjhN9yw88vhKg655N0QEAALi4u1/3HVdy8lFKcPn2anJwcgOu+Ndhmb8/av38/WVlZJCYmmtd5enrSpk0bkpOTb3iiPlZQwrLPXqBP0fcYd/2K3cDV4Oh6Q2MQQlQNo9FoTtK+vr7WDkfUAAaDAYCcnBwCAgKuqxncZgeTZWVlAVx0M3hgYKB526WUlJSQn59vXs5PQXe9vF0cmGV3D0eVD3a5+2HJm5VyXCGE9Z3vk3ZxcbFyJKImOf/7dL1jHmw2UV+rcePG4enpaV4aNWpUKce1t9Pz6n23MKL0SW3F+s9h/8pKObYQwjZIc7eoTJX1+2SziTooKAiA7Oxsi/XZ2dnmbZcycuRI8vLyzMv27dsrLaaWET6EtLyHGWV3AqB+GwgllXPFLoQQQlyKzSbqyMhIgoKCWLp0qXldfn4+69atIz4+/rL7OTk54eHhYV7c3d0rNa4RnaOZ7NCfQ8oPXW4GJI2u1OMLIYS11a5dm0mTJl11+b/++gudTlflI+anT5+Ol5dXlZ7DFlk1URcWFpKamkpqaiqgDSBLTU0lIyMDnU7H0KFDefvtt5k7dy5bt27l0UcfJSQkxOJe6xvN29WRIXc3Z3jp09qKDV/B3j+tFo8Q4ual0+muuIwZM+aajpuSksJTTz111eXbtm3L0aNH8fT0vKbziSuz6qjvDRs2cMcdd5jfDxs2DIB+/foxffp0Xn75ZYqKinjqqafIzc3l1ltvZeHChVa/h/r+lmHMSklg+pGO9LdfDL8NhoHJ4Cy/pEKIG+fo0aPm17NmzWL06NHs3LnTvM7Nzc38WimF0Wj812cfA/j7+1coDkdHxyt2SYrrY9Ur6ttvvx2l1EXL9OnTAe3b4tixY8nKyqK4uJglS5ZQv359a4YMgF6v4+0esYw3PsgBUyDkH4ZFr1o7LCHETSYoKMi8eHp6otPpzO937NiBu7s7CxYsoGXLljg5ObFq1Sr27t1L9+7dCQwMxM3NjVatWrFkyRKL4/6z6Vun0/Hll1/Ss2dPXFxciIqKYu7cuebt/2z6Pt9EvWjRIho2bIibmxudO3e2+GJRVlbGkCFD8PLywtfXlxEjRtCvX78Kt5hOmTKFunXr4ujoSIMGDfj222/N25RSjBkzhvDwcJycnAgJCWHIkCHm7f/73/+IiorC2dmZwMBAevfuXaFz3yg220dt6xqFePBA24a8VPo0JnSw+TvYtcjaYQkhKolSitNny6yyKKUq7XO88sorvPfee6Snp9OkSRMKCwu5++67Wbp0KZs3b6Zz585069aNjIyMKx7nzTffpE+fPmzZsoW7776bvn37cvLkycuWP336NBMmTODbb79lxYoVZGRk8NJLL5m3v//++3z//fdMmzaN1atXk5+fz5w5cyr02WbPns3zzz/Piy++yLZt23j66ad57LHHWLZsGQC//PILH330EZ9//jm7d+9mzpw5xMbGAlqL7pAhQxg7diw7d+5k4cKFtG/fvkLnv1FsdsKT6uCFu6JI3HqE/zvdhSft58PcITBoLRi8rR2aEOI6nSk10mi0db58bx/bCRfHyvnzPHbsWO666y7zex8fH5o2bWp+/9ZbbzF79mzmzp3L4MGDL3uc/v3789BDDwHw7rvv8vHHH7N+/Xo6d+58yfKlpaV89tln1K1bF4DBgwczduxY8/ZPPvmEkSNH0rNnTwA+/fRT5s+fX6HPNmHCBPr378/AgQMBrft07dq1TJgwgTvuuIOMjAyCgoJITEzEwcGB8PBwWrduDUBGRgaurq7cc889uLu7ExERQfPmzSt0/htFrqivg7uzA6PuacSEsj7sUyGcdXCDwmPWDksIIczi4uIs3hcWFvLSSy/RsGFDvLy8cHNzIz09/V+vqJs0aWJ+7erqioeHh3mKzEtxcXExJ2nQptE8Xz4vL4/s7Gxz0gSws7OjZcuWFfps6enpJCQkWKxLSEggPT0dgPvvv58zZ85Qp04dnnzySWbPnk1ZWRkAd911FxEREdSpU4dHHnmE77//ntOnT1fo/DeKXFFfp66xwcyKCqH/nuFEudXnS78oZMoEIao/g4Md28d2stq5K4urq+VUxy+99BJJSUlMmDCBevXqYTAY6N27N2fPnr3icRwcHCze63Q6TCZThcpXZpP+1QgLC2Pnzp0sWbKEpKQkBg4cyPjx41m+fDnu7u5s2rSJv/76i8WLFzN69GjGjBlDSkqKzd0CJlfU10mn0/HmvTFk6YNZujuPhdvOTW96g38hhRCVS6fT4eJob5WlKmdIW716Nf3796dnz57ExsYSFBTEgQMHqux8l+Lp6UlgYCApKSnmdUajkU2bNlXoOA0bNmT16tUW61avXm0xI6XBYKBbt258/PHH/PXXXyQnJ7N161YA7O3tSUxM5IMPPmDLli0cOHCAP/+0vdtt5Yq6EtTxd+OZ2+rw8Z97eHvuVu48MQOnk7ug1+fWDk0IISxERUXx66+/0q1bN3Q6HaNGjbrilXFVee655xg3bhz16tUjOjqaTz75hFOnTlXoS8rw4cPp06cPzZs3JzExkd9//51ff/3VPIp9+vTpGI1G2rRpg4uLC9999x0Gg4GIiAjmzZvHvn37aN++Pd7e3syfPx+TyUSDBg2q6iNfM7miriQD76hHuI8LroX7cPjrHdgyU+YCF0LYnIkTJ+Lt7U3btm3p1q0bnTp1okWLFjc8jhEjRvDQQw/x6KOPEh8fj5ubG506darQPBk9evTgv//9LxMmTCAmJobPP/+cadOmcfvttwPa86CnTp1KQkICTZo0YcmSJfz+++/4+vri5eXFr7/+yp133knDhg357LPP+OGHH4iJiamiT3ztdOpGdxrcYIcOHSIsLIzMzExCQ0Or9FzLdubw2LQUnrGfR7/EOIJvGwAyyb8QNq+4uJj9+/cTGRlp9QmVblYmk4mGDRvSp08f3nrrLWuHUymu9HtVkdwkTd+V6I4GAXSOCeKzv+9h4w5vZrUHveRpIYS4yMGDB1m8eDG33XYbJSUlfPrpp+zfv5+HH37Y2qHZHGn6rmSjuzXCxdGOlAOn+GXTITiTCxlrrR2WEELYFL1ez/Tp02nVqhUJCQls3bqVJUuW0LBhQ2uHZnPkirqShXgZeL5DFOMW7OC7+cu476930JedgYHrwCPY2uEJIYRNCAsLu2jEtrg0uaKuAgNujaR+oBvbTntxxOgFxXnw+xC5ZUsIIUSFSaKuAg52et7uEYsROx7LG4BJ7wi7F0Pq99YOTQghRDUjibqKtI704b4Woew2hTLd6dzgiIUjIe+QdQMTQghRrUiirkIj747Gw9met08lkuPZBErytWdXSxO4EEKIqySJugr5uTnxcudoTOgZkDsAZecM+5bBxmnWDk0IIUQ1IYm6ij3UOpymoZ5sKwlgtu/j2spFr8OpA1aNSwghRPUgibqK2el1vN0jFr0OXsyIJy+gNZQWwZxBYIX5dYUQ4p9uv/12hg4dan5fu3ZtJk2adMV9dDodc+bMue5zV9ZxrmTMmDE0a9asSs9RlSRR3wCxoZ48cksECj0Dix5HObjCwVWQMtXaoQkhqrFu3brRuXPnS25buXIlOp2OLVu2VPi4KSkpPPXUU9cbnoXLJcujR4/SpUuXSj1XTSOJ+gYZ1rEBfm5OrD7hzoqIwdrKpDfgxF7rBiaEqLYef/xxkpKSOHTo4rtJpk2bRlxcHE2aNKnwcf39/XFxcamMEP9VUFAQTk5ON+Rc1ZUk6hvE0+DA6121qfGe3tGU4rB2UHZGBpYJIa7ZPffcg7+/P9OnT7dYX1hYyE8//cTjjz/OiRMneOihh6hVqxYuLi7Exsbyww8/XPG4/2z63r17N+3bt8fZ2ZlGjRqRlJR00T4jRoygfv36uLi4UKdOHUaNGkVpaSmgPW7yzTffJC0tDZ1Oh06nM8f8z6bvrVu3cuedd2IwGPD19eWpp56isLDQvL1///706NGDCRMmEBwcjK+vL4MGDTKf62qYTCbGjh1LaGgoTk5ONGvWjIULF5q3nz17lsGDBxMcHIyzszMRERGMGzcOAKUUY8aMITw8HCcnJ0JCQhgyZMhVn/tayBSiN1D3ZiHMTMlg7b6TjOYZPujaE+IGWDssIcSVnC2q+D52TmB37s+rsQyMJaDTg4Ph34/r6HrVp7G3t+fRRx9l+vTpvPbaa+ZnOf/0008YjUYeeughCgsLadmyJSNGjMDDw4M//viDRx55hLp169K6det/PYfJZKJXr14EBgaybt068vLyLPqzz3N3d2f69OmEhISwdetWnnzySdzd3Xn55Zd54IEH2LZtGwsXLjQ/K9rT0/OiYxQVFdGpUyfi4+NJSUkhJyeHJ554gsGDB1t8GVm2bBnBwcEsW7aMPXv28MADD9CsWTOefPLJq6q3//73v3z44Yd8/vnnNG/enK+++op7772Xv//+m6ioKD7++GPmzp3Ljz/+SHh4OJmZmWRmZgLwyy+/8NFHHzFz5kxiYmLIysoiLS3tqs57rSRR30A6nY63ezSm86SV/Lgb7oq/h7vkMZhC2LZ3Qyq+z/3TIaan9nrH7/BTf4i4FR77o7zMpFg4feLifcfkVehUAwYMYPz48Sxfvtz8HOZp06Zx33334enpiaenJy+99JK5/HPPPceiRYv48ccfrypRL1myhB07drBo0SJCQrS6ePfddy/qV3799dfNr2vXrs1LL73EzJkzefnllzEYDLi5uWFvb09QUNBlzzVjxgyKi4v55ptvcHXVvrB8+umndOvWjffff5/AwEAAvL29+fTTT7GzsyM6OpquXbuydOnSq07UEyZMYMSIETz44IMAvP/++yxbtoxJkyYxefJkMjIyiIqK4tZbb0Wn0xEREWHeNyMjg6CgIBITE3FwcCA8PPyq6vF6SNP3DVYvwJ0n29cBYMzcvzl9tgxKCmDlh9o3byGEqIDo6Gjatm3LV199BcCePXtYuXIljz+u3Q5qNBp56623iI2NxcfHBzc3NxYtWkRGRsZVHT89PZ2wsDBzkgaIj4+/qNysWbNISEggKCgINzc3Xn/99as+x4Xnatq0qTlJAyQkJGAymdi5c6d5XUxMDHZ2dub3wcHB5OTkXNU58vPzOXLkCAkJCRbrExISSE9PB7Tm9dTUVBo0aMCQIUNYvHixudz999/PmTNnqFOnDk8++SSzZ8+mrKxq/3bLFbUVDLkzirmpRzice4ZPl+7i5YNPQ9YWrWns1hesHZ4Q4kKvHqn4PnYXDI6K7qYdQ/eP66KhW68vrgs8/vjjPPfcc0yePJlp06ZRt25dbrvtNgDGjx/Pf//7XyZNmkRsbCyurq4MHTqUs2fPVtr5k5OT6du3L2+++SadOnXC09OTmTNn8uGHH1baOS7k4OBg8V6n02GqxNtdW7Rowf79+1mwYAFLliyhT58+JCYm8vPPPxMWFsbOnTtZsmQJSUlJDBw40Nyi8c+4KotNX1EbjUZGjRpFZGQkBoOBunXr8tZbb6Gq+RScBkc7xtwbA8DUVQfIbjQAXPyg/qVvsxBCWJGja8UXuwuugezstXUX9k9f6bjXoE+fPuj1embMmME333zDgAEDzP3Vq1evpnv37vznP/+hadOm1KlTh127dl31sRs2bEhmZiZHjx41r1u7dq1FmTVr1hAREcFrr71GXFwcUVFRHDx40PLjOjpiNBr/9VxpaWkUFZX3369evRq9Xk+DBg2uOuYr8fDwICQk5KJHbK5evZpGjRpZlHvggQeYOnUqs2bN4pdffuHkyZMAGAwGunXrxscff8xff/1FcnIyW7dW3hevf7LpK+r333+fKVOm8PXXXxMTE8OGDRt47LHH8PT0rPJRdlXtrkaBJDYMYEl6Ds+nN+CHZ9egcw+0dlhCiGrIzc2NBx54gJEjR5Kfn0///v3N26Kiovj5559Zs2YN3t7eTJw4kezsbIukdCWJiYnUr1+ffv36MX78ePLz83nttdcsykRFRZGRkcHMmTNp1aoVf/zxB7Nnz7YoU7t2bfbv309qaiqhoaG4u7tfdFtW3759eeONN+jXrx9jxozh2LFjPPfcczzyyCPm/unKMHz4cN544w3q1q1Ls2bNmDZtGqmpqXz/vfaEw4kTJxIcHEzz5s3R6/X89NNPBAUF4eXlxfTp0zEajbRp0wYXFxe+++47DAaDRT92ZbPpK+o1a9bQvXt3unbtSu3atenduzcdO3Zk/fr11g6tUrzRLQZnBz1r95/itz0X9HHsXwHJ/7NeYEKIaufxxx/n1KlTdOrUyaI/+fXXX6dFixZ06tSJ22+/naCgIHr06HHVx9Xr9cyePZszZ87QunVrnnjiCd555x2LMvfeey8vvPACgwcPplmzZqxZs4ZRo0ZZlLnvvvvo3Lkzd9xxB/7+/pe8RczFxYVFixZx8uRJWrVqRe/evenQoQOffvppxSrjXwwZMoRhw4bx4osvEhsby8KFC5k7dy5RUVGANoL9gw8+IC4ujlatWnHgwAHmz5+PXq/Hy8uLqVOnkpCQQJMmTViyZAm///47vr6+lRrjhXTKhtuR3333Xb744gsWL15M/fr1SUtLo2PHjkycOJG+ffte1TEOHTpEWFgYmZmZhIaGVnHEFTd52R7GL9qJn5sTS1+8Dc/iIzC5jXaP9V1jIeF5a4coRI1XXFzM/v37iYyMxNnZ2drhiBriSr9XFclNNn1F/corr/Dggw8SHR2Ng4MDzZs3Z+jQoVdM0iUlJeTn55uXgoKCGxhxxT3Zrg51/V05XljC2N+3o7zC4dah2sak0bDqI6vGJ4QQwrpsOlH/+OOPfP/998yYMYNNmzbx9ddfM2HCBL7++uvL7jNu3DjzvYOenp5X3Q9jLY72et7q0RidDn7ZdIhRv23D1H4E3HGuD2jJGO3WLSGEEDclm07Uw4cPN19Vx8bG8sgjj/DCCy+Yp3K7lJEjR5KXl2detm/ffgMjvjZt6/rxwX1N0Ongu7UZvDZnK6Z2w+HOcxMILB0LK8ZbN0ghhBBWYdOjvk+fPo1eb/ldws7O7or3yzk5OVmMJMzPz6+y+CrT/XFh2NvpePHHNH5Yn0mZUfHefS9hp9NrifrPt0EpuO1la4cqhBDiBrLpRN2tWzfeeecdwsPDiYmJYfPmzUycOJEBA2rm/Ng9m4ei1+l4YVYqP208hFEpxvcehh06WPomLHsHlAluf8XaoQohhLhBbDpRf/LJJ4waNYqBAweSk5NDSEgITz/9NKNHj7Z2aFWme7Na2Ol1PD8zlV83HcZoUnx4/1DsdXpY8gb8NU67sr5jpLVDFaLGqczZrYSorN8nm07U7u7uTJo0yeJxazeDe5qEYKfT8dwPm/kt9QhGk2LSA0O0ZJ00Cpa/Byi4fSTIQz2EuG6Ojo7o9XqOHDmCv78/jo6O5pm9hKgopRRnz57l2LFj6PV6HB0dr+t4Np2ob2ZdYoP5n17HoBmbmLflKCal+O+Dg3HQ6WHxa7D8fQhoBDE9rB2qENWeXq8nMjKSo0ePcuTINcztLcQluLi4EB4eftFYq4qSRG3DOsYE8dl/WvLsd5uYvzULo2kTnzw0EEedDo6kQsNu1g5RiBrD0dGR8PBwysrK/nVOaiH+jZ2dHfb29pXSMiOJ2sZ1aBjI54+25OlvN7Lo72wGfr+RyX2fwclOX97sbTJpr6WpTojrotPpcHBwqLKnIAlxLWz6PmqhuaNBAF8+GoeTvZ4l6Tk88+1GisvODVIwGWHOs9pAM9udDVYIIcQ1kkRdTbSv789X/Vvh7KBn2c5jPPXtRopLjdoDPLbMhDWfQvbf1g5TCCFEJZNEXY0k1PNjWv/WGBzsWLHrGE98vYEzYe2h64fQ+/8gqLG1QxRCCFHJJFFXM/F1ffl6QGtcHO1Ytec4A6ancLppf4jpWV7o9ElpBhdCiBpCEnU11DrSh28GtMbNyZ7kfSfoPy2FopJzz7POOwRf3A4LR0qyFkKIGkASdTUVV9uHbx5vjbuTPev3n6TfV+spLCmDjLWQexDWTYEFIyRZCyFENSeJuhprEe7Nd0+0wcPZng0HT/Ho/60jP6o73PspoIP1n8P84ZKshRCiGpNEXc01DfPi+yduwdPgwKaMXB75v/XkNXwQup9L1ilT4Y9hUHbW2qEKIYS4BpKoa4DYUE9mPNkGbxcH0jJz+c+X68ht0Ad6/A/QwYav4MMG8MeLkJkiV9hCCFGNSKKuIWJCPJnx5C34uDqy9XAeD09dx6mo3nDfl+AaAGdOQsqX8H+J8EkL+Os9OLHX2mELIYT4F5Koa5CGwR788OQt+Lk5sv1oPg9NXcuJyG4wLB3+8ys0eQAcXODkPu1xmZ+0gLSZ1g5bCCHEFUiirmEaBLkz86lb8Hd3YkdWAQ9NXcux00ao1wF6fQEv7YZeU6FuB9A7QORt5TvvWw7bfoXSM9b7AEIIISxIoq6B6gVoyTrQw4ld2YU8NHUt+48XaRud3KBJH3jkVxi+BzyCy3dcNRF+fgySP7VO4EIIIS4iibqGquvvxqyn4gn2dGZPTiGdPlrBxMU7tfnBzzN4lb9WCkJbgWc4NO5dvn53EiS9ATnpNyx2IYQQ5XRK1ewhwIcOHSIsLIzMzExCQ0OtHc4Nd+jUaV6dvY0Vu44BEOZjYEy3GDo0DLz0DkpZPi5zxoOwa4H2OigWmjwIsb3BPaiKIxdCiJqrIrlJEvVNQCnFgm1ZjP19O1n5xQDc1SiQN7o1ItTb5co7p8+D1BmwezGYSrV1Or3Wt930Qa2v28UH9HZV/CluQmUlcChFe0Ja1jbwCodG3SEi3tqRCSGukyTqC0iiLldUUsbHS3fzf6v2U2ZSODvoee7OKJ5oF4mT/b8k2tMn4e9fYcuPkLnuHxt1YPAGVz9w8YW7xkJYa23T8T1asvGtB2GtquRz1RjGMjiyGQ6s0JJzxlooK7Ys02kcxA/UXh/fAyvGa3Xd6vEbH68Q4ppVJDfZ36CYhA1wdbJn5N0Nua9lKK/P2cb6/ScZv2gnv2w6xFvdG5NQz+/yO7v4QKsntOXkPtjyE2z9EU7sAZR2n/aZk1pZ4wWzoO3/S5toJfoeePB7bZ1SMC4MnNzB1VdL7ubFTzuXwVsrW1YCxhJtZrXoruAVpq3PXK+NUPdvAHGPlZ/vh4eh7IxW3lhybv+zlj/tHLT9AhtDYAxEtgdPK3yJM5kge5uWlPevgINr4GyBZRm3QKjdDmq11B64UjuhfNvhDdqzyHMzLBP13CHgFqB9vqBY8I4EvQxHEaK6kkR9E6of6M6sp25hTuph3vljB/uOFdH3y3V0axrC610bEujhfOUD+NSB20doi7EUzpyCouNw+oS2BDQqL+saAHXugJBm5etK8rWEdLYACo5cfeC+9coT9bEd2oNHojpZJuq9Sy++Cr2UgqOw7y/tda+p2kh4gOy/Ycd87Sq1zm2X3f2a/LP//+fHYPscyzLOXhDZTutaiGwPfvUt97lQUBO44zXL8QIlhbDpG+CChjJHt3NJ+1ziDorV/o0cDJX0wYQQVUkS9U1Kp9PRs3kod0YHMnHxTr5de5Df046wbEcOL9xVn37xEdjbXcVVmJ2DdvXmFnDp7Y3u1ZYLObrD0K1aUi86UZ7gT1+Q7E+f0hKUvRPYOWnncb3gij8oFm59AfyjLY99zyRtPzvH8n3tHcuPYe8EZ09DznZtyf5bS3jn7VsOy97WWgDOJ2qlYOEr2heFwBgtyV04Yv7fKAWzn4F9y+DJP8uv3kPjYM8SiEg4l5zbQ2Ds1V/9BjbSFsuTQZcPIGsLZG3VRuufLYTMtdpynk4PvlFaPQY2gmb/AffLDDAUQliV9FELALYdzuO1OdtIy8wFIDrInbd7NCauto91A7vRdi+BrT9BeBuIG6CtyzsEH8VYlvMIPZcoYyAgRvvpFwVFx2D/SsjLgPbDy8tPvRMOb4QeU6DZw9q6s6e1Lw92DlX3eYxlcGK3lrSztmiD0rK2aF+GLvTcJvCtq71O/p92pd/8P9Di0fLjlORr3RJCXKsLW5XyDmtjMlz9IPyW8jI7F2gtdRUR3AS8a2uvC4/BwVVa11q9xPIyqT9o3XPGUm1grLFM+2kqK399fpvJqL1u3EvrcgNtTEjKl9DlvWv++BeSPmpRYY1reTL72bbM2pDJ+wt3sCOrgN6fJdO7ZSgju0Tj6+Zk7RBvjKhEbbmQzg5uHVZ+BZ6XCfmHtGX34vJyenvtP/35fdo8o/2xALjzdW0muNALBtQ5/suI+8pgZw8BDbXlfPO+UlCQpfWPH02D47vBM6x8n6Np2oDBqI7l607sgf+10ZrmfSK17o8LF+9IrVXlcs3018NYCqWntRnzzv/0b1je8lBSCChtelxr3n1gLIPSIjh7iSWirTbZEMCxXVrXjXdtLcGAlhiytmotQXaO577AnW8VOvda72CbYw1MJq37qzALCrOhMEf7/SrMObcuR1tfkA29vyr//5WRDL88rnXz9JtbfrzZT0NxXsViuOej8i/W2dvgp/5a69SFiXrFB9r4mooIiC5P1GVntC/bViCJWpjp9Toeah1Op5gg3l+wg1kbMvl54yGStmfzcucGPNgqHDt9FfwhtnUewZD4Rvn7M7lak3LO31rizj6XwM8WADqtPz6yvTZw7XyirnunFQK/DJ1O+0wewRB118Xb278EDTpryfC8/EPaz+Jc7SroyOaL93NwPZe4I7XFNwpaPFK+fctPWp1Fd4PQltq6w5tg2TuWSdhiOQ3KePG5Rh4uT3xJo7QnxN3+qjZuArRkOKOPlrwdnM/9NGiL/bmf5nUXbI/pVd6tsWepNvI+/BZtCl6A3Ez4baDWGmJOxIXaT2PJ5ev82TVaqwtA+lz48y1o/si5x9GiHeOLqxgTobe/IJE7aYkvsp22bccfsOojqH0rJI4p32fuc9oXR3tnrRvI3ln7AnD+p53TxesCGpZ3Z+Uf0RKUkzvUuV1bZzLCl4nnEnN2+RfUf1OYVf7axQfC2mjnulCtOK0+K8Ltgm4bZ0+tO8kn0rJM/S5QlKN94bGzP/fTQatTvf251+e3ndse1qZ8f88wuP2VisVVSWw+UR8+fJgRI0awYMECTp8+Tb169Zg2bRpxcXHWDq3G8nF15P3eTejTKoxRc7ax/Wg+r83exo8pmbzdI5bYUE9rh2hdBi/tXuYL72dWCvIPawO3KtJ/bYv8orTlQvUS4dWjcOqAdlVych+c2l/+Ou+QdjWZvVVbQEsOzf9TfpW9fQ7smKf9wTufqEsKtH76q6HTlyfUspLyRH1+bvoLB8eVFGjxVVSdO8r//fb+qU2n23ZIeaJWJm2E/hXjtNN+Dxxdyxcu+ILrHgxht2hjHs4zGcGj1rk7E85qP41nL/6SYirTlvMtw8pUvi3/iHYrpPsF0wIrBZu+xWJw4dW47/+0iY1A+7yzn9bq5nyi1ttpvwvn7/QAMPhoAxvdAsDt/M9Ay3UX3l1R985Lf4F95NeKxfpPtVrAY/MvXt/53es7rsGr/PfgBrPpRH3q1CkSEhK44447WLBgAf7+/uzevRtvb29rh3ZTaBnhzdzBCXy79iATF+8i7VAe905exX/aRPBSxwZ4ulRh32p1o9NZ5xavG8nR5TID2NCSS25GeeI+uU/7Q24yalcoAPU7a5O2BF7Q3+8frfXbX3iFa77iNVheEds5XrppvccUrenzwmToXx8GLNauyMuKL3+1XnpGa9I8v875gi+h4bdo+56fEwC0hNPrywuSsJtWL+bXrpeP87zmfbXlQi4+MGz7xWXP95Uaz577WXLB67PgFVFeNqojPDhDu9PiPKW0q2vjWe2zlJWc+1ms/ZtZrCspv6XRcMHfWK8I7Sr3nwM3+3ytfV63QO2c9o6X/8ziutj0YLJXXnmF1atXs3Llyms+hgwmqxw5+cW8Oz+dOana7VS+ro7aPdktaqGrin5JIYSowSqSm65pZEJmZiaHDh0yv1+/fj1Dhw7liy++uJbDXdbcuXOJi4vj/vvvJyAggObNmzN16tQr7lNSUkJ+fr55KSgouGJ5cXUCPJyZ9GBzZjzZhnoBbpwoOstLP6XRY/JqfkzJpKjkKvuohBBCVMg1JeqHH36YZcuWAZCVlcVdd93F+vXree211xg7dmylBbdv3z6mTJlCVFQUixYt4tlnn2XIkCF8/fXXl91n3LhxeHp6mpdGjS7RTCeuWdu6fswf0o4RnaMxONiRdiiPl3/ZQqt3lvDyz2lsOHASG26kEUKIaueamr69vb1Zu3YtDRo04OOPP2bWrFmsXr2axYsX88wzz7BvXwWHwF+Go6MjcXFxrFmzxrxuyJAhpKSkkJycfMl9SkpKKCkpH315+PBhGjVqJE3fVSCnoJhfNh7mpw2Z7DtePkqzrr8rfeLC6NmiFgHu/zLLmRBC3ISqvOm7tLQUJyftvtolS5Zw773azFPR0dEcPXr0Wg55ScHBwRddETds2JCMjIzL7uPk5ISHh4d5cXd3r7R4hKUAd2eevb0uS1+8jZ+eiad3y1AMDnbsPVbEuAU7iB/3J09+s4Gk7dmUGU3/fkAhhBAXuaZR3zExMXz22Wd07dqVpKQk3nrrLQCOHDmCr69vpQWXkJDAzp07Ldbt2rWLiIiIy+whrEGn09Gqtg+tavsw5t4Y5qUd4ccNmWzKyCVpezZJ27Pxd3eiV4ta9IkLo66/m7VDFkKIauOaEvX7779Pz549GT9+PP369aNp06aANvirdevW/7L31XvhhRdo27Yt7777Ln369GH9+vV88cUXlT5oTVQeNyd7HmwdzoOtw9mdXcCPGzL5ddNhjhWU8PnyfXy+fB9xEd70aRVG19hgXJ1s+g5BIYSwumu+PctoNJKfn29xT/OBAwdwcXEhIOAyD2i4BvPmzWPkyJHs3r2byMhIhg0bxpNPPnnV+8vtWdZXajSxND2HnzZksmxnDqZzv3Gujnbc0ySEPq3CaBHuJbd5CSFuGhXJTdeUqM+cOYNSChcXba7igwcPMnv2bBo2bEinTp2uLeoqIonatmTnF/PLpkP8tOEQ+y8YgFYvwI0+caH0bB6Kv/tNMq+4EOKmVeWJumPHjvTq1YtnnnmG3NxcoqOjcXBw4Pjx40ycOJFnn332moOvbJKobZNSipQDp5iVksn8rUc5U6pNlWiv13FndAD3x4VR198VJwc7nOz1ONrrtZ92ernyFkJUe1WeqP38/Fi+fDkxMTF8+eWXfPLJJ2zevJlffvmF0aNHk56efs3BVzZJ1LavoLiUeVuOMislk9Rzj9m8kvNJ28ne7txPveU6By2hOzlo78tfa+X83Jzo1jQEv5vliWBCCJtT5Y+5PH36tPm2p8WLF9OrVy/0ej233HILBw8evJZDipuYu7MDD7UO56HW4ezKLuDHlEwWbMsi/0wpJUYTZ8ssb+06W6atK+DaZ0MbN38HXZsE069tbZqFeV3nJxBCiKpzTYm6Xr16zJkzh549e7Jo0SJeeOEFAHJycvDw8KjUAMXNpX6gO6/f04jX7ym/f95kUpw1mjhrNFFSaqKkzMjZMhMl5xbttZGS0nNlLnx9ifKbM3NJy8xl9ubDzN58mKZhXvSLj6Brk2Cc7K34PGMhhLiEa0rUo0eP5uGHH+aFF17gzjvvJD5ee9zf4sWLad68eaUGKIRer8NZb4ezgx1U0kRnqZm5fLPmAPO2HCUtM5dhmbm880c6D7UOp+8t4QR7Gv79IEIIcQNc8+1ZWVlZHD16lKZNm6LXaxOcrV+/Hg8PD6Kjo/9l7xtH+qjFlRwvLGHm+gy+W5tBVn4xAHZ6HZ1jgng0PoLWkT4yeE0IUemqfDDZP08G2GwSlEQtrkap0UTS9mymrznA+v0nzesbBnvQLz6C7s1qYXCUZnEhROWo8rm+TSYTY8eOxdPTk4iICCIiIvDy8uKtt97CZJI5nUX142Cn5+7YYH58Op75Q9rxUOswnB30pB/N55Vft3LLuKW8Oz+dzJOnrR2qEOImc0191K+99hr/93//x3vvvUdCQgIAq1atYsyYMRQXF/POO+9UapBC3EiNQjwY16sJIzpH89OGQ3yz9gCZJ8/wxYp9TF25jw7RAfRrW5tb6/lJs7gQospdU9N3SEgIn332mfmpWef99ttvDBw4kMOHD1dagNdLmr7F9TKaFMt25PB18gFW7j5uXl/H35V+8bW5r2UobjJnuRCiAqr8PuqTJ09ecsBYdHQ0J0+evMQeQlRfdnodiY0CSWwUyJ6cQr5be5CfNx5i37Ei3pj7N+MX7eS+FrV4tG1teTKYEKLSXVMfddOmTfn0008vWv/pp5/SpEmT6w5KCFtVL8CNMffGkDzyTt68N4Y6/q4UlpTxdfJBOny4nJ7/W82ERTtZs+c4xeemRRVCiOtxTU3fy5cvp2vXroSHh5vvoU5OTiYzM5P58+fTrl27Sg/0WknTt6hKSilW7TnO12sOsnRHNhf+b3K019Mi3Iv4On60redL01AvHO2v6buxEKKGuSG3Zx05coTJkyezY8cOABo2bMhTTz3F22+/bVPPi5ZELW6UI7lnWLX7OMn7TrBm73Gy80ssthsc7Iir7U18XV/a1vWjcYgH9naSuIW4Gd3Q+6gvlJaWRosWLTAabafJTxK1sAalFPuOF5G894S27DvByaKzFmXcnexpHelDfF1f4uv60jDIA71eRpELcTOo8sFkQogr0+l01PV3o66/G/+5JQKTSbErp4DkvSdYs/cE6/adIL+4jKU7cli6IwcALxcHbon0pW09X+Lr+FIvwE1u/xJCSKIW4kbQ63VEB3kQHeTBYwmRGE2K7UfySd53nDV7T7B+/0lyT5ey8O8sFv6dBYCfm9O5ZnItcUf4ukjiFuImJIlaCCuw0+uIDfUkNtSTp9rXpdRoYsuhPJL3an3cGw6c4nhhCb+nHeH3tCMA1PIymBN327p+BHlW0hNKhBA2rUKJulevXlfcnpubez2xCHHTcrDT0zLCm5YR3gy+M4riUiOpmbms2XuCtXtPsDnzFIdzz/DzxkP8vFGbX7+Onytt62lJ+5Y6vvi4Olr5UwghqkKFErWnp+e/bn/00UevKyAhBDg72HFLHV9uqeMLd8Hps2VsOHCKNXu1EeXbDuex73gR+44X8d3aDAAaBXtoV9v1fGlV2wd3ZwcrfwohRGWo1FHftkhGfYuaKO90Kev2awPTkveeYGd2gcV2O72OJqGeJNT1o21dX1pEeGvP8xZC2ASr3Z5liyRRi5vBsYISkvedIHmvNjjt4AnLp3w52utpGe5NQj1f4uv60STUEwe5h1sIq5Hbs4S4yfi7O3Fv0xDubRoCwKFTp81X2+cnX0nep93PDbtwdbSjdaQPbetqs6bJPdxC2C5J1ELUQKHeLvSJc6FPXJh58hUtcR8nee8JTp0uZdnOYyzbeQwAPzdHbq3nR7sof9pF+RHgISPKhbAVkqiFqOEunHzlkXOTr6Rn5ZO89wSr9xxn3f6THC88y5zUI8xJ1W4Fiw5yp12UlrhbR/pI/7YQVlSt+qjfe+89Ro4cyfPPP8+kSZOuah/poxbiys6WmdiUcYqVu4+xcvdxth7Ou+jhIm0ifcyJOzrIXSZeEeI61cg+6pSUFD7//HN5jKYQlczRXm++FWx4JzhVdJbVe4+zYpeWuI/mFbNy93FW7j4O7MDPzelc0vbj1ig/AtylmVyIqlQtEnVhYSF9+/Zl6tSpvP3229YOR4gazdvVkXuahHBPkxCUUuw9VmhO1Ml7T3C8sITZmw8ze/NhQGsmb19f69tuVVuayYWobNUiUQ8aNIiuXbuSmJj4r4m6pKSEkpLyxwsWFBRcobQQ4kp0Oh31AtypF+DOYwmRlJQZ2XQw16KZfEdWATuyCvhixT6c7PW0jvShfZQ/7er70SBQmsmFuF42n6hnzpzJpk2bSElJuary48aN480336ziqIS4OTnZ25kfy/lyZzhRWMLqvSdYea6ZPCv/gmby+VDX35V+bWvTq0Uobk42/+dGCJtk04PJMjMziYuLIykpydw3ffvtt9OsWbPLDib75xX14cOHadSokQwmE6KKKaXYk1PIit3HWbn7GGv3naC41ASAm5M997WoxSPxtakX4GblSIWwvhozM9mcOXPo2bMndnblfV5GoxGdToder6ekpMRi26XIqG8hrKOguJRfNx3m6+QD7DtWZF7fLsqPR+Nrc2d0AHYyyYq4SdWYRF1QUMDBgwct1j322GNER0czYsQIGjdu/K/HkEQthHUppVi95wRfJx9gaXo2pnN/cWp5GXgkPoIH4sLwlid/iZtMjbk9y93d/aJk7Orqiq+v71UlaSGE9el0Om49dytX5snTfLfuILNSMjmce4b3Fuzgo6RddG8WwqPxtWlc68pP6BPiZmTTiVoIUbOE+bgwsktDXkisz9y0I3y95gB/H8nnxw2H+HHDIVpGeNOvbW06xwThaC8PDRECbLzpuzJI07cQtkspxaaMU3y95iDztx6l7Fy7uL+7Ew+3DufhNuEEyrzjogaqMX3UlUEStRDVQ05+MT+sz+T7dQfJKdDu3LDX6+jcOIj+bWvTMsJb7skWNYYk6gtIohaieik1mli4LYtvkg+QcuCUeX2jYA/6tY3g3qa1MDjK7GeiepNEfQFJ1EJUX38fyePb5IPMST1svifb0+DAg63CeOa2ujJaXFRbFclNMlpDCGGzYkI8ee++Jqwd2YFX744mzMdA3plSPl+xj7s+Ws7ctCPU8GsNISRRCyFsn5eLI0+1r8tfL93Bl4/GERXgxvHCswz5YTOPf72Bw7lnrB2iEFVGErUQotqw0+tIbBTIH0Pa8UJifRzt9Py5I4eOE5fz9ZoDGE1ydS1qHknUQohqx9Fez/OJUcx//lbiIrwpOmvkjbl/c/9na9iVLU/MEzWLJGohRLVVL8CdH5+O560ejXFzsmdTRi5dP17JR0m7KCkzWjs8ISqFJGohRLWm1+t45JYIkoa1J7FhAKVGxX+X7qbrx6vYePCktcMT4rpJohZC1AjBngamPhrH5Idb4OfmyJ6cQnp/lszo37ZRUFxq7fCEuGaSqIUQNYZOp6Nrk2CWDLuNPnGhKAXfJB/krokrWLI929rhCXFNJFELIWocLxdHPujdlO+faEOErwtZ+cU88c0GBs3YxLFz05MKUV1IohZC1FgJ9fxY+Hx7nr6tDnZ6HX9sOUrixOX8uCFTJkoR1YYkaiFEjWZwtGNkl4b8NiiBxrU8yDtTyss/b+E//7eOgyeKrB2eEP9KErUQ4qbQuJYncwYm8Ord0Tg76Fm95wSdJq3g8+V7KTOarB2eEJcliVoIcdOwt9PzVPu6LBranoR6vhSXmhi3YAfdJ69m2+E8a4cnxCVJohZC3HQifF357vE2jO/dBE+DA38fyaf75NWMm5/OmbMyUYqwLfbWDkAIIaxBp9Nxf1wYtzcI4M3f/2belqN8vmIfP27I5JY6vsTX9SW+ji/1AtzQ6XTWDlfcxCRRCyFuav7uTnz6cAt6Ns9m1JxtHMkrZsG2LBZsywLAz82JW+r4mBN3pJ+rJG5xQ0miFkIIoEPDQNrX92fLoVyS954ged8JNhw4xfHCEuZtOcq8LUcBCPRwIt58xe1HmI9BEreoUjpVw28mPHToEGFhYWRmZhIaGmrtcIQQ1UhJmZHUjFyS950gee8JNmfkcvYfI8RreRnKm8rr+lLLy2ClaEV1UpHcJIlaCCGuUnGpkU0HT5kTd2pmLmX/eAZ2uI/LBU3lfgR5OlspWmHLKpKbpOlbCCGukrODHW3r+dG2nh8Ap8+WseFAeeLeejiPjJOnyTh5mh83HAIg0s/VfMV9W31/PA0O1vwIohqSRC2EENfIxdGe9vX9aV/fH4CC4lKLxP33kTz2Hy9i//EiflifgaO9ng7RAXRvVos7ov1xsrez8icQ1YEkaiGEqCTuzg7cER3AHdEBAOSdKWX9/pMk7z3Bit3H2JNTaB5R7uFsT9cmwfRoVotWtX3Q62VAmrg0m07U48aN49dff2XHjh0YDAbatm3L+++/T4MGDawdmhBC/CtPgwN3NQrkrkaBKKXYfjSf31KP8FvqYbLzS/hhfSY/rM+klpeBe5uF0LN5LeoHuls7bGFjbHowWefOnXnwwQdp1aoVZWVlvPrqq2zbto3t27fj6up6VceQwWRCCFtjNCnW7TvB7M2HWbAti8KSMvO2RsEe9Ggewr1Na8lAtBqsxo76PnbsGAEBASxfvpz27dtf1T6SqIUQtqy41MjS9Bxmbz7MXztzzKPIdTpoW9eX7s1q0aVxEO7OMgitJqmxo77z8rRJ8318fKwciRBCVA5nBzu6Ngmma5NgThWd5Y+tR5mz+TAbDp5i9Z4TrN5zglFztpHYKJAezWpxW31/HO3lMQ03k2pzRW0ymbj33nvJzc1l1apVly1XUlJCSUmJ+f3hw4dp1KiRXFELIaqVzJOn+S31MLM3H2bvsfLnZnu5ONA1NpiezWvRMsJbZkWrpmpk0/ezzz7LggULWLVq1RU/1JgxY3jzzTcvWi+JWghRHSml+PtIPrM3H2Zu2hGOFZRfiIT5GOjetBbdm4XIw0OqmRqXqAcPHsxvv/3GihUriIyMvGJZuaIWQtRURpNizd7jzNl8hIXbjlJ0wSM5a3kZaF/fj/ZR/rSt64eni/Rp27Iak6iVUjz33HPMnj2bv/76i6ioqAofQwaTCSFqojNnjSSlZzNn82FW7T5uMQe5XgdNw7xoH+VP+/p+NA31wt5O+rVtSY1J1AMHDmTGjBn89ttvFvdOe3p6YjBc3cT3kqiFEDXd6bNlrNt3khW7j7Fy93H25BRabHd3tiehrh/tzl1xh/m4WClScV6NSdSX62+ZNm0a/fv3v6pjSKIWQtxsDueeYdXuY6zYfZxVu4+Td6bUYnuknyvtovxoF+VPfF1f3Jyq1Q1ANUKNSdSVQRK1EOJmZjQpth7OY+Uu7Wp7U8Ypiyd+2et1tIjwpv25xN24lid2Mp1plZNEfQFJ1EIIUa6guJTkvSdYufs4K3Yf4+CJ0xbbvV0cSKinNZG3q+9HsKc8X7sq1NgJT4QQQlwfd2cHOsYE0TEmCICDJ4q0pL3rGMl7T3DqdCnzthxl3pajANT2daFpmBdNQr1oFuZJTIgnzg7y1K8bSRK1EELcxCJ8XYnwdeU/t0RQajSRlpnLil1a//aWQ7kcOHGaAydO81vqEQDs9DoaBLrTNExL3E1CvYgKcJNR5VVImr6FEEJcUt7pUtIO5ZKWmUvaoVxSM/M4XlhyUTmDgx2xtTxpEup5LoF7EeptkAlYrkCavoUQQlw3TxcH2tf3p319f0Cb2+JoXjFpmbmkHsplS2YeWw/nUVhSxvoDJ1l/4KR5Xx9XRy1xh2qJu0moJ75uTtb6KNWaJGohhBBXRafTEeJlIMTLQJfYYEAbVb7vWCFph/LMV97pR/M5WXSWv3Ye46+dx8z7h3obaBrmRdNzCbxxLU9c5dawfyU1JIQQ4prZ6XVEBboTFehO75ZaE25JmZH0owXmxJ2WmcveY0UcOnWGQ6fO8Me5gWp6HdQPdKdpqJeWwMM8qR/ojoP0d1uQRC2EEKJSOdnb0excX/V5+cWlbDuUR+r5Pu/MPLLyi9mRVcCOrAJmbcgEwNlBT+MQbZBa0zBPmoV5Ee7jclP3d0uiFkIIUeU8nB1oW8+PtvX8zOuy84svuOrOI+1QLgXFZWw4eIoNB0+Zy3m5OJivus+PNPe7ifq7JVELIYSwikAPZ4t7uk0mxf4TReeuuHNJPZRH+pF8ck+XsnzXMZbvuri/u9m5BN64lgcujjUzpdXMTyWEEKLa0et11PV3o66/G71alPd378zS+rtTz1117z1W+K/93U1CPWkQVDP6uyVRCyGEsFlO9nY0CdVmRnskXlt3tf3djvZ6GgV70DTUk9hQbbR5HX+3ajeXuSRqIYQQ1cql+ruz8orNI8y3HMpjy6Fc8ovLSM3MJTUzFzgIgKujHTG1PC2St60PVpNELYQQotoL8nQmyDOITuf6u5VSHDxxmrRDuWw9lMeWQ3lsO5JH0Vkj6/efZP3+8slZPA0ONAn1PLdozeZBHs42k7wlUQshhKhxdDodtf1cqe3nSvdmtQBtcpa9xwrLr7oPa4PV8s6UsnL3cVbuPm7e39/dSbvqruVFkzBPmtSy3sxqkqiFEELcFOz0OuoHulM/0J3748IAOFtmYmdWAVsOa1Oiph3KZXdOIccKSliSnsOS9Bzz/rW8DLSO9OGjB5rd0LglUQshhLhpOdrriQ31JDbUk75ttHVnzhrZfjSPtHNzmacdymXfsSIO555h//GiGx6jJGohhBDiAgZHO1pG+NAywse8Lr+4lG2H8zCZbnw8kqiFEEKIf+Hh7EDbun7/XrAKVP87wYUQQogaTBK1EEIIYcMkUQshhBA2TBK1EEIIYcMkUQshhBA2rMaP+jadG0t/9OhRK0cihBBCaM7nJNNV3O9V4xN1dnY2AK1bt7ZyJEIIIYSl7OxswsPDr1hGp5RSNygeqygrK2Pz5s0EBgai119fS39BQQGNGjVi+/btuLu7V1KENZvUWcVJnVWc1FnFSZ1VXGXWmclkIjs7m+bNm2Nvf+Vr5hqfqCtTfn4+np6e5OXl4eHhYe1wqgWps4qTOqs4qbOKkzqrOGvVmQwmE0IIIWyYJGohhBDChkmirgAnJyfeeOMNnJys80zS6kjqrOKkzipO6qzipM4qzlp1Jn3UQgghhA2TK2ohhBDChkmiFkIIIWyYJGohhBDChkmiroDJkydTu3ZtnJ2dadOmDevXr7d2SDZr3LhxtGrVCnd3dwICAujRowc7d+60dljVxnvvvYdOp2Po0KHWDsWmHT58mP/85z/4+vpiMBiIjY1lw4YN1g7LZhmNRkaNGkVkZCQGg4G6devy1ltvIUOVLK1YsYJu3boREhKCTqdjzpw5FtuVUowePZrg4GAMBgOJiYns3r27yuKRRH2VZs2axbBhw3jjjTfYtGkTTZs2pVOnTuTk5Fg7NJu0fPlyBg0axNq1a0lKSqK0tJSOHTtSVFRk7dBsXkpKCp9//jlNmjSxdig27dSpUyQkJODg4MCCBQvYvn07H374Id7e3tYOzWa9//77TJkyhU8//ZT09HTef/99PvjgAz755BNrh2ZTioqKaNq0KZMnT77k9g8++ICPP/6Yzz77jHXr1uHq6kqnTp0oLi6umoCUuCqtW7dWgwYNMr83Go0qJCREjRs3zopRVR85OTkKUMuXL7d2KDatoKBARUVFqaSkJHXbbbep559/3toh2awRI0aoW2+91dphVCtdu3ZVAwYMsFjXq1cv1bdvXytFZPsANXv2bPN7k8mkgoKC1Pjx483rcnNzlZOTk/rhhx+qJAa5or4KZ8+eZePGjSQmJprX6fV6EhMTSU5OtmJk1UdeXh4APj4+Vo7Etg0aNIiuXbta/K6JS5s7dy5xcXHcf//9BAQE0Lx5c6ZOnWrtsGxa27ZtWbp0Kbt27QIgLS2NVatW0aVLFytHVn3s37+frKwsi/+jnp6etGnTpsryQY1/elZlOH78OEajkcDAQIv1gYGB7Nixw0pRVR8mk4mhQ4eSkJBA48aNrR2OzZo5cyabNm0iJSXF2qFUC/v27WPKlCkMGzaMV199lZSUFIYMGYKjoyP9+vWzdng26ZVXXiE/P5/o6Gjs7OwwGo2888479O3b19qhVRtZWVkAl8wH57dVNknUosoNGjSIbdu2sWrVKmuHYrMyMzN5/vnnSUpKwtnZ2drhVAsmk4m4uDjeffddAJo3b862bdv47LPPJFFfxo8//sj333/PjBkziImJITU1laFDhxISEiJ1ZsOk6fsq+Pn5YWdnZ3629XnZ2dkEBQVZKarqYfDgwcybN49ly5YRGhpq7XBs1saNG8nJyaFFixbY29tjb2/P8uXL+fjjj7G3t8doNFo7RJsTHBxMo0aNLNY1bNiQjIwMK0Vk+4YPH84rr7zCgw8+SGxsLI888ggvvPAC48aNs3Zo1cb5v/k3Mh9Ior4Kjo6OtGzZkqVLl5rXmUwmli5dSnx8vBUjs11KKQYPHszs2bP5888/iYyMtHZINq1Dhw5s3bqV1NRU8xIXF0ffvn1JTU3Fzs7O2iHanISEhItu+du1axcRERFWisj2nT59Gr3e8s++nZ0dJpPJShFVP5GRkQQFBVnkg/z8fNatW1dl+UCavq/SsGHD6NevH3FxcbRu3ZpJkyZRVFTEY489Zu3QbNKgQYOYMWMGv/32G+7u7ua+G09PTwwGg5Wjsz3u7u4X9d+7urri6+sr/fqX8cILL9C2bVveffdd+vTpw/r16/niiy/44osvrB2azerWrRvvvPMO4eHhxMTEsHnzZiZOnMiAAQOsHZpNKSwsZM+ePeb3+/fvJzU1FR8fH8LDwxk6dChvv/02UVFRREZGMmrUKEJCQujRo0fVBFQlY8lrqE8++USFh4crR0dH1bp1a7V27Vprh2SzgEsu06ZNs3Zo1YbcnvXvfv/9d9W4cWPl5OSkoqOj1RdffGHtkGxafn6+ev7551V4eLhydnZWderUUa+99poqKSmxdmg2ZdmyZZf8+9WvXz+llHaL1qhRo1RgYKBycnJSHTp0UDt37qyyeOTpWUIIIYQNkz5qIYQQwoZJohZCCCFsmCRqIYQQwoZJohZCCCFsmCRqIYQQwoZJohZCCCFsmCRqIYQQwoZJohZCCCFsmCRqIUSl0+l0zJkzx9phCFEjSKIWoobp378/Op3uoqVz587WDk0IcQ3koRxC1ECdO3dm2rRpFuucnJysFI0Q4nrIFbUQNZCTkxNBQUEWi7e3N6A1S0+ZMoUuXbpgMBioU6cOP//8s8X+W7du5c4778RgMODr68tTTz1FYWGhRZmvvvqKmJgYnJycCA4OZvDgwRbbjx8/Ts+ePXFxcSEqKoq5c+eat506dYq+ffvi7++PwWAgKirqoi8WQgiNJGohbkKjRo3ivvvuIy0tjb59+/Lggw+Snp4OQFFREZ06dcLb25uUlBR++uknlixZYpGIp0yZwqBBg3jqqafYunUrc+fOpV69ehbnePPNN+nTpw9btmzh7rvvpm/fvpw8edJ8/u3bt7NgwQLS09OZMmUKfn5+N64ChKhOquy5XEIIq+jXr5+ys7NTrq6uFss777yjlNIeQfrMM89Y7NOmTRv17LPPKqWU+uKLL5S3t7cqLCw0b//jjz+UXq9XWVlZSimlQkJC1GuvvXbZGAD1+uuvm98XFhYqQC1YsEAppVS3bt3UY489VjkfWIgaTvqohaiB7rjjDqZMmWKxzsfHx/w6Pj7eYlt8fDypqakApKen07RpU1xdXc3bExISMJlM7Ny5E51Ox5EjR+jQocMVY2jSpIn5taurKx4eHuTk5ADw7LPPct9997Fp0yY6duxIjx49aNu27TV9ViFqOknUQtRArq6uFzVFVxaDwXBV5RwcHCze63Q6TCYTAF26dOHgwYPMnz+fpKQkOnTowKBBg5gwYUKlxytEdSd91ELchNauXXvR+4YNGwLQsGFD0tLSKCoqMm9fvXo1er2eBg0a4O7uTu3atVm6dOl1xeDv70+/fv347rvvmDRpEl988cV1HU+ImkquqIWogUpKSsjKyrJYZ29vbx6w9dNPPxEXF8ett97K999/z/r16/m///s/APr27csbb7xBv379GDNmDMeOHeO5557jkUceITAwEIAxY8bwzDPPEBAQQJcuXSgoKGD16tU899xzVxXf6NGjadmyJTExMZSUlDBv3jzzFwUhhCVJ1ELUQAsXLiQ4ONhiXYMGDdixYwegjcieOXMmAwcOJDg4mB9++IFGjRoB4OLiwqJFi3j++edp1aoVLi4u3HfffUycONF8rH79+lFcXMxHH33ESy+9hJ+fH717977q+BwdHRk5ciQHDhzAYDDQrl07Zs6cWQmfXIiaR6eUUtYOQghx4+h0OmbPnk2PHj2sHYoQ4ipIH7UQQghhwyRRCyGEEDZM+qiFuMlIb5cQ1YtcUQshhBA2TBK1EEIIYcMkUQshhBA2TBK1EEIIYcMkUQshhBA2TBK1EEIIYcMkUQshhBA2TBK1EEIIYcMkUQshhBA27P8BshEQvle07B4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generation Strategies"
      ],
      "metadata": {
        "id": "iweExsNKsIVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(\"cpu\")\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmmDgx-On1xk",
        "outputId": "37c0d7f0-c8b9-4e94-ff63-e5e77a66a607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "token_ids = generate_text_simple(\n",
        " model=model,\n",
        " idx=text_to_token_ids(\"Every effort moves you,\", tokenizer),\n",
        " max_new_tokens=25,\n",
        " context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2r1astlsN5G",
        "outputId": "a07db444-2474-427a-8c41-14f2e0f8a389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you, that\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Temperature scaling** - It is just dividing logits by a numer greater than 0"
      ],
      "metadata": {
        "id": "zWKH4l2_uecJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding a probabilistic selection\n",
        "process to the next-token generation task"
      ],
      "metadata": {
        "id": "LSMH8W2avkQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {\n",
        " \"closer\": 0,\n",
        " \"every\": 1,\n",
        " \"effort\": 2,\n",
        " \"forward\": 3,\n",
        " \"inches\": 4,\n",
        " \"moves\": 5,\n",
        " \"pizza\": 6,\n",
        " \"toward\": 7,\n",
        " \"you\": 8,\n",
        "}\n",
        "inverse_vocab = {v: k for k, v in vocab.items()}"
      ],
      "metadata": {
        "id": "Iex2yw3kvn8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "assume the LLM is given the start context \"every effort moves you\" and gener\u0002ates the following next-token logits"
      ],
      "metadata": {
        "id": "SkKu0tXbv2rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next_token_logits = torch.tensor(\n",
        " [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
        ")"
      ],
      "metadata": {
        "id": "eTAmgV5UvuXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we convert the logits into\n",
        "probabilities via the softmax function and obtain the token ID corresponding to the\n",
        "generated token"
      ],
      "metadata": {
        "id": "MtWxIMjYwJYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probas = torch.softmax(next_token_logits, dim=0)\n",
        "next_token_id = torch.argmax(probas).item()\n",
        "print(inverse_vocab[next_token_id])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxRUq7Rwv6Ei",
        "outputId": "ad7acde3-1cee-4193-a862-10f04fad9c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To implement a probabilistic sampling process, we can now replace argmax with\n",
        "the multinomial function"
      ],
      "metadata": {
        "id": "wsmQRePiwT96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
        "print(inverse_vocab[next_token_id])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R58S0XtwV8F",
        "outputId": "a5012859-4cca-449d-c3a9-8627c61e57a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The multinomial\n",
        "function samples the next token proportional to its probability score"
      ],
      "metadata": {
        "id": "B2xAaf6XwiGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_with_temperature(logits, temperature):\n",
        " scaled_logits = logits / temperature\n",
        " return torch.softmax(scaled_logits, dim=0)"
      ],
      "metadata": {
        "id": "t6vW3pMTsc8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the original probabilities alongside proba\u0002bilities scaled with different temperature values"
      ],
      "metadata": {
        "id": "v1IUL7Mbw841"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temperatures = [1, 0.1, 5] # original,lower and higher confidence\n",
        "scaled_probas = [softmax_with_temperature(next_token_logits, T)\n",
        " for T in temperatures]\n",
        "x = torch.arange(len(vocab))\n",
        "bar_width = 0.15\n",
        "fig, ax = plt.subplots(figsize=(5, 3))\n",
        "for i, T in enumerate(temperatures):\n",
        " rects = ax.bar(x + i * bar_width, scaled_probas[i],\n",
        "  bar_width, label=f'Temperature = {T}')\n",
        "ax.set_ylabel('Probability')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "4HcY1emiuwZV",
        "outputId": "35f2f689-f841-4c8b-f0c8-47afa36b37a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Top-k sampling**"
      ],
      "metadata": {
        "id": "aVPPmiyYzFkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can restrict the\n",
        "sampled tokens to the top-k most likely tokens and exclude all other tokens from the\n",
        "selection process by masking their probability scores,"
      ],
      "metadata": {
        "id": "envEaPq2zRBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_k = 3 # selection of the tokens with the largest logit values\n",
        "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
        "print(\"Top logits:\", top_logits)\n",
        "print(\"Top positions:\", top_pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kaNXaTHwz3K",
        "outputId": "6272a338-544f-4e6d-a43d-b5624d48938e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
            "Top positions: tensor([3, 7, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "set the logit values of tokens that are\n",
        "below the lowest logit value within our top-three selection to negative infinity using where function"
      ],
      "metadata": {
        "id": "83b0COLsz2zJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_logits = torch.where(\n",
        " condition=next_token_logits < top_logits[-1], #identifies logits less than the minimum in top 3\n",
        " input=torch.tensor(float('-inf')), #assigns -inf to the lower logits\n",
        " other=next_token_logits #retains original logits for other tokens\n",
        ")\n",
        "print(new_logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0DjVp3izoAw",
        "outputId": "b8d768d9-7e68-425f-ba4c-6814c6c0aa9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topk_probas = torch.softmax(new_logits, dim=0)\n",
        "print(\"Probabilities: \",topk_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii_O7Nju0aJp",
        "outputId": "3fb3674e-39f8-4539-d48d-8cc2fb75ea81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilities:  tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modifying text generation function** - Combining top-k and temperature scaling to text generation\n"
      ],
      "metadata": {
        "id": "kNPc6bQXEXxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, idx, max_new_tokens, context_size,\n",
        "             temperature=0.0, top_k=None, eos_id=None):\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        if top_k is not None:\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(\n",
        "                logits < min_val,\n",
        "                torch.tensor(float('-inf')).to(logits.device),\n",
        "                logits\n",
        "            )\n",
        "\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "            if idx_next == eos_id:\n",
        "                break\n",
        "\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # Append the new token\n",
        "\n",
        "    return idx  # Function returns after completing the loop"
      ],
      "metadata": {
        "id": "jPB-kbzC0fw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "token_ids = generate(\n",
        " model=model,\n",
        " idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        " max_new_tokens=45,\n",
        " context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        " top_k=20,\n",
        " temperature=1.3\n",
        ")\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WsUt8XkHQQV",
        "outputId": "7b65fe9a-2c08-4002-9be8-dbd08e6a1298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you know I Gisburn said between I couldn't want to now.\"\n",
            "\n",
            "It again.\"But a year to Jack, when I've by the house back his glory, as up at the sketch of their sav rich me\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weight saving & Loading"
      ],
      "metadata": {
        "id": "I2MMiIqGMq_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving both the model and optimizer *state_dict* contents."
      ],
      "metadata": {
        "id": "3sckPg65OqPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        " \"model_state_dict\": model.state_dict(),\n",
        " \"optimizer_state_dict\": optimizer.state_dict(),\n",
        " },\n",
        " \"model_and_optimizer.pth\"\n",
        ")"
      ],
      "metadata": {
        "id": "YOflSUOTHSLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*state_dict()* - a dictionary mapping each layer to its parameters.\n",
        "*model.pth* - the filename where the state_dict is saved, the .pth extension is a\n",
        "convention for PyTorch files,"
      ],
      "metadata": {
        "id": "sf4r2lRUNHd5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting to drive so that I can import the model for finetuning"
      ],
      "metadata": {
        "id": "ndokJTUiliyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the saved model and optimizer states to GPTModel instance**"
      ],
      "metadata": {
        "id": "PqsQc6N1Nopt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "model.train();"
      ],
      "metadata": {
        "id": "3GY38r54NR6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20a0548f-b3a5-41ba-9953-f3bf2855b0ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-62-2e32dcdb1060>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading pretrained weights from OpenAI"
      ],
      "metadata": {
        "id": "82MRvvyNQGyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow>=2.15.0 tqdm>=4.66"
      ],
      "metadata": {
        "id": "AKH_3xFaNypZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "url = (\n",
        " \"https://raw.githubusercontent.com/rasbt/\"\n",
        " \"LLMs-from-scratch/main/ch05/\"\n",
        " \"01_main-chapter-code/gpt_download.py\"\n",
        ")\n",
        "filename = url.split('/')[-1]\n",
        "urllib.request.urlretrieve(url, filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1hVVvCuQu7E",
        "outputId": "2f8b9fe3-5bb2-4747-c060-f93373673e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('gpt_download.py', <http.client.HTTPMessage at 0x7d19e248e6d0>)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "settings, params = download_and_load_gpt2(\n",
        " model_size=\"124M\", models_dir=\"gpt2\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdnAoq_OQzl0",
        "outputId": "2fbbea55-26d4-42a6-e3cb-b7fbe0744783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 37.4kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 3.60MiB/s]\n",
            "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 126kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:34<00:00, 14.3MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 7.08MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 2.29MiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 2.22MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "inspect the contents\n",
        "of settings and params"
      ],
      "metadata": {
        "id": "jJpm2ROHR-_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Settings:\", settings)\n",
        "print(\"Parameter dictionary keys:\", params.keys())"
      ],
      "metadata": {
        "id": "kNo9OHBmRFF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46884de5-ab77-4f0c-bac2-10550d553d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
            "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The weights of the token embedding layer"
      ],
      "metadata": {
        "id": "tm9OK8cKSfb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(params[\"wte\"])\n",
        "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
      ],
      "metadata": {
        "id": "endypKrUSCSs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "253488bf-9281-4e35-ed39-799dfb0df70d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
            "   0.04531523]\n",
            " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
            "   0.04318958]\n",
            " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
            "  -0.08785918]\n",
            " ...\n",
            " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
            "  -0.06952604]\n",
            " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
            "  -0.02245961]\n",
            " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
            "   0.12067825]]\n",
            "Token embedding weight tensor dimensions: (50257, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_configs = {\n",
        " \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        " \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        " \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        " \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}"
      ],
      "metadata": {
        "id": "a_DXnEYFSabe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt2-small (124M)\"\n",
        "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
        "NEW_CONFIG.update(model_configs[model_name])"
      ],
      "metadata": {
        "id": "-WpRj2g-S630"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NEW_CONFIG.update({\"context_length\": 1024})"
      ],
      "metadata": {
        "id": "hSDdJcGaTEQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NEW_CONFIG.update({\"qkv_bias\": True})"
      ],
      "metadata": {
        "id": "SBvdfSPOTHQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt = GPTModel(NEW_CONFIG)\n",
        "gpt.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8qAdB7CTPE6",
        "outputId": "177f02f3-7da6-4d33-fa91-e0c91db67f5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "assign utility function that checks whether two tensors or arrays (left and\n",
        "right) have the same dimensions or shape and returns the right tensor as trainable\n",
        "PyTorch parameters"
      ],
      "metadata": {
        "id": "nat1RG1kT2U2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assign(left, right):\n",
        " if left.shape != right.shape:\n",
        "  raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
        "  \"Right: {right.shape}\"\n",
        "  )\n",
        " return torch.nn.Parameter(torch.tensor(right))"
      ],
      "metadata": {
        "id": "_ZQSPemnTSxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading OpenAI weights into GPT model code**"
      ],
      "metadata": {
        "id": "oR3epLhuVUKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "  gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "  gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "  for b in range(len(params[\"blocks\"])):\n",
        "    q_w, k_w, v_w = np.split(\n",
        "      (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "    gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "      gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "    gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "      gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "    gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "      gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "    q_b, k_b, v_b = np.split(\n",
        "      (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "    gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "      gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "    gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "      gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "    gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "      gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "    gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "      gpt.trf_blocks[b].att.out_proj.weight,\n",
        "      params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "      gpt.trf_blocks[b].att.out_proj.bias,\n",
        "      params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "    gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "      gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "      params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "      gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "      params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "\n",
        "    gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "      gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "      params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "      gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "      params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "    gpt.trf_blocks[b].norm1.scale = assign(\n",
        "      gpt.trf_blocks[b].norm1.scale,\n",
        "      params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "    gpt.trf_blocks[b].norm1.shift = assign(\n",
        "      gpt.trf_blocks[b].norm1.shift,\n",
        "      params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "\n",
        "  gpt.trf_blocks[b].norm2.scale = assign(\n",
        "    gpt.trf_blocks[b].norm2.scale,\n",
        "    params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "  gpt.trf_blocks[b].norm2.shift = assign(\n",
        "    gpt.trf_blocks[b].norm2.shift,\n",
        "    params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "  gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "  gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "  gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
      ],
      "metadata": {
        "id": "AJeqFhEnTu8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_weights_into_gpt(gpt, params)\n",
        "gpt.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRCKgudoVgFS",
        "outputId": "bf7ab4ad-0c6a-4e87-b009-e1ca2ed2bc95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "token_ids = generate(\n",
        " model=gpt,\n",
        " idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
        " max_new_tokens=30,\n",
        " context_size=NEW_CONFIG[\"context_length\"],\n",
        " top_k=50,\n",
        " temperature=1.4\n",
        ")\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "Iw3MD8-OV00l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47d03bfd-c2e7-4f80-a5e6-d52a4dbfe97a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you the I a in for a a from it, of\n",
            " all if there she at the that much a I to the the that that, the a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-U16ue54V6hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning"
      ],
      "metadata": {
        "id": "KnXoF5M9tcy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "def download_and_unzip_spam_data(\n",
        " url, zip_path, extracted_path, data_file_path):\n",
        " if data_file_path.exists():\n",
        "  print(f\"{data_file_path} already exists. Skipping download \"\n",
        "  \"and extraction.\"\n",
        "  )\n",
        "  return\n",
        "\n",
        "with urllib.request.urlopen(url) as response: #Download File\n",
        " with open(zip_path, \"wb\") as out_file:\n",
        "  out_file.write(response.read())\n",
        "\n",
        " with zipfile.ZipFile(zip_path, \"r\") as zip_ref: # Unzips the file\n",
        "  zip_ref.extractall(extracted_path)\n",
        "\n",
        " original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        " os.rename(original_file_path, data_file_path)  #Adds a .tsv extension\n",
        " print(f\"File downloaded and saved as {data_file_path}\")\n",
        "\n",
        "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETM4f4vNtgtz",
        "outputId": "3e871772-8c20-4c69-e0c8-e981acda5875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\n",
            "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\n",
        " data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"]\n",
        ")\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VtvxwECtonU",
        "outputId": "c5af5f77-0fd1-403d-fd69-a3ebfadc535b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Label                                               Text\n",
            "0      ham  Go until jurong point, crazy.. Available only ...\n",
            "1      ham                      Ok lar... Joking wif u oni...\n",
            "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3      ham  U dun say so early hor... U c already then say...\n",
            "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
            "...    ...                                                ...\n",
            "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
            "5568   ham               Will ü b going to esplanade fr home?\n",
            "5569   ham  Pity, * was in mood for that. So...any other s...\n",
            "5570   ham  The guy did some bitching but I acted like i'd...\n",
            "5571   ham                         Rofl. Its true to its name\n",
            "\n",
            "[5572 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eifj-rpHtsZN",
        "outputId": "1e024d88-f601-4dbb-fb56-9e4649a77053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_balanced_dataset(df):\n",
        " num_spam = df[df[\"Label\"] == \"spam\"].shape[0] # Counts spam instances\n",
        " ham_subset = df[df[\"Label\"] == \"ham\"].sample(\n",
        " num_spam, random_state=123\n",
        " )\n",
        "\n",
        " balanced_df = pd.concat([\n",
        " ham_subset, df[df[\"Label\"] == \"spam\"]\n",
        " ])\n",
        " return balanced_df\n",
        "\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "print(balanced_df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb17TojltwJo",
        "outputId": "572cfa1c-5029-4b6d-af4a-81555a4fc4b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     747\n",
            "spam    747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
      ],
      "metadata": {
        "id": "9uz9FKuotylC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_split(df, train_frac, validation_frac):\n",
        "\n",
        " df = df.sample(\n",
        " frac=1, random_state=123\n",
        " ).reset_index(drop=True) #Shuffles the entire dataframe\n",
        " train_end = int(len(df) * train_frac) #Calculate split indices\n",
        " validation_end = train_end + int(len(df) * validation_frac)\n",
        "\n",
        " #Split dataframe\n",
        " train_df = df[:train_end]\n",
        " validation_df = df[train_end:validation_end]\n",
        " test_df = df[validation_end:]\n",
        " return train_df, validation_df, test_df\n",
        "\n",
        "train_df, validation_df, test_df = random_split(\n",
        " balanced_df, 0.7, 0.1)"
      ],
      "metadata": {
        "id": "1YQp93Vxt1wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ],
      "metadata": {
        "id": "aBN8E4uqt5B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGwgKsUjt7e2",
        "outputId": "66f6d4ab-964d-4a1c-fe74-ec8584b4f510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Smm3dGhtuBFO",
        "outputId": "9334f5d6-7943-4880-f2e8-84b9ca5c2e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "gxAz7cD-uESY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpamDataset(Dataset):\n",
        " def __init__(self, csv_file, tokenizer, max_length=None,\n",
        " pad_token_id=50256):\n",
        "  self.data = pd.read_csv(csv_file)\n",
        "\n",
        " #Pretokenizes text\n",
        "  self.encoded_texts = [\n",
        "  tokenizer.encode(text) for text in self.data[\"Text\"]\n",
        "  ]\n",
        "\n",
        "  if max_length is None:\n",
        "    self.max_length = self._longest_encoded_length()\n",
        "  else:\n",
        "    self.max_length = max_length\n",
        "\n",
        "  #Truncates sequences if they are longer than max length\n",
        "  self.encoded_texts = [\n",
        "  encoded_text[:self.max_length]\n",
        "  for encoded_text in self.encoded_texts\n",
        "  ]\n",
        "\n",
        "  self.encoded_texts = [\n",
        "    encoded_text + [pad_token_id] *\n",
        "    (self.max_length - len(encoded_text))\n",
        "    for encoded_text in self.encoded_texts\n",
        "    ]\n",
        "\n",
        " def __getitem__(self, index):\n",
        "  encoded = self.encoded_texts[index]\n",
        "  label = self.data.iloc[index][\"Label\"]\n",
        "  return (\n",
        "    torch.tensor(encoded, dtype=torch.long),\n",
        "    torch.tensor(label, dtype=torch.long)\n",
        "    )\n",
        "\n",
        " def __len__(self):\n",
        "  return len(self.data)\n",
        "\n",
        " def _longest_encoded_length(self):\n",
        "  max_length = 0\n",
        "  for encoded_text in self.encoded_texts:\n",
        "    encoded_length = len(encoded_text)\n",
        "    if encoded_length > max_length:\n",
        "      max_length = encoded_length\n",
        "  return max_length"
      ],
      "metadata": {
        "id": "yCN9qIzwuG3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SpamDataset(\n",
        " csv_file=\"train.csv\",\n",
        " max_length=None,\n",
        " tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "_RFZBDxbuLPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset.max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp9UQ_-xuN2g",
        "outputId": "3aa4d398-34ee-4942-e6b5-f1a10ad3833b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = SpamDataset(\n",
        " csv_file=\"validation.csv\",\n",
        " max_length=train_dataset.max_length,\n",
        " tokenizer=tokenizer\n",
        ")\n",
        "test_dataset = SpamDataset(\n",
        " csv_file=\"test.csv\",\n",
        " max_length=train_dataset.max_length,\n",
        " tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "dZbpuTSCuQNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "torch.manual_seed(123)\n",
        "train_loader = DataLoader(\n",
        " dataset=train_dataset,\n",
        " batch_size=batch_size,\n",
        " shuffle=True,\n",
        " num_workers=num_workers,\n",
        " drop_last=True,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        " dataset=val_dataset,\n",
        " batch_size=batch_size,\n",
        " num_workers=num_workers,\n",
        " drop_last=False,\n",
        ")\n",
        "test_loader = DataLoader(\n",
        " dataset=test_dataset,\n",
        " batch_size=batch_size,\n",
        " num_workers=num_workers,\n",
        " drop_last=False,\n",
        ")"
      ],
      "metadata": {
        "id": "xLlZ1b16uS9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_batch, target_batch in train_loader:\n",
        " pass\n",
        "print(\"Input batch dimensions:\", input_batch.shape)\n",
        "print(\"Label batch dimensions\", target_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2a1IEoiuWcB",
        "outputId": "0cbc3ff9-9a3c-40ba-b26e-ccac08f0a6e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch dimensions: torch.Size([8, 120])\n",
            "Label batch dimensions torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EExQZHwfuZrg",
        "outputId": "cd64224e-21ab-4bd6-89f9-397037235bbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 training batches\n",
            "19 validation batches\n",
            "38 test batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initializing pretrained weights**"
      ],
      "metadata": {
        "id": "VnHvGROqudCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "INPUT_PROMPT = \"Every effort moves\""
      ],
      "metadata": {
        "id": "uO4gNz7HucZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_CONFIG = {\n",
        " \"vocab_size\": 50257,\n",
        " \"context_length\": 1024,\n",
        " \"drop_rate\": 0.0,\n",
        " \"qkv_bias\": True\n",
        "}\n",
        "model_configs = {\n",
        " \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        " \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        " \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        " \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
      ],
      "metadata": {
        "id": "GB0iNB-wulgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(\n",
        " model_size=model_size, models_dir=\"gpt2\"\n",
        ")\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_fc3t_7uonS",
        "outputId": "ca70d535-0ce6-4326-db15-ed051ee4d15f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
            "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = \"Every effort moves you\"\n",
        "token_ids = generate_text_simple(\n",
        " model=model,\n",
        " idx=text_to_token_ids(text_1, tokenizer),\n",
        " max_new_tokens=25,\n",
        " context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jErPIIlYu1xM",
        "outputId": "9b7ecfc4-5287-4e94-a49a-dae084de3db6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every effort moves you the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = (\n",
        " \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
        " \" 'You are a winner you have been specially\"\n",
        " \" selected to receive $1000 cash or a $2000 award.'\"\n",
        ")\n",
        "token_ids = generate_text_simple(\n",
        " model=model,\n",
        " idx=text_to_token_ids(text_2, tokenizer),\n",
        " max_new_tokens=23,\n",
        " context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2JhYcvnxy8P",
        "outputId": "4b1dd210-a73c-41b2-a281-606cbc54a148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.' the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding classification head**"
      ],
      "metadata": {
        "id": "FqvJf2soyecP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Architecture"
      ],
      "metadata": {
        "id": "CGFyvtkozLAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng-yWcEzyUp5",
        "outputId": "f086c873-3408-4f7c-fbbd-d292e70ca803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freeze the model"
      ],
      "metadata": {
        "id": "NXkyrho1z-qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        " param.requires_grad = False"
      ],
      "metadata": {
        "id": "9E3D7h59zRM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding a classification layer**"
      ],
      "metadata": {
        "id": "yl3G85nEpSrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "num_classes = 2\n",
        "model.out_head = torch.nn.Linear(\n",
        " in_features=BASE_CONFIG[\"emb_dim\"],\n",
        " out_features=num_classes\n",
        ")"
      ],
      "metadata": {
        "id": "ng1MYNOs0DCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "make the final LayerNorm and last transformer block trainable"
      ],
      "metadata": {
        "id": "faDWDOj8qaXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.trf_blocks[-1].parameters():\n",
        " param.requires_grad = True\n",
        "for param in model.final_norm.parameters():\n",
        " param.requires_grad = True"
      ],
      "metadata": {
        "id": "CTodtCLap5Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer.encode(\"Do you have time\")\n",
        "inputs = torch.tensor(inputs).unsqueeze(0)\n",
        "print(\"Inputs:\", inputs)\n",
        "print(\"Inputs dimensions:\", inputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fv8Gvcrq3pW",
        "outputId": "0983bb79-017d-4ad0-d3da-f59ecc237842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs: tensor([[5211,  345,  423,  640]])\n",
            "Inputs dimensions: torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ayBg9DMXrE3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pass the encoded token IDs to the model"
      ],
      "metadata": {
        "id": "AdoSK_BJrHvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        " outputs = model(inputs)\n",
        "print(\"Outputs:\\n\", outputs)\n",
        "print(\"Outputs dimensions:\", outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E43L59pprGtN",
        "outputId": "19c28e81-6bb4-4c13-ff8f-cf07242143c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs:\n",
            " tensor([[[0.3708, 1.2060],\n",
            "         [0.2238, 1.4616],\n",
            "         [0.2839, 1.4423],\n",
            "         [0.2767, 1.3516]]])\n",
            "Outputs dimensions: torch.Size([1, 4, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Last output token:\", outputs[:, -1, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FALaR0sCriVl",
        "outputId": "b19a196a-3840-4a52-fe44-fb9d74d41301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last output token: tensor([[0.2767, 1.3516]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "last token in a sequence accu\u0002mulates the most information since it is the only token with access to data from all the\n",
        "previous tokens. Therefore, in our spam classification task, we focus on this last token\n",
        "during the fine-tuning process."
      ],
      "metadata": {
        "id": "ge4wzNtTsjG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "83NxYq1pq3Bk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calaculating classification loss and accuracy"
      ],
      "metadata": {
        "id": "AY9ECXi6tBr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtain class label"
      ],
      "metadata": {
        "id": "A5r7k4sruW5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits = outputs[:, -1, :]\n",
        "label = torch.argmax(logits)\n",
        "print(\"Class label:\", label.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOcMUsV8tJpg",
        "outputId": "c62cf282-16be-4fd4-c34d-41b52ae3858a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "  model.eval()\n",
        "  correct_predictions, num_examples = 0, 0\n",
        "  if num_batches is None:\n",
        "    num_batches = len(data_loader)\n",
        "  else:\n",
        "    num_batches = min(num_batches, len(data_loader))\n",
        "  for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "    if i < num_batches:\n",
        "      input_batch = input_batch.to(device)\n",
        "      target_batch = target_batch.to(device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        logits = model(input_batch)[:, -1, :]\n",
        "      predicted_labels = torch.argmax(logits, dim=-1)\n",
        "      num_examples += predicted_labels.shape[0]\n",
        "      correct_predictions += (\n",
        "          (predicted_labels == target_batch).sum().item()\n",
        "  )\n",
        "    else:\n",
        "      break\n",
        "  return correct_predictions / num_examples"
      ],
      "metadata": {
        "id": "N-gIWcfNuaGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "classification accuracies across various datasets"
      ],
      "metadata": {
        "id": "kYUSX4HWRqd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "torch.manual_seed(123)\n",
        "train_accuracy = calc_accuracy_loader(\n",
        " train_loader, model, device, num_batches=10\n",
        ")\n",
        "val_accuracy = calc_accuracy_loader(\n",
        " val_loader, model, device, num_batches=10\n",
        ")\n",
        "test_accuracy = calc_accuracy_loader(\n",
        " test_loader, model, device, num_batches=10\n",
        ")\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPOJRmcCRUPR",
        "outputId": "d7e077ff-2ea2-4b46-ea34-e97af9626f2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 46.25%\n",
            "Validation accuracy: 45.00%\n",
            "Test accuracy: 48.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To improve the prediction accuracies, we need to fine-tune the model."
      ],
      "metadata": {
        "id": "DzLZ9WynRx_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        " input_batch = input_batch.to(device)\n",
        " target_batch = target_batch.to(device)\n",
        " logits = model(input_batch)[:, -1, :]\n",
        " loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
        " return loss"
      ],
      "metadata": {
        "id": "73mAEePMRinv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the calc_loss_batch function to compute the loss for a single batch obtained\n",
        "from the previously defined data loaders."
      ],
      "metadata": {
        "id": "GXXUlMn7TFcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating classification loss**"
      ],
      "metadata": {
        "id": "Z0qh1F-1TNo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        " total_loss = 0.\n",
        " if len(data_loader) == 0:\n",
        "  return float(\"nan\")\n",
        " elif num_batches is None:\n",
        "  num_batches = len(data_loader)\n",
        " else:\n",
        "  num_batches = min(num_batches, len(data_loader))\n",
        " for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "  if i < num_batches:\n",
        "    loss = calc_loss_batch(\n",
        "    input_batch, target_batch, model, device\n",
        "    )\n",
        "    total_loss += loss.item()\n",
        "  else:\n",
        "    break\n",
        " return total_loss / num_batches"
      ],
      "metadata": {
        "id": "x78Q9qwHTEmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "compute the initial loss for each\n",
        "data set"
      ],
      "metadata": {
        "id": "lVD5ZBGeT1v7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        " train_loss = calc_loss_loader(\n",
        " train_loader, model, device, num_batches=5\n",
        " )\n",
        " val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        " test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
        "print(f\"Training loss: {train_loss:.3f}\")\n",
        "print(f\"Validation loss: {val_loss:.3f}\")\n",
        "print(f\"Test loss: {test_loss:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u20bN6gTZxe",
        "outputId": "8fe65abb-5574-4a1c-8070-e3e9ea3277c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.767\n",
            "Validation loss: 0.785\n",
            "Test loss: 0.741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning the model on supervised data"
      ],
      "metadata": {
        "id": "Lw2V5A-GUDSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifier_simple(\n",
        " model, train_loader, val_loader, optimizer, device,\n",
        " num_epochs, eval_freq, eval_iter):\n",
        "\n",
        "  train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "  examples_seen, global_step = 0, -1\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      for input_batch, target_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = calc_loss_batch(\n",
        "        input_batch, target_batch, model, device\n",
        "        )\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        examples_seen += input_batch.shape[0]\n",
        "        global_step += 1\n",
        "\n",
        "        if global_step % eval_freq == 0:\n",
        "          train_loss, val_loss = evaluate_model(\n",
        "          model, train_loader, val_loader, device, eval_iter)\n",
        "          train_losses.append(train_loss)\n",
        "          val_losses.append(val_loss)\n",
        "          print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "          f\"Train loss {train_loss:.3f}, \"\n",
        "          f\"Val loss {val_loss:.3f}\"\n",
        "          )\n",
        "\n",
        "      train_accuracy = calc_accuracy_loader(\n",
        "        train_loader, model, device, num_batches=eval_iter\n",
        "        )\n",
        "      val_accuracy = calc_accuracy_loader(\n",
        "        val_loader, model, device, num_batches=eval_iter\n",
        "        )\n",
        "\n",
        "      print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "      print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "      train_accs.append(train_accuracy)\n",
        "      val_accs.append(val_accuracy)\n",
        "\n",
        "  return train_losses, val_losses, train_accs, val_accs, examples_seen"
      ],
      "metadata": {
        "id": "nN-4_clhT6Er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        " model.eval()\n",
        " with torch.no_grad():\n",
        "  train_loss = calc_loss_loader(\n",
        "    train_loader, model, device, num_batches=eval_iter\n",
        "    )\n",
        "  val_loss = calc_loss_loader(\n",
        "    val_loader, model, device, num_batches=eval_iter\n",
        "    )\n",
        " model.train()\n",
        "\n",
        " return train_loss, val_loss"
      ],
      "metadata": {
        "id": "oNXsmv96PwOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "torch.manual_seed(123)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = \\\n",
        "  train_classifier_simple(\n",
        "  model, train_loader, val_loader, optimizer, device,\n",
        "  num_epochs=num_epochs, eval_freq=50,\n",
        "  eval_iter=5\n",
        "  )\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsmuKvAxQIe4",
        "outputId": "8a08cd80-5da3-46f5-cd2d-9865fb5c77c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 0.724, Val loss 0.761\n",
            "Ep 1 (Step 000050): Train loss 0.642, Val loss 0.651\n",
            "Ep 1 (Step 000100): Train loss 0.569, Val loss 0.616\n",
            "Training accuracy: 52.50% | Validation accuracy: 62.50%\n",
            "Ep 2 (Step 000150): Train loss 0.584, Val loss 0.561\n",
            "Ep 2 (Step 000200): Train loss 0.508, Val loss 0.507\n",
            "Ep 2 (Step 000250): Train loss 0.457, Val loss 0.466\n",
            "Training accuracy: 80.00% | Validation accuracy: 82.50%\n",
            "Ep 3 (Step 000300): Train loss 0.387, Val loss 0.414\n",
            "Ep 3 (Step 000350): Train loss 0.395, Val loss 0.393\n",
            "Training accuracy: 85.00% | Validation accuracy: 87.50%\n",
            "Ep 4 (Step 000400): Train loss 0.224, Val loss 0.378\n",
            "Ep 4 (Step 000450): Train loss 0.413, Val loss 0.348\n",
            "Ep 4 (Step 000500): Train loss 0.339, Val loss 0.369\n",
            "Training accuracy: 92.50% | Validation accuracy: 85.00%\n",
            "Ep 5 (Step 000550): Train loss 0.341, Val loss 0.338\n",
            "Ep 5 (Step 000600): Train loss 0.525, Val loss 0.320\n",
            "Training accuracy: 92.50% | Validation accuracy: 85.00%\n",
            "Ep 6 (Step 000650): Train loss 0.305, Val loss 0.325\n",
            "Ep 6 (Step 000700): Train loss 0.398, Val loss 0.348\n",
            "Ep 6 (Step 000750): Train loss 0.320, Val loss 0.310\n",
            "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
            "Ep 7 (Step 000800): Train loss 0.401, Val loss 0.335\n",
            "Ep 7 (Step 000850): Train loss 0.203, Val loss 0.307\n",
            "Ep 7 (Step 000900): Train loss 0.345, Val loss 0.315\n",
            "Training accuracy: 92.50% | Validation accuracy: 87.50%\n",
            "Ep 8 (Step 000950): Train loss 0.403, Val loss 0.308\n",
            "Ep 8 (Step 001000): Train loss 0.356, Val loss 0.312\n",
            "Training accuracy: 95.00% | Validation accuracy: 87.50%\n",
            "Ep 9 (Step 001050): Train loss 0.226, Val loss 0.333\n",
            "Ep 9 (Step 001100): Train loss 0.335, Val loss 0.293\n",
            "Ep 9 (Step 001150): Train loss 0.341, Val loss 0.308\n",
            "Training accuracy: 82.50% | Validation accuracy: 87.50%\n",
            "Ep 10 (Step 001200): Train loss 0.294, Val loss 0.280\n",
            "Ep 10 (Step 001250): Train loss 0.276, Val loss 0.267\n",
            "Training accuracy: 97.50% | Validation accuracy: 87.50%\n",
            "Training completed in 105.23 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "plot the loss function for the training and validation set"
      ],
      "metadata": {
        "id": "IJae2P7CYTR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_values(\n",
        "    epochs_seen, examples_seen, train_values, val_values,\n",
        "    label=\"loss\"):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "    ax1.plot(\n",
        "    epochs_seen, val_values, linestyle=\"-.\",\n",
        "    label=f\"Validation {label}\"\n",
        "    )\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        "\n",
        "    ax2 = ax1.twiny()\n",
        "    ax2.plot(examples_seen, train_values, alpha=0)\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "    fig.tight_layout()\n",
        "    plt.savefig(f\"{label}-plot.pdf\")\n",
        "    plt.show()\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
      ],
      "metadata": {
        "id": "TmpeLsWRQu5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "ea3fc8d6-e40a-4d59-ac6b-ab4d7406f48d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "plot the classification accuracies"
      ],
      "metadata": {
        "id": "QOKXEl6va4l3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
        "plot_values(\n",
        " epochs_tensor, examples_seen_tensor, train_accs, val_accs,\n",
        " label=\"accuracy\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "8PQ-uF4fYNnq",
        "outputId": "75547484-257e-473e-c7b8-5020c69f40b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAZxhJREFUeJzt3Xd4U9UbwPFvuvegpRMoq+wChdKyZEsZIiCI7DIcIFMciDJURBQVUVQQlKGyRAH5iYJQQDYUSsto2aNltGWVDqAjub8/AoHQFhpom7R9P8+Tx+Tec2/eHGrenHvOPUelKIqCEEIIIUySmbEDEEIIIUTeJFELIYQQJkwStRBCCGHCJFELIYQQJkwStRBCCGHCJFELIYQQJkwStRBCCGHCJFELIYQQJkwStRBCCGHCJFELIfKlVatWjB071thhCFHqSKIWoogMGjQIlUqV49GhQwdjhyaEMGEWxg5AiNKkQ4cOLFy4UG+btbW1kaIRQhQH0qIWoghZW1vj5eWl93B1dQVg69atWFlZsX37dl35GTNm4OHhQWJiIgDr16+nefPmuLi44ObmxnPPPcfp06d15c+dO4dKpeK3337jmWeewdbWlkaNGnHixAkiIiIICgrCwcGBjh07cuXKFd1xgwYNolu3bnz44YeULVsWJycnhg0bRmZmZp6fJSMjg7feegtfX1/s7e0JCQlh69atuv3nz5+nS5cuuLq6Ym9vT+3atfn777/zPN/333+Pv78/NjY2eHp60rNnT90+jUbD9OnTqVSpEra2ttSrV4/ff/9d7/gjR47QsWNHHBwc8PT0ZMCAAVy9elW3v1WrVowePZp33nmHMmXK4OXlxQcffJBnPEKYCknUQpiIe33AAwYM4ObNmxw8eJBJkybx448/4unpCUB6ejrjxo1j//79hIeHY2ZmRvfu3dFoNHrnmjJlChMnTiQyMhILCwv69u3LO++8w9dff8327ds5deoUkydP1jsmPDyc2NhYtm7dyrJly1i1ahUffvhhnvGOHDmS3bt3s3z5cg4dOsSLL75Ihw4dOHnyJAAjRowgIyODbdu2cfjwYT777DMcHBxyPdf+/fsZPXo0H330EcePH2f9+vW0aNFCt3/69On8/PPPzJ07l6NHj/LGG2/Qv39//vvvPwCSk5Np06YNgYGB7N+/n/Xr15OYmEivXr303mfx4sXY29uzd+9eZsyYwUcffcTGjRvz+S8khJEoQogiERYWppibmyv29vZ6j2nTpunKZGRkKPXr11d69eql1KpVS3nllVceec4rV64ogHL48GFFURTl7NmzCqD8+OOPujLLli1TACU8PFy3bfr06Ur16tX1YitTpoySnp6u2zZnzhzFwcFBUavViqIoSsuWLZUxY8YoiqIo58+fV8zNzZWLFy/qxdO2bVtlwoQJiqIoSkBAgPLBBx/kq27++OMPxcnJSUlJScmx786dO4qdnZ2ya9cuve1Dhw5V+vTpoyiKokydOlVp37693v74+HgFUI4fP66Lv3nz5nplGjVqpIwfPz5fMQphLNJHLUQRat26NXPmzNHbVqZMGd1zKysrlixZQt26dfHz8+Orr77SK3vy5EkmT57M3r17uXr1qq4lHRcXR506dXTl6tatq3t+rzUeEBCgty0pKUnv3PXq1cPOzk73ukmTJqSlpREfH4+fn59e2cOHD6NWq6lWrZre9oyMDNzc3AAYPXo0w4cP599//6Vdu3b06NFDL64HPfvss/j5+VG5cmU6dOhAhw4d6N69O3Z2dpw6dYpbt27x7LPP6h2TmZlJYGAgANHR0WzZsiXXFvvp06d1cT78/t7e3jnqQQhTI4laiCJkb29P1apVH1lm165dAFy/fp3r169jb2+v29elSxf8/PyYP38+Pj4+aDQa6tSpk6Mv2dLSUvdcpVLluu3hy+WGSEtLw9zcnAMHDmBubq63716yfPnllwkNDWXdunX8+++/TJ8+nS+//JJRo0blOJ+joyORkZFs3bqVf//9l8mTJ/PBBx8QERFBWloaAOvWrcPX11fvuHsD8dLS0ujSpQufffZZjnN7e3vrnj9YB/D09SBEUZBELYQJOX36NG+88Qbz589nxYoVhIWFsWnTJszMzLh27RrHjx9n/vz5PPPMMwDs2LGjwN47Ojqa27dvY2trC8CePXtwcHCgfPnyOcoGBgaiVqtJSkrSxZKb8uXLM2zYMIYNG8aECROYP39+rokawMLCgnbt2tGuXTumTJmCi4sLmzdv5tlnn8Xa2pq4uDhatmyZ67ENGjTgjz/+oGLFilhYyNeaKFnkL1qIIpSRkUFCQoLeNgsLC9zd3VGr1fTv35/Q0FAGDx5Mhw4dCAgI4Msvv+Ttt9/G1dUVNzc35s2bh7e3N3Fxcbz77rsFFltmZiZDhw5l4sSJnDt3jilTpjBy5EjMzHKOOa1WrRr9+vVj4MCBfPnllwQGBnLlyhXCw8OpW7cunTt3ZuzYsXTs2JFq1apx48YNtmzZQs2aNXN977/++oszZ87QokULXF1d+fvvv9FoNFSvXh1HR0feeust3njjDTQaDc2bN+fmzZvs3LkTJycnwsLCGDFiBPPnz6dPnz66Ud2nTp1i+fLl/Pjjjzla/UIUJ5KohShC69ev17sUC1C9enWOHTvGtGnTOH/+PH/99RegvWQ7b948+vTpQ/v27alXrx7Lly9n9OjR1KlTh+rVq/PNN9/QqlWrAomtbdu2+Pv706JFCzIyMujTp88jb19auHAhH3/8MW+++SYXL17E3d2dxo0b89xzzwGgVqsZMWIEFy5cwMnJiQ4dOuToc7/HxcWFVatW8cEHH3Dnzh38/f1ZtmwZtWvXBmDq1KmULVuW6dOnc+bMGVxcXGjQoAHvvfceAD4+PuzcuZPx48fTvn17MjIy8PPzo0OHDrn+0BCiOFEpiqIYOwghhHENGjSI5ORk1qxZY+xQhBAPkZ+aQgghhAmTRC2EEEKYMLn0LYQQQpgwaVELIYQQJkwStRBCCGHCJFELIYQQJkwS9VP47rvvqFixIjY2NoSEhLBv3z5jh1Qopk+fTqNGjXB0dMTDw4Nu3bpx/PhxvTJ37txhxIgRuLm54eDgQI8ePXRLM94TFxdH586dsbOzw8PDg7fffpvs7Gy9Mlu3bqVBgwZYW1tTtWpVFi1aVNgfr1B8+umnqFQqxo4dq9smdQQXL16kf//+uLm5YWtrS0BAAPv379ftVxSFyZMn4+3tja2tLe3atdOtxnXP9evX6devH05OTri4uDB06FDdNKP3HDp0iGeeeQYbGxvKly/PjBkziuTzFQS1Ws2kSZN0S3pWqVKFqVOn8uBwotJWT9u2baNLly74+PigUqly3EZYlPWxcuVKatSogY2NDQEBAY9curXAGG89kOJt+fLlipWVlbJgwQLl6NGjyiuvvKK4uLgoiYmJxg6twIWGhioLFy5Ujhw5okRFRSmdOnVSKlSooKSlpenKDBs2TClfvrwSHh6u7N+/X2ncuLHStGlT3f7s7GylTp06Srt27ZSDBw8qf//9t+Lu7q5baUlRFOXMmTOKnZ2dMm7cOCUmJkaZPXu2Ym5urqxfv75IP+/T2rdvn1KxYkWlbt26utWmFEXq6Pr164qfn58yaNAgZe/evcqZM2eUDRs2KKdOndKV+fTTTxVnZ2dlzZo1SnR0tPL8888rlSpVUm7fvq0r06FDB6VevXrKnj17lO3btytVq1bVraKlKIpy8+ZNxdPTU+nXr59y5MgRZdmyZYqtra3yww8/FOnnfVLTpk1T3NzclL/++ks5e/assnLlSsXBwUH5+uuvdWVKWz39/fffyvvvv6+sWrVKAZTVq1fr7S+q+ti5c6dibm6uzJgxQ4mJiVEmTpyoWFpa6lavKyySqJ9QcHCwMmLECN1rtVqt+Pj4KNOnTzdiVEUjKSlJAZT//vtPURRFSU5OViwtLZWVK1fqysTGxiqAsnv3bkVRtP+jmZmZKQkJCboyc+bMUZycnJSMjAxFURTlnXfeUWrXrq33Xi+99JISGhpa2B+pwKSmpir+/v7Kxo0b9ZaFlDpSlPHjx+dYZvJBGo1G8fLyUj7//HPdtuTkZMXa2lpZtmyZoiiKEhMTowBKRESErsw///yjqFQq3ZKb33//veLq6qqrs3vv/eCynqasc+fOypAhQ/S2vfDCC0q/fv0URZF6ejhRF2V99OrVS+ncubNePCEhIcprr71WoJ/xYXLp+wlkZmZy4MAB2rVrp9tmZmZGu3bt2L17txEjKxo3b94E7i/PeODAAbKysvTqo0aNGlSoUEFXH7t37yYgIEC35CJAaGgoKSkpHD16VFfmwXPcK1Oc6nTEiBF07tw5x+eQOoK1a9cSFBTEiy++iIeHB4GBgcyfP1+3/+zZsyQkJOh9PmdnZ0JCQvTqyMXFhaCgIF2Zdu3aYWZmxt69e3VlWrRogZWVla5MaGgox48f58aNG4X9MZ9a06ZNCQ8P58SJE4B2sZQdO3bQsWNHQOrpYUVZH8b6/08S9RO4evUqarVa7wsVtGv8PrzgQkmj0WgYO3YszZo1061/nJCQgJWVFS4uLnplH6yPhISEXOvr3r5HlUlJSeH27duF8XEK1PLly4mMjGT69Ok59kkdwZkzZ5gzZw7+/v5s2LCB4cOHM3r0aBYvXgzc/4yP+v8qISEBDw8Pvf0WFhaUKVPGoHo0Ze+++y69e/emRo0aWFpaEhgYyNixY+nXrx8g9fSwoqyPvMoUdn3JohzCICNGjODIkSMFurxiSRAfH8+YMWPYuHEjNjY2xg7HJGk0GoKCgvjkk08A7VKZR44cYe7cuYSFhRk5OtPx22+/sWTJEpYuXUrt2rWJiopi7Nix+Pj4SD2VUtKifgLu7u6Ym5vnGLGbmJiIl5eXkaIqfCNHjuSvv/5iy5YtlCtXTrfdy8uLzMxMkpOT9co/WB9eXl651te9fY8q4+TkpFsj2VQdOHCApKQkGjRogIWFBRYWFvz333988803WFhY4OnpWerryNvbm1q1aultq1mzJnFxccD9z/io/6+8vLxISkrS25+dnc3169cNqkdT9vbbb+ta1QEBAQwYMIA33nhDd6VG6klfUdZHXmUKu74kUT8BKysrGjZsSHh4uG6bRqMhPDycJk2aGDGywqEoCiNHjmT16tVs3ryZSpUq6e1v2LAhlpaWevVx/Phx4uLidPXRpEkTDh8+rPc/y8aNG3FyctJ9eTdp0kTvHPfKFIc6bdu2LYcPHyYqKkr3CAoKol+/frrnpb2OmjVrluO2vhMnTuDn5wdApUqV8PLy0vt8KSkp7N27V6+OkpOTOXDggK7M5s2b0Wg0hISE6Mps27aNrKwsXZmNGzdSvXp1XF1dC+3zFZRbt27lWJrT3NwcjUYDSD09rCjrw2j//xXqULUSbPny5Yq1tbWyaNEiJSYmRnn11VcVFxcXvRG7JcXw4cMVZ2dnZevWrcrly5d1j1u3bunKDBs2TKlQoYKyefNmZf/+/UqTJk2UJk2a6Pbfu/Woffv2SlRUlLJ+/XqlbNmyud569PbbbyuxsbHKd999V2xuPcrNg6O+FUXqaN++fYqFhYUybdo05eTJk8qSJUsUOzs75ddff9WV+fTTTxUXFxflzz//VA4dOqR07do119tsAgMDlb179yo7duxQ/P399W6zSU5OVjw9PZUBAwYoR44cUZYvX67Y2dmZ5G1HuQkLC1N8fX11t2etWrVKcXd3V9555x1dmdJWT6mpqcrBgweVgwcPKoAyc+ZM5eDBg8r58+cVRSm6+ti5c6diYWGhfPHFF0psbKwyZcoUuT3L1M2ePVupUKGCYmVlpQQHByt79uwxdkiFAsj1sXDhQl2Z27dvK6+//rri6uqq2NnZKd27d1cuX76sd55z584pHTt2VGxtbRV3d3flzTffVLKysvTKbNmyRalfv75iZWWlVK5cWe89ipuHE7XUkaL873//U+rUqaNYW1srNWrUUObNm6e3X6PRKJMmTVI8PT0Va2trpW3btsrx48f1yly7dk3p06eP4uDgoDg5OSmDBw9WUlNT9cpER0crzZs3V6ytrRVfX1/l008/LfTPVlBSUlKUMWPGKBUqVFBsbGyUypUrK++//77ebUOlrZ62bNmS63dQWFiYoihFWx+//fabUq1aNcXKykqpXbu2sm7dukL73PfI6llCCCGECZM+aiGEEMKESaIWQgghTJgkaiGEEMKESaIWQgghTJgkaiGEEMKESaIWQgghTJgk6qeQkZHBBx98QEZGhrFDMWlST48ndfR4UkePJ3X0eMWxjuQ+6qeQkpKCs7MzN2/exMnJydjhmCypp8eTOno8qaPHkzp6vOJYR9KiFkIIIUyYJGohhBDChJW69aizs7M5ePAgnp6eOVaoMVRqaioAFy9eJCUlpSDCK5Gknh5P6ujxpI4eT+ro8UyljjQaDYmJiQQGBmJh8ehUXOr6qCMiIggODjZ2GEIIIQT79u2jUaNGjyxT6lrUnp6egLZyvL29jRyNEEKI0ujy5csEBwfrctKjlLpEfe9yt7e3N+XKlTNyNEIIIUqz/HTBymAyIYQQwoRJohZCCCFMmCRqIYQQwoRJohZCCCFMmCRqIYQQIh/+F32Jo5duFvn7SqIWQgghHiPmUgpvroym+/e7ijxZS6IWQgghHiEtI5sRSyPJzNbQvKo7Nb2KdjEPSdRCCCFEHhRF4b1Vhzl7NR1vZxu+fLEeZmaqIo1BErUQQgiRh+UR8ayNvoS5mYrZfQJxtbcq8hgkUQshhBC5iL2cwgdrjwLwdmh1giqWMUockqiFEEKIh6RlZDNiSSQZ2RpaVS/Lq89UNloskqiFEEKIByiKwvurD3PmajpeTjbM7FW/yPulHySJWgghhHjAioh4/oy62y/dN5AyRuiXfpAkaiGEEOKuYwkpTLnbL/1m+2o0MlK/9INK3TKXQghRUqVlZBMdn0zk+RtExt0gKTWDj7vVIbCCq7FDKxbSM7J5/W6/dMtqZRnWooqxQwIkUQshRLGkKApnr6YTGZdMZNwNIs/f4ERiKhpFv9zgRRH8PqwpVT0cjBNoMaEoChPXHOHMlXQ8nayZ2avo75fOiyRqIYQoBtLvtZbjbhAZl8zBuBvcuJWVo5yviy0N/FxpUMGFNVGXiI5PJmzBPla93hRPJxsjRF48rNx/gdUHL2Kmgtl9GuDmYG3skHQkUQshhIlRFIVz127pLmFHxiVzPCElR2vZysKMur7OusTcoIIrHg8k4+fr+dBz7m7OXk0nbME+fhvWBCcbyyL+NKbveEIqk9ceAeDN9tUJrmT8fukHSaIWQggjS8/IJvpCMgfjtP3LB+OTuZ6emaOcr4stgXcTcgM/V2p5O2FlkfeYYDcHa34eEswLc3ZxLCGVV3/ez+IhwVhbmBfmxylWtP3SB7iTpaFFtbIMb2ka/dIPkkQthBBFSFEUzl+7dbelfIPI88kcy6O1HODrrGspN/BzfaJL1+XL2LFwUCN6z9vDnjPXGbcimtl9Ak2m/9WYFEVh0pojnDbBfukHSaIWQohCdCszm+j4m0TG3eBg3A0OxiVzLZfWso+zDYF+rtqkXMGF2j7Oj2wtG6KOrzM/DGjIoIX7WHf4MmUdrZnSpRYqleklpaK08sAFVt3tl/6mdyDuJtQv/SBJ1EIIUUAURSHu+i1dSzky7gbHElJRP9RctjI3o46vk66l3KCCK17OhTvQq1lVd77sVZ/Ryw6yaNc5PJ1sGN7K9C7zFpUTialM/lPbLz3u2WqEVHYzckR5k0QthBBP6HammugLybrEHBV/g6tpOVvL3s42NKjgqu1f9nOlto+TUfqJn6/nw5XUDKb+FcNn649R1tGang3LFXkcxnYrU3u/9J0sDc/4u/N6q6rGDumRJFEL8QSOXLzJrtNXUZTHlzU2O2sLnq/rg7OdjPYtCPvPXWdt9CUi424Qezn31nLte63lCq408HPB29nWSNHmNLR5JZJS7vDDtjOM/+MQ7g5WtKruYeywitSkNUc5lZSGh6M1X71k3Hm880MStRAGuJOl5quNJ5i//UyOwT+mbNHOsyweEkw5Vztjh1KsLdl7nklrjuj923s52dDAz+Vui9mVOr7GaS0bYnyHGiSlZrD64EVeXxLJslcaU6+8i7HDKhIr98fzR+QFbb90H9Ptl36QJGoh8iky7gZvr4zm9JV0AFpUK4u7g3En68+PXaeucfpKOi98v4uFgxtR28fZ2CEVO4qiMHPjCWZvPgVApwAvOgV406CCKz4uptNazi8zMxWf9ajL1bQMtp+8ypBFEfw+vCmV3O2NHVqhOpGYyqS7/dJvtKtGYxPul36QJGohHuNOlpqvNp1g/jZtK7qsozWfdA/g2Vqexg4tXy7fvM2gBREcT0zlpR/28MOAhjSr6m7ssIqNLLWGCasO8/uBC4D2C35026rFfsS0lYUZc/o3pM+8PRy+eJOBC/byx/CmeDiWzNnLbmVq15e+k6WheVV3Xm9t2v3SD5LVs4R4hINxN3hu9g5++E+bpLvV92HjGy2KTZIG8Ha25bdhTWhcuQxpGdkMWriPNQcvGjusYiE9I5uXF+/n9wMXMDdT8VmPAMa08y/2SfoeB2sLFgxqhJ+bHfHXbzN4YQRpGdnGDqtQTPnzKCeT0ih7t1/a3MT7pR8kiVqIXNzJUjP9n1h6zNnFqaQ03B2smTegIbN6B+JiZ/qXux/mbGvJ4iHBdK7rTZZaYeyKKH747zRKcRgNZyRXUjPoPW8P/524gq2lOfMHNuSlRhWMHVaBK+uonb3M3cGKo5dSGPbLATKzNcYOq0D9fuACKw9o+6W/7l2fso6m3y/9IEnUQjwkKj45Ryt607gWtK/tZezQnoq1hTmzewcytHklAKb/c4wP/xeTY9SygLNX0+kxZxeHL96kjL0Vy15tTJsaxecqiqH83OxZOCgYOytzdpy6ytu/R6MpIX8XJxNTmbRG2y89pm01mlYpft0+Rk/U3333HRUrVsTGxoaQkBD27duXZ9msrCw++ugjqlSpgo2NDfXq1WP9+vVFGK0oyTKy1Xy2/hgvfL9T14r+oRi3onNjZqZi0nO1mNi5JgCLdp1j1LJI7mSpjRyZ6YiKT6bHnF3EXb9FhTJ2rBrelPqlYER0QDln5vZviIWZij+jLjH9n1hjh/TUbmeqGbE0kttZappVdWNkm+LTL/0goybqFStWMG7cOKZMmUJkZCT16tUjNDSUpKSkXMtPnDiRH374gdmzZxMTE8OwYcPo3r07Bw8eLOLIRUkTHZ/Mc9/sYM7W02gU6Hq3Lzq0mLei8/LyM5X5pk8gVuZm/H04gYE/7eNmLksmljbhsYn0mbeH6+mZ1C3nzB/Dm1KxhI+EflCLamX5/MW6AMzffpb5284YOaKnM2XtEU4kavulZ70UWKz6pR+kUozYSRUSEkKjRo349ttvAdBoNJQvX55Ro0bx7rvv5ijv4+PD+++/z4gRI3TbevToga2tLb/++mu+3vPChQuUL1+e+Ph4ypUrfTPyCH0Z2WpmbTrJD/9pE7S7gxXTugeU2AT9sF2nr/LazwdIzcjG38OBxUOCi+XtRgVh+b443lt9GI0CraqX5bu+DbC3Lp03xvzw32mm/3MM0Pbpdq3va+SIDLcq8gLjfotGpYIlQ0NoamJ3OhiSi4zWos7MzOTAgQO0a9fufjBmZrRr147du3fnekxGRgY2Nvq3Dtja2rJjx4483ycjI4OUlBTdIzU1tWA+gCj2Hm5FP1/Ph41vtCw1SRqgaRV3Vg5vgqeTNSeT0njh+10cS0gxdlhFSlEUvtp4gndXaZP0iw3LMX9gUKlN0gCvtqjMkGbasQxvrYxm+8krRo7IMKeSUnl/9b1+aX+TS9KGMlqivnr1Kmq1Gk9P/QEanp6eJCQk5HpMaGgoM2fO5OTJk2g0GjZu3MiqVau4fPlynu8zffp0nJ2ddY9atWoV6OcQxU9GtprPNxzjhTm7OJmUhruDFXP7N+CbPoG42peMvmhD1PByYtXrzfD3cCAh5Q4vztnNrtNXjR1WkchWa3j3j8N8HX4SgNFtqjKjZ10szY0+fMeoVCoVEzvX5Lm7dwkM++UARy7eNHZY+XI7U82IJQe5naWmaRU3RrXxN3ZIT61Y/TV+/fXX+Pv7U6NGDaysrBg5ciSDBw/GzCzvjzFhwgRu3rype8TExBRhxMLUHLqQTJfZO/huy2nUGoUu9Xz4942WdKjjbezQjMrXxZbfhzUluGIZUjOyGbQggv9FXzJ2WIXqVmY2r/5ygBX74zFTwbTudRjXvnqJuUf6aZmZqfiyVz2aVnEjPVPNoIX7OH8t3dhhPdaH/zvK8cRU3B2smdW7eN0vnRejJWp3d3fMzc1JTEzU256YmIiXV+6XHsuWLcuaNWtIT0/n/PnzHDt2DAcHBypXrpzn+1hbW+Pk5KR7ODo6FujnEMXDvVZ09+93cSIxDTd7bSt6dp9AypTCVnRunO0s+XloMJ0CvMhUaxi17CA/bi/eg4nyci0tgz7z9rD5WBI2lmb8MCCIfiF+xg7L5FhbmPPDgIbU9HbialomYQv2cTUtw9hh5Wn1wQssj4hHdfd+6ZIyy5rRErWVlRUNGzYkPDxct02j0RAeHk6TJk0eeayNjQ2+vr5kZ2fzxx9/0LVr18IOVxRjhy/c5PnZO3Wt6OfqerNxnLSic2Njac7sPg0Y1LQiAB+vi2XqXzEl5p5agPPXtPdIR1+4iaudJUteblysZporao42liwe3Ihyrracu3aLIYsiSDfB2ctOJaXp+qVHt/EvUdPkGvXS97hx45g/fz6LFy8mNjaW4cOHk56ezuDBgwEYOHAgEyZM0JXfu3cvq1at4syZM2zfvp0OHTqg0Wh45513jPURhAnLyFbzxYbjdPt+J8cTU3Gzt2JOvwZ827eBtKIfwdxMxZQutZjQsQYAP+04y+jlB8nILv73Wh+6kMwL3+/i3LVblHO15ffhTWno52rssEyeh5MNPw8Jpoy9FYcu3GT4kkiy1KYze9mdLDUjl0ZyK1NNk8pujG5b/PulH2TUYY0vvfQSV65cYfLkySQkJFC/fn3Wr1+vG2AWFxen1/98584dJk6cyJkzZ3BwcKBTp0788ssvuLi4GOkTCFN15OJN3vwtmuOJ2lH+net689HztXErBkvamQKVSsVrLavg6WTD279H89ehy1xNy+CHAUE42xbPda23HE9ixBLtl3ltHycWDm5UYi6NFoXKZR34KSyIvvP3su3EFcb/fogve9UziT79D/93lGMJqbg7WPF1CemXfpBR76M2BrmPumTLzNYwe/NJvt+qvcztZm/F1G516BQgl7mf1I6TVxn26wHSMrKp7unIoiGN8HYuXvda/7Y/ngmrDqPWKDzj786c/g1xKMW3Xz2NLceSePnn/ag1CsNaVuHdu1dejOXPqIuMWR6FSgW/DAmhuX/xuORdLO6jFqKgHbl4k+e/3cHszadQaxQ6B3jz7xstJEk/peb+7qx4rTFlHa05npjKC9/v4kRi8ZiPQFEUZoef5J3fD6HWKLwQ6MtPYY0kST+F1jU8+PSFAADm/neaBTvOGi2W01fSeG/VYQBGta5abJK0oeSvVZiWI6sg8SiUa6R92D9+YffMbA3fbj7Jd3db0WXsrZjatQ6d60qCLii1fZxZNbwpgxbu4/SVdHrO2cX8gUGEVH78v4+xZKs1TF57lKV74wB4vVUV3g4tgNuvko7Bzq/BzBy6fnt/++7vIeGwYecq3wiChmifq7Ng7Wjt8+dmguXdqxaRv8D5XYad16MmNBt9//X/xkJ2Bjz7ITh4aLcdXQ0n/jXsvC7lofV7vBhUnqTUDMzDp+C0IYVw1Xu0bXZ3EPDJTXDkD8POa+sCHabff/3fDLh+FhoPA+962m1xe+HAIl0RtaJwJjaRD5Vsyrpa8Ux6WVj90L9tXv9Ggf2gYnPttsSjsOtb8sXcAp6fbdhnKwCSqIXxqbO1/wMA2DjD9i/u7ytTBcoHa5N2+WDwqKX9n++uIxdv8tbKaI4laFt4nQK8+KhrHdylL7rAlS9jxx/DmzJ08X4OnL/BgJ/2Mat3fZO8YnE7U82oZQfZFJuISgUfPl+bgU0q5v8E6mxIioEL+yA+AiqE3E+oNs4QvRTMrfSTwNltcOIfwwLVZN8/r6LRnheg42f3E3X83vvb86tKG/1Effh3yEyFFm/dT9SXow0/r1ddaP0eoP3hc333QdwyL9Lrn3bYet6dAezKMcPP6+ijn6hP/gsXIqBml/uJ+sY5vfOaA8/ee3IbiM7lvHn9G1VofD9Rp17Of7zm1pKoRSlzbgeETwW/ptBuinZbpRbQYCDE7YGrJ+D6ae0jepl2v5UD+DZA7dOItdfLMS3anqsaB8rYW/FR19o8V9fHeJ+nFHCxs2LJyyGMXnaQf2MSGbE0kinP1WLQ3ekmTcH19EyGLo7gYFwyVhZmfNM7kA51HjMtbPo1bWK4sA/i98HFSMh6YHKPW9fuJ1Qnb+jwqTbJPqh+H20CMETZB/p3VebQ7kPtc4sHfmjW6gZuBq765PLQutmt3wN1JtiVub+tajuwcTHsvPeSPNoBh67Pvs3qPTGcv1hGO3nMa42p7dfk/ufIL6uHFj5p9ArUeA7KVr+/zbuu7rxHL6ewNuoSKhX0CipP5bwWTnngRz1w/9/It8H9bW5V8x/vw+crIjKYTBhP7F+woh/Ye8C42Put6ntuXYeLB7RfnBf2wYUD2lbBQ07Y1KXMyE33W9GKAiYwErUkU2sUPlh7lF/2nAfgtRaVGd+hBmZGHm0bf/0WYQv2ceZqOs62lvwYFkSjimX0C2nU2tZy/D5tco7fp/0x+DBrJ/BtqL2SU7G59kekyOFOlpqwBfvYe/Y6ZR2tWTW8KeXL2BXa+525kkaX2TtIz1Qzqk1V3mxf/fEHmSBDcpG0qEXRuHkB9v4Ajt7Q5HXttuodod0HUK9PziQN2l///s9qH0BmZhbL/97I8f3h1OcEQRanqMQl/CtWQPVgkp7dAJzLQ7c54Fz8Vv0pDszNVHzUtTZezjZ8vuE4P2w7Q2LKHWb0rIeVhXHGqB65eJNBCyO4mpaBr4sti4c0oqqHo/YHn6Xt/UvJ2z6HrdNznsC9GpQL1vYblwvWtuaM1IIqTmwszZk3MIiXftjNsYRUwhbs4/fhTQtlroI7WWpGLD1Ieqaa4EplGFPC7pfOiyRqUbguRsLu77QDVxS1tvXcaKj20p6ZOTR/I1+nOXrpJm+tPETsZQVow/U6fWndrQ6YpaPKeGC1pxvn4PoZSI4HuwcGOm37Qrv9Xl932RryJfyUVCoVI1pXxcvJhvF/HGJN1CWupGUwt39DHG2K9l7rbSeuMPzXA6RnZlPDy4nFQ4LxdLKBpS/BifXQexnU6KQt7NsQrByhXMO7iTlYu82uzKPfROTJ2daSRYOD6TFnF2eupjNkUQRLXwnBzqpgU8zUv2KIvZyCm70Vs/sEYlFKFk+RRC0KnkYNx//RJui4B0arVnwGmowEs/x/iWepNXy35RTfbj5FtkbB1c6SD7vWoUtd77ujd631v2BdKsCwndpLmZYPTGYR8yckHIKoJdrXD39RlwsCW5mh6kn0aFiOso7WDP/1ADtPXaPXD3tYNLiRNlEWtlvX2bn1Hw7v/pd5nKSO3UVUr8TiZH/3ve3v3q5z7eT9Yyq3hnfPyw+1AublbMPiIY3oOXc3UfHJjFgSybyBQQW2Etna6Ess2RuHSgVfvVS/aP6+TIT0UYuCk5EGUUthz/dw4+69lWYWUKen9nL3vdGb+RRzKYW3VkYTc1nbYg6t7cnH3QIo6/gEI7pPboK43dq+7ouRkJmWs4xc+nwqeV56LigaNSTF3h2vsB8lfh+qBxPwPa9suT9Y6OZF7SVvaS0XmQPnb9Dvxz3cydLwYsNyzOhZ96lviTt7NZ3nvtlOeqaaEa2r8HaocSdZKQiG5CJJ1OLp3bwI++bBgYVw5+6atTYu2lGywa+Ak2EjsbPUGr7fcprZm0+SrVFwsbPkI71W9FPK72CizjO1l+kB7qRoL91Lq/uRHh7M9VNYEEEPD+bKr+xMOPvfYwcTntZ4k+4RSJ2QZzErH6y9h1h+YBnVpphEXv1lPxoFRrauyluhTz7g606Wmhe+30XM5RSCK5Zh6SshJeKStwwmE0Vn42TtJe57t6qUqQyNX4f6fXPecpEPMZdSePv3aI5eKoBWdF7MzMErQPu4l4hzuz2nXND9Y478AX+Nhfr9odt32m1Zt7UJ31Bla4LV3VGxKZe093HauYPr3WUW1dmQkNtNoY/h5g82TtrnaVfgZpz2B5NblftlLh4w/Lyule63SG9d114tsXLQv3XmcjRosikPrO5my8frznI8IZVPfzzBuPbVaFoll4lRnMvfv90nI1XbWgZtVwRo/6aW9da/DcrKAbVPAzYkl2dlkg9RSlVGdQ5hSHPTuT1MQLtannzSPYB3Vx3m2y2n8HCyNuw+9gd8vC6GmMsplLG34ptS1C/9IEnUwjAaDaDcb7E4eGq/SP2aQ5MRUK0DmBn2P5KiKOw7e50fd5xlU2wiigIudpZ8+Hxtnq/nUzST/tu7QfUO2gdok6Xqgc9x/e66zI4P3I+bHAfz2xj+XsN3gWdt7fPIX2DrJ9qrD899pd2WkfJk5x24Fiq31D6P/RPWvamdMOKlX++Xmd8WMPAiWs8FUKeH9vm57fDbQKjQFIY8MLnHrz0g/QoAzsDnAPd+W22++3hYxxkQ8pr2+eVDsKgT+ATCq1u126zsoEZnsLTTDQJMdqjK0F8OciDhBlbmZnzVu77MQGeiegdXICk1g5kbTzBl7VHcHawNnhznr0OX+HWPdma5mb3q4eVcevqlHySJWuRf9Ar471NoNQHq9tJuCxygnbDEJ9Dg02WpNfx9+DI/bj/L4Ys3dds7BXjxwfO1jbuy0cO3i7WfCs3GaG//usfMApwfmlgiPx4cTGfjpD3Hg5fUVaonO6/FA/Vl5ag9h91Dcx+7lDc4T2Npp//cuYLexBcAOPmChf5CHQoKybeySM/UtogdrS1xsrVAxd0fXlYOD8Rufb8eNJr7P/Z6/awrcuHGLcJ+2MvpK+k42Vgwb2AQjU14ClMBo9pUJTHlDkv2xjF2eRRl7K3y/W927mo67/6hnZL19VZVaFXd4zFHlFzSRy3yb9vnsPlj7ejtQX898Wlu3spiWUQci3ed4/LNOwBYW5jRo2E5hjSrRFUPh8ecQRQXiqLw7eZTfLnxBAAvNPDlsx51DR4JfPTSTQYvjCApNQNvZxsWDwmmmmcBDlQThUatURj+6wH+jUnE0caClcOaUMPL6ZHH3MlS02POLo5eSqFRRVeWvdK4xF3ylj5q8fQuR2snsK/1vPbyI0DQULB21vY/P4Hz19JZuPMcv+2P51amGgB3B2vCmvjRr7FfoUyQIIxLpVIxqq0/ns42TFh1mFWRF7mSmmHQMpM7T13ltV+K9zKbpZm5mYpv+gQy4Ke9RJy7QdiCfax6vRm+Lnn/G37ydyxHL6XgamdZavulHyQtanGfRqOdDH/3t9q+SIDyITDUwBV2HqAoCvvP3+DH7Wf4NyZRd+W4hpcjQ5tX4vn6PlhbyAjd0mDL8SRe/zWS21lqavs4sXBwo8d2b6w5eJG3f48mS60QUqkM8wYG4WxbtJOpiIJx81YWL/6wixOJaVT1cOD3YU1wscv543zdocuMWBoJwMLBjWhdQi95y+1ZjyCJOheZt7SLXuz5Hq6d0m5TmUPt7tr7n30bGnzKLLWGf44k8NP2M0RfuN//3Kp6WV5uXplmVd2KZpCYMCnR8ckMWRTBtfRMyrnasnhIMFXK5uzqUBSFedvOMP2fYwB0ruvNzF715EddMXcp+TY95uzi8s07NPRzZcnLIdhY3v83PX8tnc7f7CAtI5thLavwbsfif790XiRRP4Ik6gekJsC++bD/J7h9Q7vN2hkahmlH4zobXj83b2exIiKORTvPcelu/7OVhRk9GvgypFkl/KVfsdQ7fy2dsAX7OHftFq52lvw0qBENKtwfTKfWKEz9K4ZFu84BMLR5Jd7vVNPoC36IgnEiMZWec3aRciebdjU9mdu/ARbmZmRka/ulj1xMIcjPlWWvNi6wWc1MkSTqR5BEjXbh9N3fw+GVoMnSbnOteP/+Z2vDk2n89Vss2HmW3yLiSdf1P1sxoHFF+jWuIOtDCz1X0zIYuiiC6As3sbE0Y3afBjxby5M7WWrG/RbF34cTAJjYuSYvP1PZyNGKghZx7jr9f9xLRraGPsEV+KR7HT5Ye5TFu8/jamfJutHP4POIPuySQBL1I5TqRK0o2kUKTm64v61CE+39z9U7GTybk6IoRMbd4MftZ9lwNAHN3b+kap4OvNy8Ms/X99G7rCXEg25lZjNiSSRbjl/BTAXvdarJv0cT2XfuOpbmKr7sVZ/n68n64iXVhqMJDP/1ABoF2tbwIPxYEgALBzWidY2S2S/9oEId9V2xYkWGDBnCoEGDqFDhCe71FMajUoGjp7b/uVZX7QIZ5Qzvf85Wa1h/NIEft58lKj5Zt71FtbK83LwSz/i7S/+zeCw7KwvmDwzi/dVHWLE/no/XaWcmc7S24IeBDWlaxf0xZxDFWWhtLz7qWoeJa47okvRrLSuXiiRtKIMT9dixY1m0aBEfffQRrVu3ZujQoXTv3h1ra7m0aZLuXTC5lzhbjocWb2tXmTJQyp0sfouIZ+HOc1xMvg2AlbkZ3QN9GdK8EtW9pP9ZGMbC3IxPewTg5WzD1+En8XSyZtHgYGp6P/o+W1Ey9G/sR1JqBt+En6RRRVfeav/kc4KXZE986TsyMpJFixaxbNky1Go1ffv2ZciQITRo0KCgYyxQpe7S94kN2rWYO0zXn7vaAPHXb7Fo1zlWRMSTlqGdZaqMvRUDGvvRv7Ffwc7DLUqtE4mpeDnb4FTEa1kL4zuZmEpFd/sSPXjsYUXaR52VlcX333/P+PHjycrKIiAggNGjRzN48GCTvPxZqhK1osD81nDpoHb6y2c/MujwyLgb/LT9LP8cuazrf67q4cDLzSvRLdBX+p+FEOIJFcnMZFlZWaxevZqFCxeyceNGGjduzNChQ7lw4QLvvfcemzZtYunSpU96elEQVCrovQy2fwnPvJmvQ7LVGv6NSeTH7WeIjEvWbX/G352hzSvRwr+s3CYjhBBFyOBEHRkZycKFC1m2bBlmZmYMHDiQr776iho17t+Y3r17dxo1alSggYon5OQNnb94bLHUO1n8tv8CC3ee5cKN+/3PXev7MPSZSo+dm1cIIUThMLhDoFGjRpw8eZI5c+Zw8eJFvvjiC70kDVCpUiV69+6dr/N99913VKxYERsbG0JCQti3b98jy8+aNYvq1atja2tL+fLleeONN7hz546hH6PkS47LV7GLybeZti6GptM3M/WvGC7cuI2rnSWj21Rlx7ut+fzFepKkhRDCiAxuUZ85cwY/P79HlrG3t2fhwoWPPdeKFSsYN24cc+fOJSQkhFmzZhEaGsrx48fx8Mg5RH/p0qW8++67LFiwgKZNm3LixAkGDRqESqVi5syZhn6UkuvGOfi2Efi3hxfma9f1fUhUfDI/bj/DP0cSUN/tgK5S1p6hzSvzQgPpfxZCCFNhcKJOSkoiISGBkJAQve179+7F3NycoKD8jyyeOXMmr7zyCoMHDwZg7ty5rFu3jgULFvDuu+/mKL9r1y6aNWtG377a1ZsqVqxInz592Lt3r6Efo2Tb9AGoMyEzDSzvz+6j1ihsjNHe/7z//A3d9mZV3Xi5eWVaVpP+ZyGEMDUGX/oeMWIE8fHxObZfvHiRESNG5Ps8mZmZHDhwgHbt2t0PxsyMdu3asXv37lyPadq0KQcOHNBdHj9z5gx///03nTp1MvBTlGBxe+HoakAF7aeBSoVGo/Dz7nO0+mILw36NZP/5G1iaq+jRoBx/j36GJS83pnUND0nSQghhggxuUcfExOR6r3RgYCAxMTH5Ps/Vq1dRq9V4enrqbff09OTYsWO5HtO3b1+uXr1K8+bNURSF7Oxshg0bxnvvvZfn+2RkZJCRkaF7nZqamu8Yix2NBjZM0D5vMAC86gCwaNc5PvpL+2/jYmdJ/xA/Bjbxw8Pp0UsMCiGEMD6DW9TW1tYkJibm2H758mUsLJ74bq982bp1K5988gnff/89kZGRrFq1inXr1jF16tQ8j5k+fTrOzs66R61atQo1RqM6ugouHgBLe2g9EQCNRmHx7nOAdnq+3e+25a3Q6pKkhRCimDA4Ubdv354JEyZw8+b9NYaTk5N57733ePbZZ/N9Hnd3d8zNzXMk/cTERLy8vHI9ZtKkSQwYMICXX36ZgIAAunfvzieffML06dPRaDS5HnMv1nsPQ1r9xUrWbW3fNEDzN7RzegM7Tl3l/LVbONpYMKatP7ZWMkhMCCGKE4MT9RdffEF8fDx+fn60bt2a1q1bU6lSJRISEvjyyy/zfR4rKysaNmxIeHi4bptGoyE8PJwmTZrkesytW7cwM9MP2dxcm3jymmDN2toaJycn3cPRsYTOR71nDtyMBydf7WpYdy3Zex6AHg3KYWdVuFc8hBBCFDyDv7l9fX05dOgQS5YsITo6GltbWwYPHkyfPn2wtDRsjt5x48YRFhZGUFAQwcHBzJo1i/T0dN0o8IEDB+Lr68v06dMB6NKlCzNnziQwMJCQkBBOnTrFpEmT6NKliy5hl0ppV2D73dvT2k7R3Y6VcPMOm2K1q9L0DZGVzoQQojh6oiaWvb09r7766lO/+UsvvcSVK1eYPHkyCQkJ1K9fn/Xr1+sGmMXFxem1oCdOnIhKpWLixIlcvHiRsmXL0qVLF6ZNm/bUsRRrWz+BzFTwCYSAF3Wbl0fEodYoBFcqQzXPEnolQQghSrgnXpQjJiaGuLg4MjMz9bY///zzBRJYYSlxi3IkxcKcpqBoYPA/4NcU0M7Z3fyzLSSk3OHr3vXpWt/XyIEKIYS4p1AX5Thz5gzdu3fn8OHDqFQqXd/wvZWy1Gr1E4Qsnti/E7VJumYXXZIGCD+WRELKHdzsrehQJ/fBeUIIIUyfwYPJxowZQ6VKlUhKSsLOzo6jR4+ybds2goKC2Lp1ayGEKPKUdVs785iZJbT7UG/Xr3u0g8heDCqPtUUp7r8XQohizuAW9e7du9m8eTPu7u6YmZlhZmZG8+bNmT59OqNHj+bgwYOFEafIjaUtvPQr3DgPrvfnXz9/LZ3tJ6+iUkHfYBlEJoQQxZnBLWq1Wq27xcnd3Z1Lly4B4Ofnx/Hjxws2OpE/rvqLpCzdq105q4V/WSq45VyQQwghRPFhcKKuU6cO0dHRAISEhDBjxgx27tzJRx99ROXKlQs8QJGLOymw7i1IuZRjV0a2mt/2a+di79/40aucCSGEMH0GX/qeOHEi6enpAHz00Uc899xzPPPMM7i5ubFixYoCD1DkYsdXEDEf4vfCa9tAdX8xjX8OJ3DjVhbezja0rl7WiEEKIYQoCAYn6tDQUN3zqlWrcuzYMa5fv46rq6tu5LcoZDWeg/O7oNkYvSQN92ci6xNcAQtzgy+YCCGEMDEGfZNnZWVhYWHBkSNH9LaXKVNGknRRKtcQhqyH6h31Nh9LSCHi3A3MzVS81Ki8kYITQghRkAxK1JaWllSoUEHulTaWBxceUalytKbvDSJrX8sTT1kdSwghSgSDr42+//77vPfee1y/fr0w4hF5URT4pSv8Ownu3MyxOz0jm1WRFwHoFyKDyIQQoqQwuI/622+/5dSpU/j4+ODn54e9vb3e/sjIyAILTjwgZg2c3QbxEdB4ONg46+1eG32JtIxsKrnb07SKm3FiFEIIUeAMTtTdunUrhDDEI2VnwMYp2ufNxoCTj95uRVF0M5H1Da6AmZmMFxBCiJLC4EQ9ZcqUwohDPMreHyD5PDh4QbPROXZHxSdz9FIKVhZm9GxYAhYaEUIIoSP375i69Kuw7XPt87aTwMo+R5EldweRPVfXG1d7q6KMTgghRCEzuEVtZmb2yFuxZER4Adv6KWSkgFcA1OuTY3fyrUz+F62doUwGkQkhRMljcKJevXq13uusrCwOHjzI4sWL+fDDD/M4SjyRKydg/wLt8/bTwCznKlh/RF4kI1tDTW8nGlRwKdr4hBBCFDqDE3XXrl1zbOvZsye1a9dmxYoVDB06tEACE8DGSaCooXonqNwyx25FUXQzkfULqSCTzgghRAlUYH3UjRs3Jjw8vKBOJ05vgRPrwcwCnv0o1yK7z1zjzJV07K3M6RboW8QBCiGEKAoFkqhv377NN998g6+vJIsCoVHDvxO1z4OGgrt/rsWW7NEOIusW6IuDtcEXR4QQQhQDBn+7P7z4hqIopKamYmdnx6+//lqgwZVaUUsh8Yh2UpNW7+ZaJCn1DhuOJgAyiEwIIUoygxP1V199pZeozczMKFu2LCEhIbi6uhZocKXW0bsD9lq8A3Zlci3yW0Q82RqFBhVcqOXjVITBCSGEKEoGJ+pBgwYVQhhCT7+VcHgl1O6e6261RmHZvngA+jeW1rQQQpRkBvdRL1y4kJUrV+bYvnLlShYvXlwgQZV6ZuZQrzdYWOe6e+vxJC4m38bFzpJOAd5FHJwQQoiiZHCinj59Ou7u7jm2e3h48MknnxRIUKXWsb8h6/Zji92biezFhuWwscx5b7UQQoiSw+BEHRcXR6VKlXJs9/PzIy4urkCCKpUuHYTlfeDbYLiTkmex+Ou32HI8CYC+MohMCCFKPIMTtYeHB4cOHcqxPTo6Gjc3WV7xid1OBqdyUKEx2OQ9OGx5RByKAs2rulPJPee830IIIUoWgweT9enTh9GjR+Po6EiLFi0A+O+//xgzZgy9e/cu8ABLjSqtYdT+R176zszWsCJCO4isX0iFoopMCCGEERncop46dSohISG0bdsWW1tbbG1tad++PW3atHniPurvvvuOihUrYmNjQ0hICPv27cuzbKtWrVCpVDkenTt3fqL3NimWtnnejgWw4WgCV9My8XC0pl0tzyIMTAghhLEY3KK2srJixYoVfPzxx0RFRWFra0tAQAB+fk/WX7pixQrGjRvH3LlzCQkJYdasWYSGhnL8+HE8PDxylF+1ahWZmZm619euXaNevXq8+OKLT/T+RndwCSgaqN8310U3HnRvXu/ejcpjaS4rlAohRGnwxPNO+vv74++f+9SWhpg5cyavvPIKgwcPBmDu3LmsW7eOBQsW8O67OWflKlNGv8W5fPly7OzsimeivnUdNrwHd5K1remAnnkWPZWUyp4z1zFTQe9guewthBClhcHNsh49evDZZ5/l2D5jxgyDk2VmZiYHDhygXbt29wMyM6Ndu3bs3r07X+f46aef6N27N/b2uQ+sysjIICUlRfdITU01KMZCte0LbZL2qJ3n5Cb33Lslq00NT3xcbIsgOCGEEKbA4ES9bds2OnXqlGN7x44d2bZtm0Hnunr1Kmq1Gk9P/f5WT09PEhISHnv8vn37OHLkCC+//HKeZaZPn46zs7PuUatWLYNiLDTXTsO+edrn7ac+8rL37Uw1fxy4AED/xtKaFkKI0sTgRJ2WloaVlVWO7ZaWlqSk5H3/b2H46aefCAgIIDg4OM8yEyZM4ObNm7pHTExMEUb4CBsngyYLqj4LVds+suj/Dl0i5U425cvY0sK/bBEFKIQQwhQYnKgDAgJYsWJFju3Lly83uLXq7u6Oubk5iYmJetsTExPx8vJ65LHp6eksX76coUOHPrKctbU1Tk5Ouoejo6NBMRaKczvg2F+gMof2Hz+2+JI92kFkfYP9MDNTPaa0EEKIksTgwWSTJk3ihRde4PTp07Rp0waA8PBwli5dyu+//27QuaysrGjYsCHh4eF069YNAI1GQ3h4OCNHjnzksStXriQjI4P+/fsb+hGMS6OBDe9rnzccBB41Hln88IWbRF+4iaW5il5B5Qo/PiGEECbF4ETdpUsX1qxZwyeffMLvv/+Ora0t9erVY/PmzTlGZOfHuHHjCAsLIygoiODgYGbNmkV6erpuFPjAgQPx9fVl+vTpesf99NNPdOvWrfjNhnb4N7gcBVaO0GrCY4vfuyWrYx1v3BxyX6RDCCFEyfVEt2d17txZN8FISkoKy5Yt46233uLAgQOo1WqDzvXSSy9x5coVJk+eTEJCAvXr12f9+vW6AWZxcXGYmelfoT9+/Dg7duzg33//fZLwjSfzFmz6UPu8xZvg8Oj+5pQ7WfwZdQmQ5SyFEKK0euL7qLdt28ZPP/3EH3/8gY+PDy+88ALffffdE51r5MiReV7q3rp1a45t1atXR1GUJ3ovo9r9LaReAucKEDL8scVXR17kdpaaap4ONKroWgQBCiGEMDUGJeqEhAQWLVrETz/9REpKCr169SIjI4M1a9aYzm1Ppio1AXbM0j5/9gOwtHlkcUVRdJe9+4X4oVLJIDIhhCiN8j3qu0uXLlSvXp1Dhw4xa9YsLl26xOzZswsztpJl+0zISodyjaD2C48tHnHuBicS07C1NKd7A98iCFAIIYQpyneL+p9//mH06NEMHz68QKYOLXVavwcW1lCzC+SjdXyvNd21vg9ONpaFHZ0QQggTle8W9Y4dO0hNTaVhw4aEhITw7bffcvXq1cKMrWSxddHOQFY+78lZ7rmWlsE/h7Uzs/ULkUFkQghRmuU7UTdu3Jj58+dz+fJlXnvtNZYvX46Pjw8ajYaNGzea1hzapiQtCQwc+LbywAUy1RrqlXMmoJxzIQUmhBCiODB4ZjJ7e3uGDBnCjh07OHz4MG+++SaffvopHh4ePP/884URY/GlzoJFnWFhR7hxLl+HaDQKS+8uwCGtaSGEEE+1qHH16tWZMWMGFy5cYNmyZQUVU8lx+RAkx8PVE2Cbv9urtp28Qtz1WzjaWNClnk8hByiEEMLUPfF91A8yNzenW7duumlAxV3lGsKoA3DtJNjk7xL2veUsezQoh61V3itqCSGEKB0KJFGLR3D21T7y4VLybcJjtQuUyHKWQggh4CkvfYs83DgP53cZfNjyiHg0CoRUKkNVDxNY5UsIIYTRSaIuDBsnaweQbfsi34dkqTUs36e97C3zegshhLhHEnVBi9sDMWtAZQbVO+b7sPDYRJJSM3B3sCK09qPX4hZCCFF6SKIuSBoNbHhP+zxwAHjWzvehv+7RtqZ7BZXHykL+WYQQQmhJRihIR1fBxQNg5QCt38/3YWevprPj1FVUKugTLIPIhBBC3CejvgtK1m3Y9IH2efOx4OiZ70OX3p3Xu1W1spQvY1fwsQlhwtRqNVlZWcYOQ4gCZWlpibl5wdxiK4m6oOz5Hm7Gg1M5aJL72tq5uZOlZuWBC4AMIhOli6IoJCQkkJycbOxQhCgULi4ueHl5PfUyxZKoC0JaknYZS4B2U8DSNt+H/n34Msm3svB1saVVdY9CClAI03MvSXt4eGBnZydrrosSQ1EUbt26RVJSEgDe3t5PdT5J1AVhyyeQmQY+gVCnp0GH3puJrE9weczN5ItKlA5qtVqXpN3c3IwdjhAFztZW22BLSkrCw8PjqS6Dy2Cyp5UYA5GLtc9DPwGz/Fdp7OUUDpy/gYWZil6NyhdSgEKYnnt90nZ2MiZDlFz3/r6fdgyGJOqn9e9EUDRQ83nwa2rQoUvuDiILre2Fh6NNYUQnhEmTy92iJCuov29J1E/j5CY4HQ5mlvDshwYdmpaRzerIiwD0C5FbsoQorSpWrMisWbPyXX7r1q2oVCoZhFeKSB/10yhTCap31v63TGWDDl1z8CLpmWoqu9vTpIr00Qlh6h7XOpoyZQoffPCBweeNiIjA3t4+3+WbNm3K5cuXcXbO34p8oviTRP003KpAn6WgURt0mKIoukFkfUMqyOU/IYqBy5cv656vWLGCyZMnc/z4cd02BwcH3XNFUVCr1VhYPP4rtmzZsgbFYWVlhZdX6ZxmODMzEysrK2OHUeTk0ndBMDNsNF9kXDKxl1OwtjCjZ8NyhRSUEKIgeXl56R7Ozs6oVCrd62PHjuHo6Mg///xDw4YNsba2ZseOHZw+fZquXbvi6emJg4MDjRo1YtOmTXrnffjSt0ql4scff6R79+7Y2dnh7+/P2rVrdfsfvvS9aNEiXFxc2LBhAzVr1sTBwYEOHTro/bDIzs5m9OjRuLi44Obmxvjx4wkLC6Nbt255ft5r167Rp08ffH19sbOzIyAggGXLlumV0Wg0zJgxg6pVq2JtbU2FChWYNm2abv+FCxfo06cPZcqUwd7enqCgIPbu3QvAoEGDcrz/2LFjadWqle51q1atGDlyJGPHjsXd3Z3Q0FAAZs6cSUBAAPb29pQvX57XX3+dtLQ0vXPt3LmTVq1aYWdnh6urK6Ghody4cYOff/4ZNzc3MjIy9Mp369aNAQMG5FkfxiSJ2gjuDSJ7rq4PLnal79ehEA9TFIVbmdlGeSiKUmCf49133+XTTz8lNjaWunXrkpaWRqdOnQgPD+fgwYN06NCBLl26EBcX98jzfPjhh/Tq1YtDhw7RqVMn+vXrx/Xr1/Msf+vWLb744gt++eUXtm3bRlxcHG+99ZZu/2effcaSJUtYuHAhO3fuJCUlhTVr1jwyhjt37tCwYUPWrVvHkSNHePXVVxkwYAD79u3TlZkwYQKffvopkyZNIiYmhqVLl+LpqZ2VMS0tjZYtW3Lx4kXWrl1LdHQ077zzDhqNJh81ed/ixYuxsrJi586dzJ07FwAzMzO++eYbjh49yuLFi9m8eTPvvPOO7pioqCjatm1LrVq12L17Nzt27KBLly6o1WpefPFF1Gq13o+fpKQk1q1bx5AhQwyKrajIpe8idiM9k78OaX/p9m8sg8iEALidpabW5A1Gee+Yj0KxsyqYr8KPPvqIZ599Vve6TJky1KtXT/d66tSprF69mrVr1zJyZN4zGA4aNIg+ffoA8Mknn/DNN9+wb98+OnTokGv5rKws5s6dS5UqVQAYOXIkH330kW7/7NmzmTBhAt27dwfg22+/5e+//37kZ/H19dVL9qNGjWLDhg389ttvBAcHk5qaytdff823335LWFgYAFWqVKF58+YALF26lCtXrhAREUGZMmUAqFq16iPfMzf+/v7MmDFDb9vYsWN1zytWrMjHH3/MsGHD+P777wGYMWMGQUFButcAtWvfXySpb9++LFy4kBdffBGAX3/9lQoVKui15k2J0VvU3333HRUrVsTGxoaQkBC9X2u5SU5OZsSIEXh7e2NtbU21atUe+wdnSv6IvEBmtoZa3k7UL+9i7HCEEAUoKChI73VaWhpvvfUWNWvWxMXFBQcHB2JjYx/boq5bt67uub29PU5OTrpZrnJjZ2enS9KgnQnrXvmbN2+SmJhIcHCwbr+5uTkNGzZ8ZAxqtZqpU6cSEBBAmTJlcHBwYMOGDbrYY2NjycjIoG3btrkeHxUVRWBgoC5JP6nc4ty0aRNt27bF19cXR0dHBgwYwLVr17h165buvfOKC+CVV17h33//5eJF7Z03ixYtYtCgQSY7XsioLeoVK1Ywbtw45s6dS0hICLNmzSI0NJTjx4/j4ZFzOs3MzEyeffZZPDw8+P333/H19eX8+fO4uLgUffBPQKO5P4isf2M/k/2jEKKo2VqaE/NRqNHeu6A8PHr7rbfeYuPGjXzxxRdUrVoVW1tbevbsSWZm5iPPY2lpqfdapVI98pJxbuWf9pL+559/ztdff82sWbN0/cFjx47VxX5v5q28PG6/mZlZjhhzmxjk4To9d+4czz33HMOHD2fatGmUKVOGHTt2MHToUDIzM7Gzs3vsewcGBlKvXj1+/vln2rdvz9GjR1m3bt0jjzEmo7aoZ86cySuvvMLgwYOpVasWc+fOxc7OjgULFuRafsGCBVy/fp01a9bQrFkzKlasSMuWLfUuLZmy3WeucfZqOg7WFnSt72PscIQwGSqVCjsrC6M8CvMH886dOxk0aBDdu3cnICAALy8vzp07V2jvlxtnZ2c8PT2JiIjQbVOr1URGRj7yuJ07d9K1a1f69+9PvXr1qFy5MidOnNDt9/f3x9bWlvDw8FyPr1u3LlFRUXn2rZctW1ZvwBtoW8KPc+DAATQaDV9++SWNGzemWrVqXLp0Kcd75xXXPS+//DKLFi1i4cKFtGvXjvLlTXd2SKMl6szMTA4cOEC7du3uB2NmRrt27di9e3eux6xdu5YmTZowYsQIPD09qVOnDp988glqtWG3RxnLr3u0g8i6B/piby3DA4Qo6fz9/Vm1ahVRUVFER0fTt29fgwdTFYRRo0Yxffp0/vzzT44fP86YMWO4cePGI3+k+Pv7s3HjRnbt2kVsbCyvvfYaiYmJuv02NjaMHz+ed955h59//pnTp0+zZ88efvrpJwD69OmDl5cX3bp1Y+fOnZw5c4Y//vhD9/3epk0b9u/fz88//8zJkyeZMmUKR44ceexnqVq1KllZWcyePZszZ87wyy+/6AaZ3TNhwgQiIiJ4/fXXOXToEMeOHWPOnDlcvXpVV6Zv375cuHCB+fPnm+wgsnuMlqivXr2KWq3WjRC8x9PTk4SEhFyPOXPmDL///jtqtZq///6bSZMm8eWXX/Lxxx/n+T4ZGRmkpKToHqmpqQX6OfIrMeUO/8Zo/8j7ySAyIUqFmTNn4urqStOmTenSpQuhoaE0aNCgyOMYP348ffr0YeDAgTRp0gQHBwdCQ0Oxscl76uKJEyfSoEEDQkNDadWqlS7pPmjSpEm8+eabTJ48mZo1a/LSSy/p+satrKz4999/8fDwoFOnTgQEBPDpp5/qFqcIDQ1l0qRJvPPOOzRq1IjU1FQGDhz42M9Sr149Zs6cyWeffUadOnVYsmQJ06dP1ytTrVo1/v33X6KjowkODqZJkyb8+eefeve1Ozs706NHDxwcHB55m5pJUIzk4sWLCqDs2rVLb/vbb7+tBAcH53qMv7+/Ur58eSU7O1u37csvv1S8vLzyfJ8pU6YoQI5HfHx8wXyQfPp60wnFb/xfSo/vdxbp+wphim7fvq3ExMQot2/fNnYopZJarVaqVaumTJw40dihGFWbNm2UUaNGFdr5H/V3Hh8fn+9cZLQWtbu7O+bm5nqXUgASExPznHXH29ubatWq6S0XVrNmTRISEvIcnDFhwgRu3rype8TExBTch8inbLWGZfu0g8ikNS2EKGrnz59n/vz5nDhxgsOHDzN8+HDOnj1L3759jR2aUdy4cYPVq1ezdetWRowYYexwHstoidrKyoqGDRvqdfhrNBrCw8Np0qRJrsc0a9aMU6dO6fXxnDhxAm9v7zynlbO2tsbJyUn3cHR0LNgPkg9bjl/h8s07uNpZ0rHO0y0gLoQQhjIzM2PRokU0atSIZs2acfjwYTZt2kTNmjWNHZpRBAYGMmjQID777DOqV69u7HAey6gjmsaNG0dYWBhBQUEEBwcza9Ys0tPTGTx4MAADBw7E19dX1/8wfPhwvv32W8aMGcOoUaM4efIkn3zyCaNHjzbmx3isezOR9Qoqj00B3goihBD5Ub58eXbu3GnsMExGUY+8f1pGTdQvvfQSV65cYfLkySQkJFC/fn3Wr1+vG2AWFxeHmdn9Rn/58uXZsGEDb7zxBnXr1sXX15cxY8Ywfvx4Y32Ex4q/fov/TlwBoE+wXPYWQghhGKPfIzRy5Mg8p9LbunVrjm1NmjRhz549hRxVwVm6Lw5FgWf83anonv+l7IQQQggwgSlES7KMbDW/RcQD0C/Ez8jRCCGEKI4kURei9UcSuJaeiaeTNe1q5pwSVQghhHgcSdSF6N683r0bVcDCXKpaCCGE4SR7FJITiansO3sdczOVDCITQgjxxCRRF5Kld1vTbWt44OWc9zR9QojSpVWrVjnWU541a9Yjj1GpVKxZs+ap37ugziOKliTqQnArM5s/DlwAtMtZCiGKvy5dutChQ4dc923fvh2VSsWhQ4cMPm9ERASvvvrq04an54MPPqB+/fo5tl++fJmOHTsW6HuJwieJuhD8L/oSqRnZ+LnZ0byqu7HDEUIUgKFDh7Jx40YuXLiQY9/ChQsJCgqibt26Bp+3bNmy2NnZFUSIj+Xl5YW1tXWRvJcpedz636ZOEnUh+HWP9rJ33+AKmJkV3lq3Qoii89xzz1G2bFkWLVqktz0tLY2VK1cydOhQrl27Rp8+ffD19cXOzo6AgACWLVv2yPM+fOn75MmTtGjRAhsbG2rVqsXGjRtzHDN+/HiqVauGnZ0dlStXZtKkSWRlZQGwaNEiPvzwQ6Kjo1GpVKhUKl3MD1/6Pnz4MG3atMHW1hY3NzdeffVV0tLSdPsHDRpEt27d+OKLL/D29sbNzY0RI0bo3is3p0+fpmvXrnh6euLg4ECjRo3YtGmTXpmMjAzGjx9P+fLlsba2pmrVqrrlMQGOHj3Kc889p5v2+ZlnnuH06dNAzq4DgG7dujFo0CC9Op06dSoDBw7EyclJd8XiUfV2z//+9z8aNWqEjY0N7u7udO/eHYCPPvqIOnXq5Pi89evXZ9KkSXnWR0GQRF3ADl1I5vDFm1iZm9GzYTljhyNE8ZKZbvhDnX3/eHW2dlvW7fyd1wAWFhYMHDiQRYsWoSiKbvvKlStRq9X06dOHO3fu0LBhQ9atW8eRI0d49dVXGTBgAPv27cvXe2g0Gl544QWsrKzYu3cvc+fOzXXmRUdHRxYtWkRMTAxff/018+fP56uvvgK0Mz6++eab1K5dm8uXL3P58mVeeumlHOdIT08nNDQUV1dXIiIiWLlyJZs2bcoxAdWWLVs4ffo0W7ZsYfHixSxatCjHj5UHpaWl0alTJ8LDwzl48CAdOnSgS5cuxMXF6coMHDiQZcuW8c033xAbG8sPP/yAg4MDABcvXqRFixZYW1uzefNmDhw4wJAhQ8jOzs7rLXP1xRdfUK9ePQ4ePKhLpI+qN4B169bRvXt3OnXqxMGDBwkPDyc4OBiAIUOGEBsbS0REhK78wYMHOXTokG7a60JTCCt7mTRDlhZ7Em+vjFL8xv+ljFkWWSjnF6IkyHP5vylOhj+OrLp//JFV2m0LOumf97NKuR9roNjYWAVQtmzZotv2zDPPKP3798/zmM6dOytvvvmm7nXLli2VMWPG6F77+fkpX331laIoirJhwwbFwsJCuXjxom7/P//8owDK6tWr83yPzz//XGnYsKHu9ZQpU5R69erlKPfgeebNm6e4uroqaWlpuv3r1q1TzMzMlISEBEVRFCUsLEzx8/PTW1r4xRdfVF566aU8Y8lN7dq1ldmzZyuKoijHjx9XAGXjxo25lp0wYYJSqVIlJTMzM9f9D9efoihK165dlbCwMN1rPz8/pVu3bo+N6+F6a9KkidKvX788y3fs2FEZPny47vWoUaOUVq1a5Vm+2C9zWRLdvJ3F2uhLAPSTQWRClDg1atSgadOmLFiwAIBTp06xfft2hg4dCoBarWbq1KkEBARQpkwZHBwc2LBhg15r8lFiY2MpX748Pj4+um25rSa4YsUKmjVrhpeXFw4ODkycODHf7/Hge9WrVw97+/tTGzdr1gyNRsPx48d122rXrq23tLC3tzdJSUl5njctLY233nqLmjVr4uLigoODA7Gxsbr4oqKiMDc3p2XLlrkeHxUVxTPPPIOlpaVBn+dhQUFBObY9rt6ioqJo27Ztnud85ZVXWLZsGXfu3CEzM5OlS5cyZMiQp4ozP4w+13dJsiryAneyNFT3dCTIz9XY4QhR/Lx3yfBjzB8YHFWji/YcqofaIGMPP11cDxg6dCijRo3iu+++Y+HChVSpUkWXdD7//HO+/vprZs2aRUBAAPb29owdO7ZABzPt3r2bfv368eGHHxIaGoqzszPLly/nyy+/LLD3eNDDCVOlUuktNfywt956i40bN/LFF19QtWpVbG1t6dmzp64ObG1tH/l+j9tvZmam1/UA5Npn/uAPEMhfvT3uvbt06YK1tTWrV6/GysqKrKwsevbs+chjCoK0qAuIoii6mcj6Na6ASiWDyIQwmJW94Q/zB9ob5hbabZa2+TvvE+jVqxdmZmYsXbqUn3/+mSFDhuj+f9+5cyddu3alf//+1KtXj8qVK3PixIl8n7tmzZrEx8dz+fJl3baHFyHatWsXfn5+vP/++wQFBeHv78/58+f1P66VFWq1+rHvFR0dTXr6/b76nTt3YmZm9lRrNO/cuZNBgwbRvXt3AgIC8PLy0ltWMiAgAI1Gw3///Zfr8XXr1mX79u15DlgrW7asXv2o1WqOHDny2LjyU29169YlPDw8z3NYWFgQFhbGwoULWbhwIb17935sci8IkqgLyN6z1zmVlIadlTndA32NHY4QopA4ODjw0ksvMWHCBC5fvqw32tjf35+NGzeya9cuYmNjee2110hMTMz3udu1a0e1atUICwsjOjqa7du38/777+uV8ff3Jy4ujuXLl3P69Gm++eYbVq9erVemYsWKnD17lqioKK5evUpGRkaO9+rXrx82NjaEhYVx5MgRtmzZwqhRoxgwYIBuqeEn4e/vz6pVq4iKiiI6Opq+ffvqtcArVqxIWFgYQ4YMYc2aNZw9e5atW7fy22+/AdoVFVNSUujduzf79+/n5MmT/PLLL7rL8W3atGHdunWsW7eOY8eOMXz4cJKTk/MV1+PqbcqUKSxbtowpU6YQGxvL4cOH+eyzz/TKvPzyy2zevJn169cXyWVvkERdYO61prvW98HR5un6VoQQpm3o0KHcuHGD0NBQvf7kiRMn0qBBA0JDQ2nVqhVeXl5069Yt3+c1MzNj9erV3L59m+DgYF5++WWmTZumV+b555/njTfeYOTIkdSvX59du3bluD2oR48edOjQgdatW1O2bNlcbxGzs7Njw4YNXL9+nUaNGtGzZ0/atm3Lt99+a1hlPGTmzJm4urrStGlTunTpQmhoKA0aNNArM2fOHHr27Mnrr79OjRo1eOWVV3Qtezc3NzZv3kxaWhotW7akYcOGzJ8/X3cJfsiQIYSFhTFw4EBatmxJ5cqVad269WPjyk+9tWrVipUrV7J27Vrq169PmzZtcozY9/f3p2nTptSoUYOQkJCnqap8UykPX+wv4S5cuED58uWJj4+nXLmCuX3qSmoGTT8NJ0ut8Neo5tTxdS6Q8wpRUt25c4ezZ89SqVIlbGxkil1RfCiKgr+/P6+//jrjxo17ZNlH/Z0bkotkMFkB+G1/PFlqhfrlXSRJCyFECXXlyhWWL19OQkJC4d87/QBJ1E9JrVFYtu/uILIQWSVLCCFKKg8PD9zd3Zk3bx6urkV3Z48k6qe07cQVLty4jZONBV3q+Tz+ACGEEMWSsXqKZTDZU1qyVzu8v2fD8thYmj+mtBBCCGEYSdRP4WLybTYf087Q06+xXPYWQghR8CRRP4Xl++LQKNCkshtVyjoYOxwhip1SdtOJKGUK6u9bEvUTUhSFNVEXAegv83oLYZB798TeunXLyJEIUXju/X0/7bzlMpjsCalUKtaOaM6aqIs8W+vJZ/ERojQyNzfHxcVFt7iDnZ2dTLsrSgxFUbh16xZJSUm4uLjoLWryJCRRPwVXeysGN6tk7DCEKJa8vLwAHrkSkxDFmYuLi+7v/GlIohZCGIVKpcLb2xsPD488F2AQoriytLR86pb0PZKohRBGZW5uXmBfaEKURDKYTAghhDBhkqiFEEIIEyaJWgghhDBhpa6P+t4C5pcvXzZyJEIIIUqreznoXk56lFKXqBMTEwEIDg42ciRCCCFKu8TERCpUePQU1CqllM3hl52dzcGDB/H09MTM7Omu/KemplKrVi1iYmJwdHQsoAhLLqkvw0mdGUbqyzBSX4YpyPrSaDQkJiYSGBiIhcWj28ylLlEXpJSUFJydnbl58yZOTk7GDsfkSX0ZTurMMFJfhpH6Moyx6ksGkwkhhBAmTBK1EEIIYcIkUT8Fa2trpkyZgrW1tbFDKRakvgwndWYYqS/DSH0Zxlj1JX3UQgghhAmTFrUQQghhwiRRCyGEECZMErUQQghhwiRRP4XvvvuOihUrYmNjQ0hICPv27TN2SCZp+vTpNGrUCEdHRzw8POjWrRvHjx83dljFxqeffopKpWLs2LHGDsVkXbx4kf79++Pm5oatrS0BAQHs37/f2GGZJLVazaRJk6hUqRK2trZUqVKFqVOnIsOV7tu2bRtdunTBx8cHlUrFmjVr9PYrisLkyZPx9vbG1taWdu3acfLkyUKLRxL1E1qxYgXjxo1jypQpREZGUq9ePUJDQ0lKSjJ2aCbnv//+Y8SIEezZs4eNGzeSlZVF+/btSU9PN3ZoJi8iIoIffviBunXrGjsUk3Xjxg2aNWuGpaUl//zzDzExMXz55Ze4uroaOzST9NlnnzFnzhy+/fZbYmNj+eyzz5gxYwazZ882dmgmIz09nXr16vHdd9/lun/GjBl88803zJ07l71792Jvb09oaCh37twpnIAU8USCg4OVESNG6F6r1WrFx8dHmT59uhGjKh6SkpIUQPnvv/+MHYpJS01NVfz9/ZWNGzcqLVu2VMaMGWPskEzS+PHjlebNmxs7jGKjc+fOypAhQ/S2vfDCC0q/fv2MFJFpA5TVq1frXms0GsXLy0v5/PPPdduSk5MVa2trZdmyZYUSg7Son0BmZiYHDhygXbt2um1mZma0a9eO3bt3GzGy4uHmzZsAlClTxsiRmLYRI0bQuXNnvb8zkdPatWsJCgrixRdfxMPDg8DAQObPn2/ssExW06ZNCQ8P58SJEwBER0ezY8cOOnbsaOTIioezZ8+SkJCg9/+ls7MzISEhhfb9X+pWzyoIV69eRa1W4+npqbfd09OTY8eOGSmq4kGj0TB27FiaNWtGnTp1jB2OyVq+fDmRkZFEREQYOxSTd+bMGebMmcO4ceN47733iIiIYPTo0VhZWREWFmbs8EzOu+++S0pKCjVq1MDc3By1Ws20adPo16+fsUMrFhISEgBy/f6/t6+gSaIWRWrEiBEcOXKEHTt2GDsUkxUfH8+YMWPYuHEjNjY2xg7H5Gk0GoKCgvjkk08ACAwM5MiRI8ydO1cSdS5+++03lixZwtKlS6lduzZRUVGMHTsWHx8fqS8TJZe+n4C7uzvm5ua6ta3vSUxMxMvLy0hRmb6RI0fy119/sWXLFsqVK2fscEzWgQMHSEpKokGDBlhYWGBhYcF///3HN998g4WFBWq12tghmhRvb29q1aqlt61mzZrExcUZKSLT9vbbb/Puu+/Su3dvAgICGDBgAG+88QbTp083dmjFwr3v+KL8/pdE/QSsrKxo2LAh4eHhum0ajYbw8HCaNGlixMhMk6IojBw5ktWrV7N582YqVapk7JBMWtu2bTl8+DBRUVG6R1BQEP369SMqKgpzc3Njh2hSmjVrluN2vxMnTuDn52ekiEzbrVu3MDPT/+o3NzdHo9EYKaLipVKlSnh5eel9/6ekpLB3795C+/6XS99PaNy4cYSFhREUFERwcDCzZs0iPT2dwYMHGzs0kzNixAiWLl3Kn3/+iaOjo64fx9nZGVtbWyNHZ3ocHR1z9N/b29vj5uYm/fq5eOONN2jatCmffPIJvXr1Yt++fcybN4958+YZOzST1KVLF6ZNm0aFChWoXbs2Bw8eZObMmQwZMsTYoZmMtLQ0Tp06pXt99uxZoqKiKFOmDBUqVGDs2LF8/PHH+Pv7U6lSJSZNmoSPjw/dunUrnIAKZSx5KTF79mylQoUKipWVlRIcHKzs2bPH2CGZJCDXx8KFC40dWrEht2c92v/+9z+lTp06irW1tVKjRg1l3rx5xg7JZKWkpChjxoxRKlSooNjY2CiVK1dW3n//fSUjI8PYoZmMLVu25PqdFRYWpiiK9hatSZMmKZ6enoq1tbXStm1b5fjx44UWj6yeJYQQQpgw6aMWQgghTJgkaiGEEMKESaIWQgghTJgkaiGEEMKESaIWQgghTJgkaiGEEMKESaIWQgghTJgkaiGEEMKESaIWQhQalUrFmjVrjB2GEMWaJGohSqhBgwahUqlyPDp06GDs0IQQBpBFOYQowTp06MDChQv1tllbWxspGiHEk5AWtRAlmLW1NV5eXnoPV1dXQHtZes6cOXTs2BFbW1sqV67M77//rnf84cOHadOmDba2tri5ufHqq6+SlpamV2bBggXUrl0ba2trvL29GTlypN7+q1ev0r17d+zs7PD392ft2rW6fTdu3KBfv36ULVsWW1tb/P39c/ywEKK0k0QtRCk2adIkevToQXR0NP369aN3797ExsYCkJ6eTmhoKK6urkRERLBy5Uo2bdqkl4jnzJnDiBEjePXVVzl8+DBr166latWqeu/x4Ycf0qtXLw4dOkSnTp3o168f169f171/TEwM//zzD7GxscyZMwd3d/eiqwAhioNCW5dLCGFUYWFhirm5uWJvb6/3mDZtmqIo2uVHhw0bpndMSEiIMnz4cEVRFGXevHmKq6urkpaWptu/bt06xczMTElISFAURVF8fHyU999/P88YAGXixIm612lpaQqg/PPPP4qiKEqXLl2UwYMHF8wHFqKEkj5qIUqw1q1bM2fOHL1tZcqU0T1v0qSJ3r4mTZoQFRUFQGxsLPXq1cPe3l63v1mzZmg0Go4fP45KpeLSpUu0bdv2kTHUrVtX99ze3h4nJyeSkpIAGD58OD169CAyMpL27dvTrVs3mjZt+kSfVYiSShK1ECWYvb19jkvRBcXW1jZf5SwtLfVeq1QqNBoNAB07duT8+fP8/fffbNy4kbZt2zJixAi++OKLAo9XiOJK+qiFKMX27NmT43XNmjUBqFmzJtHR0aSnp+v279y5EzMzM6pXr46joyMVK1YkPDz8qWIoW7YsYWFh/Prrr8yaNYt58+Y91fmEKGmkRS1ECZaRkUFCQoLeNgsLC92ArZUrVxIUFETz5s1ZsmQJ+/bt46effgKgX79+TJkyhbCwMD744AOuXLnCqFGjGDBgAJ6engB88MEHDBs2DA8PDzp27Ehqaio7d+5k1KhR+Ypv8uTJNGzYkNq1a5ORkcFff/2l+6EghNCSRC1ECbZ+/Xq8vb31tlWvXp1jx44B2hHZy5cv5/XXX8fb25tly5ZRq1YtAOzs7NiwYQNjxoyhUaNG2NnZ0aNHD2bOnKk7V1hYGHfu3OGrr77irbfewt3dnZ49e+Y7PisrKyZMmMC5c+ewtbXlmWeeYfny5QXwyYUoOVSKoijGDkIIUfRUKhWrV6+mW7duxg5FCPEI0kcthBBCmDBJ1EIIIYQJkz5qIUop6fUSoniQFrUQQghhwiRRCyGEECZMErUQQghhwiRRCyGEECZMErUQQghhwiRRCyGEECZMErUQQghhwiRRCyGEECZMErUQQghhwv4PoWaY/ind1fIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gweur0aXa78d",
        "outputId": "6b2087e7-1e50-45dc-cbec-9ff878d43b81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 87.60%\n",
            "Validation accuracy: 90.60%\n",
            "Test accuracy: 89.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using LLM as a spam classifier**"
      ],
      "metadata": {
        "id": "wO00PPR4dEUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_review(\n",
        " text, model, tokenizer, device, max_length=None,\n",
        " pad_token_id=50256):\n",
        " model.eval()\n",
        "\n",
        " input_ids = tokenizer.encode(text)   # Prepares inputs to the model\n",
        " supported_context_length = model.pos_emb.weight.shape[1]\n",
        "\n",
        " input_ids = input_ids[:min(      #Truncates the sequence if they are too long\n",
        " max_length, supported_context_length\n",
        " )]\n",
        "\n",
        " input_ids += [pad_token_id] * (max_length - len(input_ids)) # Pads sequences to the longest sequence\n",
        "\n",
        " input_tensor = torch.tensor(\n",
        " input_ids, device=device\n",
        " ).unsqueeze(0) #Adds batch dimension\n",
        "\n",
        " with torch.no_grad(): #Model inference without gradient tracking\n",
        "  logits = model(input_tensor)[:, -1, :]\n",
        " predicted_label = torch.argmax(logits, dim=-1).item()\n",
        " return \"spam\" if predicted_label == 1 else \"not spam\" # Returns classified results"
      ],
      "metadata": {
        "id": "Ich3sgPpbOKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = (\n",
        " \"You are a winner you have been specially\"\n",
        " \" selected to receive $1000 cash or a $2000 award.\"\n",
        ")\n",
        "print(classify_review(\n",
        " text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cv8Cnn2euXb",
        "outputId": "5b05e10e-c62d-40a6-dd90-99826e5ba0f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = (\n",
        " \"Hey, just wanted to check if we're still on\"\n",
        " \" for dinner tonight? Let me know!\"\n",
        ")\n",
        "print(classify_review(\n",
        " text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl0ss1Rye3Vg",
        "outputId": "1dd07190-c668-4b82-d0a8-4ec068883cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the model"
      ],
      "metadata": {
        "id": "Vv-LQlsjfExv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"review_classifier.pth\")"
      ],
      "metadata": {
        "id": "Whuk9_8Ye73a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instruction fine-tuning"
      ],
      "metadata": {
        "id": "o_r_-04kvA7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instruction fine-tuning involves training a model on a dataset where the input-output\n",
        "pairs, are explicitly provided."
      ],
      "metadata": {
        "id": "g6flYbYUwqs8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preparation**"
      ],
      "metadata": {
        "id": "glzWg3mNvJqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import urllib"
      ],
      "metadata": {
        "id": "EXUPD-F3vjlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading dataset\n",
        "def download_and_load_file(file_path, url):\n",
        "  if not os.path.exists(file_path):\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "      text_data = response.read().decode(\"utf-8\")\n",
        "\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "      file.write(text_data)\n",
        "  else:\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "      text_data = file.read()\n",
        "    with open(file_path, \"r\") as file:\n",
        "      data = json.load(file)\n",
        "\n",
        "    return data\n",
        "\n",
        "file_path = \"instruction-data.json\"\n",
        "url = (\n",
        " \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
        " \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
        ")\n",
        "\n",
        "data = download_and_load_file(file_path, url)\n",
        "print(\"Number of entries:\", len(data))"
      ],
      "metadata": {
        "id": "JJNSlwDmfIKe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "4c32629f-7647-4698-c10c-344a503b35d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-8e0d9400d670>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_and_load_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of entries:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Example entry:\\n\", data[50])"
      ],
      "metadata": {
        "id": "5ji73PmqwGWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Another example entry:\\n\", data[999])"
      ],
      "metadata": {
        "id": "c5S-1HDbwSK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing prompt formating"
      ],
      "metadata": {
        "id": "QgY6ZN0Mx45u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alpaca style format"
      ],
      "metadata": {
        "id": "3ggmdPXPyIU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def format_input(entry):\n",
        "  instruction_text = (\n",
        "  f\"Below is an instruction that describes a task. \"\n",
        "  f\"Write a response that appropriately completes the request.\"\n",
        "  f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "  )\n",
        "\n",
        "  input_text = (\n",
        "  f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "  )\n",
        "  return instruction_text + input_text"
      ],
      "metadata": {
        "id": "bN6ucSn2wc0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_input = format_input(data[50])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
        "print(model_input + desired_response)"
      ],
      "metadata": {
        "id": "MNsq8tF7yR4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_input = format_input(data[999])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
        "print(model_input + desired_response)"
      ],
      "metadata": {
        "id": "CYi26CF4yYY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divide dataset to training, validation and test sets"
      ],
      "metadata": {
        "id": "AYfUydOUyPz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_portion = int(len(data) * 0.85)\n",
        "test_portion = int(len(data) * 0.1)\n",
        "val_portion = len(data) - train_portion - test_portion\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]\n",
        "\n",
        "print(\"Training set length:\", len(train_data))\n",
        "print(\"Validation set length:\", len(val_data))\n",
        "print(\"Test set length:\", len(test_data))"
      ],
      "metadata": {
        "id": "RUCCG1Xpx-f5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Organizing data into training batches**"
      ],
      "metadata": {
        "id": "RS2qfWZNzCL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batching process"
      ],
      "metadata": {
        "id": "8erPg9es0qbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "class InstructionDataset(Dataset):\n",
        "  def __init__(self, data, tokenizer):\n",
        "    self.data = data\n",
        "    self.encoded_texts = []\n",
        "    for entry in data:\n",
        "      instruction_plus_input = format_input(entry)\n",
        "      response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "      full_text = instruction_plus_input + response_text\n",
        "      self.encoded_texts.append(\n",
        "      tokenizer.encode(full_text)\n",
        "      )\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.encoded_texts[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "metadata": {
        "id": "enuPjHn7y6xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing padding process with a custom collate function"
      ],
      "metadata": {
        "id": "e3rEMbWT18pC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_draft_1(batch,pad_token_id=50256,device=\"cpu\"):\n",
        " batch_max_length = max(len(item)+1 for item in batch) # Find the longest sequence in the batch\n",
        " inputs_lst = []\n",
        "\n",
        "#Pads and prepares input\n",
        " for item in batch:\n",
        "  new_item = item.copy()\n",
        "  new_item += [pad_token_id]\n",
        "\n",
        "  padded = (\n",
        "  new_item + [pad_token_id] *\n",
        "  (batch_max_length - len(new_item))\n",
        "  )\n",
        "\n",
        "  inputs = torch.tensor(padded[:-1]) #Removes extra padded token added earlier\n",
        "  inputs_lst.append(inputs)\n",
        "\n",
        " inputs_tensor = torch.stack(inputs_lst).to(device) #Converts the lists of inputs to tensor and transfers it to the target device\n",
        " return inputs_tensor"
      ],
      "metadata": {
        "id": "ZDMSjBB708PH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "batch = (\n",
        " inputs_1,\n",
        " inputs_2,\n",
        " inputs_3\n",
        ")\n",
        "print(custom_collate_draft_1(batch))"
      ],
      "metadata": {
        "id": "3zWrFqXl3B0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Updated collate function generates the target token IDs from the input\n",
        "token IDs"
      ],
      "metadata": {
        "id": "ODVpjpRp3yND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_draft_2(\n",
        " batch,\n",
        " pad_token_id=50256,\n",
        " device=\"cpu\"\n",
        "):\n",
        "\n",
        " batch_max_length = max(len(item)+1 for item in batch)\n",
        " inputs_lst, targets_lst = [], []\n",
        "\n",
        " for item in batch:\n",
        "  new_item = item.copy()\n",
        "  new_item += [pad_token_id]\n",
        "\n",
        "  padded = (\n",
        "  new_item + [pad_token_id] *\n",
        "  (batch_max_length - len(new_item))\n",
        "  )\n",
        "  inputs = torch.tensor(padded[:-1])\n",
        "  targets = torch.tensor(padded[1:])\n",
        "  inputs_lst.append(inputs)\n",
        "  targets_lst.append(targets)\n",
        "\n",
        " inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        " targets_tensor = torch.stack(targets_lst).to(device)\n",
        " return inputs_tensor, targets_tensor\n",
        "\n",
        "inputs, targets = custom_collate_draft_2(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "id": "lrZ4PkdE3Lfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Update collate function to replace the padding tokens with placeholder(-100)"
      ],
      "metadata": {
        "id": "zrB5huHa5zWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(batch,pad_token_id=50256,ignore_index=-100,\n",
        " allowed_max_length=None,\n",
        " device=\"cpu\"\n",
        "):\n",
        "\n",
        " batch_max_length = max(len(item)+1 for item in batch)\n",
        " inputs_lst, targets_lst = [], []\n",
        " for item in batch:\n",
        "  new_item = item.copy()\n",
        "  new_item += [pad_token_id]\n",
        "\n",
        "  # Pads sequence to the max length\n",
        "  padded = (\n",
        "    new_item + [pad_token_id] *\n",
        "    (batch_max_length - len(new_item))\n",
        "    )\n",
        "\n",
        "  inputs = torch.tensor(padded[:-1]) # Truncates the last token for inputs\n",
        "  targets = torch.tensor(padded[1:]) # Shifts +1 to the right for targets\n",
        "\n",
        "# Replace all but the first padding tokens in targets by ignore_index\n",
        "  mask = targets == pad_token_id\n",
        "  indices = torch.nonzero(mask).squeeze()\n",
        "  if indices.numel() > 1:\n",
        "    targets[indices[1:]] = ignore_index\n",
        "\n",
        "  # Optionally truncates to the max sequence length\n",
        "  if allowed_max_length is not None:\n",
        "    inputs = inputs[:allowed_max_length]\n",
        "  targets = targets[:allowed_max_length]\n",
        "\n",
        "  inputs_lst.append(inputs)\n",
        "  targets_lst.append(targets)\n",
        "\n",
        " inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        " targets_tensor = torch.stack(targets_lst).to(device)\n",
        " return inputs_tensor, targets_tensor"
      ],
      "metadata": {
        "id": "L0jkbvcb4NrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, targets = custom_collate_fn(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "id": "koRynGwC7kJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building Dataloader"
      ],
      "metadata": {
        "id": "dpaBqG2AZZTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "customized_collate_fn = partial(\n",
        " custom_collate_fn,\n",
        " device=device,\n",
        " allowed_max_length=1024\n",
        ")"
      ],
      "metadata": {
        "id": "NqkKjruz7pfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken\n",
        "import tiktoken\n",
        "# Define the tokenizer here\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "2d4TvE8vaTrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "torch.manual_seed(123)\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        " train_dataset,\n",
        " batch_size=batch_size,\n",
        " collate_fn=customized_collate_fn,\n",
        " shuffle=True,\n",
        " drop_last=True,\n",
        " num_workers=num_workers\n",
        ")\n",
        "\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        " val_dataset,\n",
        " batch_size=batch_size,\n",
        " collate_fn=customized_collate_fn,\n",
        " shuffle=False,\n",
        " drop_last=False,\n",
        " num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        " test_dataset,\n",
        " batch_size=batch_size,\n",
        " collate_fn=customized_collate_fn,\n",
        " shuffle=False,\n",
        " drop_last=False,\n",
        " num_workers=num_workers\n",
        ")"
      ],
      "metadata": {
        "id": "jKcaVaFXZfDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader:\")\n",
        "for inputs, targets in train_loader:\n",
        " print(inputs.shape, targets.shape)"
      ],
      "metadata": {
        "id": "faEWfykUaA2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading a pretrained LLM**"
      ],
      "metadata": {
        "id": "hFmVgYFRapdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "from chapter04 import GPTModel\n",
        "from chapter05 import load_weights_into_gpt\n",
        "BASE_CONFIG = {\n",
        " \"vocab_size\": 50257, # Vocabulary size\n",
        " \"context_length\": 1024, # Context length\n",
        " \"drop_rate\": 0.0, # Dropout rate\n",
        " \"qkv_bias\": True # Query-key-value bias\n",
        "}\n",
        "model_configs = {\n",
        " \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        " \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        " \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        " \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(\n",
        " model_size=model_size,\n",
        " models_dir=\"gpt2\"\n",
        ")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ],
      "metadata": {
        "id": "EHQXn8jxafMm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}