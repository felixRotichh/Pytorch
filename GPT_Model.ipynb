{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOFRQ+6vR9KM+vP3MpcbH1X"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyLEgAZs3-Be",
        "outputId": "0aee3317-4631-4930-f225-b87aa0e3ffb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tp8rop76re4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        " \"vocab_size\": 50257, # Vocabulary size\n",
        " \"context_length\": 1024, # Context length\n",
        " \"emb_dim\": 768, # Embedding dimension\n",
        " \"n_heads\": 12, # Number of attention heads\n",
        " \"n_layers\": 12, # Number of layers\n",
        " \"drop_rate\": 0.1, # Dropout rate\n",
        " \"qkv_bias\": False # Query-Key-Value bias\n",
        "}"
      ],
      "metadata": {
        "id": "D_5syb9L-g7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length,\n",
        "                 dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads) == 0, \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.tril(torch.ones(context_length, context_length)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        keys = keys.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "\n",
        "        attn_scores = queries @ keys.transpose(2,3)\n",
        "\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "        attn_scores.masked_fill_(~mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(\n",
        "                attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = (attn_weights @ values).transpose(1,2)\n",
        "        context_vec = context_vec.contiguous().view(\n",
        "                b, num_tokens, self.d_out\n",
        "            )\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "        return context_vec\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        " def __init__(self, emb_dim):\n",
        "  super().__init__()\n",
        "  self.eps = 1e-6\n",
        "  self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "  self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        " def forward(self, x):\n",
        "  mean = x.mean(dim=-1, keepdim=True)\n",
        "  var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "  norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "  return self.scale * norm_x + self.shift\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "    nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "    nn.GELU(),\n",
        "    nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.att = MultiHeadAttention(\n",
        "    d_in=cfg[\"emb_dim\"],\n",
        "    d_out=cfg[\"emb_dim\"],\n",
        "    context_length=cfg[\"context_length\"],\n",
        "    num_heads=cfg[\"n_heads\"],\n",
        "    dropout=cfg[\"drop_rate\"],\n",
        "    qkv_bias=cfg[\"qkv_bias\"])\n",
        "    self.ff = FeedForward(cfg)\n",
        "    self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "  def forward(self, x):\n",
        "    shortcut = x\n",
        "    x = self.norm1(x)\n",
        "    x = self.att(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "    shortcut = x\n",
        "    x = self.norm2(x)\n",
        "    x = self.ff(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "    return x\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        " def __init__(self, cfg):\n",
        "  super().__init__()\n",
        "  self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "  self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "  self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "  self.trf_blocks = nn.Sequential(\n",
        "  *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "  self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "  self.out_head = nn.Linear(\n",
        "  cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "  )\n",
        " def forward(self, in_idx):\n",
        "  batch_size, seq_len = in_idx.shape\n",
        "  tok_embeds = self.tok_emb(in_idx)\n",
        "\n",
        "  pos_embeds = self.pos_emb(\n",
        "  torch.arange(seq_len, device=in_idx.device)\n",
        "  )\n",
        "  x = tok_embeds + pos_embeds\n",
        "  x = self.drop_emb(x)\n",
        "  x = self.trf_blocks(x)\n",
        "  x = self.final_norm(x)\n",
        "  logits = self.out_head(x)\n",
        "  return logits"
      ],
      "metadata": {
        "id": "OKWY9VWZ-Kx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "batch = torch.randint(0, GPT_CONFIG_124M[\"vocab_size\"], (2, GPT_CONFIG_124M[\"context_length\"]))\n",
        "out = model(batch)\n",
        "print(\"Input batch:\\n\", batch)\n",
        "print(\"\\nOutput shape:\", out.shape)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_dX18cq-TG1",
        "outputId": "458d2a32-b5e9-4f57-95a4-4e51fb7ae9cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch:\n",
            " tensor([[33231,  5926, 24713,  ..., 49336, 41648, 32671],\n",
            "        [10172, 27008,  8208,  ..., 13070, 21853,  2501]])\n",
            "\n",
            "Output shape: torch.Size([2, 1024, 50257])\n",
            "tensor([[[ 0.5308,  0.4928, -0.9391,  ..., -1.4309,  0.1997,  0.4656],\n",
            "         [-0.3631,  0.5425,  0.0338,  ..., -0.1140,  0.4920,  1.0638],\n",
            "         [ 0.9737, -0.1625,  0.0723,  ..., -0.2512, -0.4033,  0.6453],\n",
            "         ...,\n",
            "         [-0.1220,  0.2133, -0.2269,  ...,  0.3387, -0.0767,  1.1347],\n",
            "         [-0.0235, -0.0345, -0.2267,  ..., -0.0245, -0.2595,  0.0324],\n",
            "         [-0.4894, -0.2561,  0.3605,  ...,  1.2794,  0.1741,  0.6201]],\n",
            "\n",
            "        [[ 0.7369,  0.0081, -0.8092,  ..., -1.1218,  0.0431,  0.8633],\n",
            "         [-1.1341, -0.3540, -0.9096,  ..., -0.5346,  0.4521,  0.9500],\n",
            "         [ 1.0283, -1.2349, -0.3155,  ...,  0.2146, -0.3040,  0.1514],\n",
            "         ...,\n",
            "         [-0.3694,  0.3291,  0.4069,  ..., -0.4248,  0.3314, -0.3901],\n",
            "         [-0.1029, -0.1202, -0.2995,  ..., -0.0179, -0.1066,  1.1677],\n",
            "         [ 0.2187, -0.2103,  0.7067,  ..., -0.2502,  1.0299,  0.5998]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters: {total_params:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG5OZmArEha5",
        "outputId": "ff645018-8536-4c43-fa14-38381ba5e055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 163,018,752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
        "print(\"Output layer shape:\", model.out_head.weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIiQpP7swD7J",
        "outputId": "7a74307a-848b-45f8-a1f3-a619e8600f2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token embedding layer shape: torch.Size([50257, 768])\n",
            "Output layer shape: torch.Size([50257, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Weight tying reduces the overall memory footprint and computational complexity\n",
        "of the model**"
      ],
      "metadata": {
        "id": "Icrq3hn5yMG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_params_gpt2 = (\n",
        " total_params - sum(p.numel()\n",
        " for p in model.out_head.parameters())\n",
        ")\n",
        "print(f\"Number of trainable parameters \"\n",
        " f\"considering weight tying: {total_params_gpt2:,}\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRKPB9HExpUA",
        "outputId": "f1e5987e-10cb-4f79-8157-4fc430110b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters considering weight tying: 124,421,376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory requirements of the 163 million parameters in our GPTModel object\n",
        "\n",
        "total_size_bytes = total_params * 4\n",
        "total_size_mb = total_size_bytes / (1024 * 1024)\n",
        "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du1TTVHOx00L",
        "outputId": "51b20a52-cf75-4673-f4b6-74ba17340e32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total size of the model: 621.87 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generating Texts**"
      ],
      "metadata": {
        "id": "l2XEg2HJ2o5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_simple(model, idx,\n",
        "  max_new_tokens, context_size):\n",
        "  for _ in range(max_new_tokens):\n",
        "    idx_cond = idx[:, -context_size:]\n",
        "    with torch.no_grad():\n",
        "      logits = model(idx_cond)\n",
        "\n",
        "    logits = logits[:, -1, :]\n",
        "    probas = torch.softmax(logits, dim=-1)\n",
        "    idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "    idx = torch.cat((idx, idx_next), dim=1)\n",
        "    return idx"
      ],
      "metadata": {
        "id": "PgdFoEIxyhxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "start_context = \"Hello, I am\"\n",
        "encoded = tokenizer.encode(start_context)\n",
        "print(\"encoded:\", encoded)\n",
        "\n",
        "encoded_tensor = torch.tensor(encoded).unsqueeze(0) #Add batch dimension\n",
        "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQwQqxrt2xSY",
        "outputId": "084770df-a20f-4130-c5a4-e4af5e3f4bd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoded: [15496, 11, 314, 716]\n",
            "encoded_tensor.shape: torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Put the model into .eval() mode. This disables random components like\n",
        "dropout, which are only used during training**"
      ],
      "metadata": {
        "id": "rdRGexi44x8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "out = generate_text_simple(\n",
        " model=model,\n",
        " idx=encoded_tensor,\n",
        " max_new_tokens=6,\n",
        " context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "print(\"Output:\", out)\n",
        "print(\"Output length:\", len(out[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPc3Yc1b4MbT",
        "outputId": "8c97c5b3-cf41-443e-86b1-5e8b814cd56f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: tensor([[15496,    11,   314,   716, 11595]])\n",
            "Output length: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using the .decode method of the tokenizer, we can convert the IDs back into text**"
      ],
      "metadata": {
        "id": "qW7vAUma5Lvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
        "print(decoded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9_SfNTk5ETc",
        "outputId": "a577bd3f-66c3-434b-85de-e9ef4ccf77da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, I am haz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using GPT to generate text"
      ],
      "metadata": {
        "id": "RcbclCD77Qvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        " \"vocab_size\": 50257,\n",
        " \"context_length\": 256, #Reduced Context length to 256\n",
        " \"emb_dim\": 768,\n",
        " \"n_heads\": 12,\n",
        " \"n_layers\": 12,\n",
        " \"drop_rate\": 0.1,\n",
        " \"qkv_bias\": False\n",
        "}\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxKART6-5RI_",
        "outputId": "38319459-5056-4baf-ee99-e21c531c5230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Utility functions for text to token ids conversion**"
      ],
      "metadata": {
        "id": "gGtqrPc0PO6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_token_ids(text, tokenizer):\n",
        " encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        " encoded_tensor = torch.tensor(encoded).unsqueeze(0) #.unsqueeze(0) adds batch dimension\n",
        " return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        " flat = token_ids.squeeze(0) #removes batch dimension\n",
        " return tokenizer.decode(flat.tolist())"
      ],
      "metadata": {
        "id": "CgIZJEEN7jqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_context = \"Every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        " model=model,\n",
        " idx=text_to_token_ids(start_context, tokenizer),\n",
        " max_new_tokens=10,\n",
        " context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")"
      ],
      "metadata": {
        "id": "NChGX4wQNwq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQANOU6OOUNo",
        "outputId": "d3b66120-1397-49d7-da4c-af9739ac7107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves youLee\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Evaluation"
      ],
      "metadata": {
        "id": "qlqeMPaqWiWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inputs have been mapped to token IDs\n",
        "inputs = torch.tensor([[16833, 3626, 6100], # [\"every effort moves\",\n",
        "                          [40, 1107, 588]]) # \"I really like\"]"
      ],
      "metadata": {
        "id": "qxxHpRYfOgjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Targets contain Token IDs we want the model to produce\n",
        "targets = torch.tensor([[3626, 6100, 345 ], # [\" effort moves you\",\n",
        " [1107, 588, 11311]]) # \" really like chocolate\"]"
      ],
      "metadata": {
        "id": "elmObceaJjy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feed the inputs into model to calculate logits vectors for the inputs\n",
        "**"
      ],
      "metadata": {
        "id": "Yi6BBpddOlcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        " logits = model(inputs)\n",
        "probas = torch.softmax(logits, dim=-1)  #Probability of each token in the vocabulary\n",
        "print(probas.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myk9PF4DKb_Y",
        "outputId": "22dfa37e-08c3-460e-a6b2-513a69e016ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 50257])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Applying argmax function to the probability scores to get token IDs**"
      ],
      "metadata": {
        "id": "rQ8GBKorLeZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "print(\"Token IDs:\\n\", token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It5hS3wFK1_M",
        "outputId": "6efb0654-acc2-4173-8c98-f4428df93562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[[13195],\n",
            "         [41034],\n",
            "         [ 8429]],\n",
            "\n",
            "        [[19385],\n",
            "         [40202],\n",
            "         [23677]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Convert token IDs back into text. The model produces random text that is different from the target text because it has\n",
        "not been trained yet**\n",
        "\n"
      ],
      "metadata": {
        "id": "xRpc22mTL2lK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
        "print(f\"Outputs batch 1:\"\n",
        " f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZQbfDihLsDh",
        "outputId": "3d67e4bb-a14e-441f-9712-7069d806e34e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Targets batch 1:  effort moves you\n",
            "Outputs batch 1: War probing sword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**initial softmax probability scores cor\u0002responding to the target tokens**"
      ],
      "metadata": {
        "id": "lPV_9EM0N7CV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_idx = 0\n",
        "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 1:\", target_probas_1)\n",
        "\n",
        "text_idx = 1\n",
        "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 2:\", target_probas_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GycObu7-MEsc",
        "outputId": "db22e5e9-c5b3-4c26-b296-717e8d7e209f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1: tensor([1.4403e-05, 1.6720e-05, 8.6229e-06])\n",
            "Text 2: tensor([1.2030e-05, 4.5597e-05, 6.2099e-05])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**calculate the loss for the probability scores of the two example batches. We apply logarithm to the probability scores**"
      ],
      "metadata": {
        "id": "Oh1jMz67Pm7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
        "print(log_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw3_Q2e9N5UO",
        "outputId": "85ee08ed-b8db-4621-9908-ae4dd12362d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-11.1481, -10.9989, -11.6611, -11.3281,  -9.9957,  -9.6868])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combine these log probabilities into a single score by computing the aver\u0002age**"
      ],
      "metadata": {
        "id": "o-eajB7FQX5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_log_probas = torch.mean(log_probas)\n",
        "print(avg_log_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5LhXhVcP3wN",
        "outputId": "8f436ca1-a349-41f8-e11b-bbde273e9d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-10.8031)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating the average negative log probability**"
      ],
      "metadata": {
        "id": "IdUOeJjdQ4r9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neg_avg_log_probas = avg_log_probas * -1\n",
        "print(neg_avg_log_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFZTtPgDQgFU",
        "outputId": "f52db736-29c1-4313-98a2-1ba8c585380f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.8031)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The term for turning -10.8031 to 10.8031 is called cross entropy loss"
      ],
      "metadata": {
        "id": "lKgSfca4R-NV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Logits shape:\", logits.shape)\n",
        "print(\"Targets shape:\", targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMKuDcH4R84d",
        "outputId": "4d5b8d44-894f-41f1-bdcc-e614434f292e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape: torch.Size([2, 3, 50257])\n",
            "Targets shape: torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the cross_entropy loss function in PyTorch, we want to flatten these tensors\n",
        "by combining them over the batch dimension"
      ],
      "metadata": {
        "id": "1hHwzdbpTRnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits_flat = logits.flatten(0, 1)\n",
        "targets_flat = targets.flatten()\n",
        "print(\"Flattened logits:\", logits_flat.shape)\n",
        "print(\"Flattened targets:\", targets_flat.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj-DOEGMS1Fp",
        "outputId": "2644fa28-ccc3-4a1e-c162-f3b0bd9f9dfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flattened logits: torch.Size([6, 50257])\n",
            "Flattened targets: torch.Size([6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using PyTorch's cross entropy function to calculate loss**"
      ],
      "metadata": {
        "id": "9zvdPzVsTxW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN6nJpnNTPyj",
        "outputId": "c373d961-2c00-45a2-ee11-84ada6ecfc07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.8031)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating Perplexity"
      ],
      "metadata": {
        "id": "4vsKYLR8VIPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity = torch.exp(loss)\n",
        "print(perplexity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mNQP5ywTv0H",
        "outputId": "7103077f-13a4-40e2-a028-c06107274558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(49173.1719)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perplexity can provide a more interpre\u0002table way to understand the uncertainty of a model in predicting the next token in a\n",
        "sequence**"
      ],
      "metadata": {
        "id": "ShyyMuZKVTeG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating the training and validation set losses"
      ],
      "metadata": {
        "id": "wbfOMv2BWJrb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train on \"The Verdict\" short story"
      ],
      "metadata": {
        "id": "ef-hfnkBdLu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
        " \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
        " \"the-verdict.txt\")\n",
        "file_path = \"the-verdict.txt\"\n",
        "urllib.request.urlretrieve(url, file_path)"
      ],
      "metadata": {
        "id": "AKyVSLyZVMcN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a1ce22e-78b0-4a8c-d723-853bb4494bef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('the-verdict.txt', <http.client.HTTPMessage at 0x7a003202f090>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"the-verdict.txt\"\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        " text_data = file.read()"
      ],
      "metadata": {
        "id": "Fu3wnVKHdyJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check number of characters and tokens in the dataset"
      ],
      "metadata": {
        "id": "dMUmamCyeqil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_characters = len(text_data)\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "print(\"Characters:\", total_characters)\n",
        "print(\"Tokens:\", total_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAToJQIpelIE",
        "outputId": "25f6d2ac-96f0-460d-d1bb-257c977f9031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Characters: 20479\n",
            "Tokens: 5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dividing dataset into a training and a validation set**"
      ],
      "metadata": {
        "id": "WGk4wrnqfkdg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataloader"
      ],
      "metadata": {
        "id": "Z9YxzUUmg2UM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "1zpn9gP1hgLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        token_ids = tokenizer.encode(txt) #tokenizes the entire text\n",
        "\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i+max_length]\n",
        "            target_chunk = token_ids[i+1:i+max_length+1]\n",
        "\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "     #Returns total number of rows in the dataset\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    #Returns a single row from the dataset\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "    #Dataloader to generate batches with input pairs\n",
        "    def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128,\n",
        "                             shuffle=True, drop_last=True, num_workers=0):\n",
        "        tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "        dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "        dataloader = DataLoader(\n",
        "            dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=shuffle,\n",
        "            drop_last=drop_last,\n",
        "            num_workers=num_workers\n",
        "        )\n",
        "\n",
        "\n",
        "        return dataloader"
      ],
      "metadata": {
        "id": "fnfCkgnag1sO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a train_ratio"
      ],
      "metadata": {
        "id": "H3b7eXwNf2iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]"
      ],
      "metadata": {
        "id": "CZ_8xm_oe0bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating dataloaders for train_data and val_data"
      ],
      "metadata": {
        "id": "9K8cTuYpiEWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = GPTDatasetV1.create_dataloader_v1(\n",
        " train_data,\n",
        " batch_size=2,\n",
        " max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        " stride=GPT_CONFIG_124M[\"context_length\"],\n",
        " drop_last=True,\n",
        " shuffle=True,\n",
        " num_workers=0\n",
        ")\n",
        "val_loader = GPTDatasetV1.create_dataloader_v1(\n",
        " val_data,\n",
        " batch_size=2,\n",
        " max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        " stride=GPT_CONFIG_124M[\"context_length\"],\n",
        " drop_last=False,\n",
        " shuffle=False,\n",
        " num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "UypJpdu_gDxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if dataloaders were created"
      ],
      "metadata": {
        "id": "fluJNds2mFQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader:\")\n",
        "for x, y in train_loader:\n",
        " print(x.shape, y.shape)\n",
        "\n",
        "print(\"\\nValidation loader:\")\n",
        "for x, y in val_loader:\n",
        " print(x.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OBHKi7ok8mY",
        "outputId": "aea51d34-0052-4072-97fc-1050472175fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            "Validation loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement utility function to calculate cross entropy loss of a given batch"
      ],
      "metadata": {
        "id": "dsS8mYkWiYL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        " input_batch = input_batch.to(device)\n",
        " target_batch = target_batch.to(device)\n",
        " logits = model(input_batch)\n",
        " loss = torch.nn.functional.cross_entropy(\n",
        " logits.flatten(0, 1), target_batch.flatten()\n",
        " )\n",
        " return loss"
      ],
      "metadata": {
        "id": "etYoTe6EmJpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to compute training and validation loss**"
      ],
      "metadata": {
        "id": "v7NI94KQiqIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        " total_loss = 0.\n",
        " if len(data_loader) == 0:\n",
        "  return float(\"nan\")\n",
        " elif num_batches is None:\n",
        "  num_batches = len(data_loader)\n",
        " else:\n",
        "  num_batches = min(num_batches, len(data_loader))\n",
        " for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "  if i < num_batches:\n",
        "    loss = calc_loss_batch(\n",
        "      input_batch, target_batch, model, device\n",
        "    )\n",
        "    total_loss += loss.item() # Sums loss for each batch\n",
        "  else:\n",
        "    break\n",
        " return total_loss / num_batches  #Avgs loss over all the batches"
      ],
      "metadata": {
        "id": "9J6Ws5iAik4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "with torch.no_grad():\n",
        " train_loss = calc_loss_loader(train_loader, model, device)\n",
        " val_loss = calc_loss_loader(val_loader, model, device)\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdAI6QwHjcTJ",
        "outputId": "8626cec1-29f7-4a8f-b824-70f3458f9149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 11.002762688530815\n",
            "Validation loss: 11.05290699005127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training an LLM"
      ],
      "metadata": {
        "id": "OlhlHZPWk9LO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing LLM training flow"
      ],
      "metadata": {
        "id": "X4EJNFJUmgkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        " model.eval()\n",
        " with torch.no_grad():\n",
        "  train_loss = calc_loss_loader(\n",
        "    train_loader, model, device, num_batches=eval_iter\n",
        "    )\n",
        "  val_loss = calc_loss_loader(\n",
        "    val_loader, model, device, num_batches=eval_iter\n",
        "  )\n",
        " model.train()\n",
        " return train_loss, val_loss"
      ],
      "metadata": {
        "id": "jG_J8Ij6oYZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        " model.eval()\n",
        " context_size = model.pos_emb.weight.shape[0]\n",
        " encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        " with torch.no_grad():\n",
        "  token_ids = generate_text_simple(\n",
        "  model=model, idx=encoded,\n",
        "  max_new_tokens=50, context_size=context_size\n",
        "  )\n",
        " decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        " print(decoded_text.replace(\"\\n\", \" \"))\n",
        " model.train()"
      ],
      "metadata": {
        "id": "i50CYcfdo6fB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_simple(model, train_loader, val_loader,\n",
        " optimizer, device, num_epochs,\n",
        " eval_freq, eval_iter, start_context, tokenizer):\n",
        " train_losses, val_losses, track_tokens_seen = [], [], []\n",
        " tokens_seen, global_step = 0, -1\n",
        " for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  for input_batch, target_batch in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    loss = calc_loss_batch(\n",
        "      input_batch, target_batch, model, device\n",
        "      )\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    tokens_seen += input_batch.numel()\n",
        "    global_step += 1\n",
        "    if global_step % eval_freq == 0:\n",
        "      train_loss, val_loss = evaluate_model(\n",
        "        model, train_loader, val_loader, device, eval_iter)\n",
        "      train_losses.append(train_loss)\n",
        "      val_losses.append(val_loss)\n",
        "      track_tokens_seen.append(tokens_seen)\n",
        "      print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "      f\"Train loss {train_loss:.3f}, \"\n",
        "      f\"Val loss {val_loss:.3f}\"\n",
        "      )\n",
        "  generate_and_print_sample(\n",
        "    model, tokenizer, device, start_context\n",
        "  )\n",
        " return train_losses, val_losses, track_tokens_seen"
      ],
      "metadata": {
        "id": "hcLa5AD1kdgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(\n",
        " model.parameters(),\n",
        " lr=0.0004, weight_decay=0.1\n",
        ")\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        " model, train_loader, val_loader, optimizer, device,\n",
        " num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        " start_context=\"Every effort moves you, \", tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laOQ8VhDo_fO",
        "outputId": "f0f25dcb-2414-4146-efff-96c768734a8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.868, Val loss 10.099\n",
            "Ep 1 (Step 000005): Train loss 8.115, Val loss 8.253\n",
            "Every effort moves you, ,\n",
            "Ep 2 (Step 000010): Train loss 6.662, Val loss 7.041\n",
            "Ep 2 (Step 000015): Train loss 5.962, Val loss 6.549\n",
            "Every effort moves you, ,\n",
            "Ep 3 (Step 000020): Train loss 5.650, Val loss 6.538\n",
            "Ep 3 (Step 000025): Train loss 6.298, Val loss 7.969\n",
            "Every effort moves you, ,\n",
            "Ep 4 (Step 000030): Train loss 5.091, Val loss 6.421\n",
            "Ep 4 (Step 000035): Train loss 4.599, Val loss 6.404\n",
            "Every effort moves you,  was\n",
            "Ep 5 (Step 000040): Train loss 3.691, Val loss 6.291\n",
            "Every effort moves you,  through\n",
            "Ep 6 (Step 000045): Train loss 3.679, Val loss 6.202\n",
            "Ep 6 (Step 000050): Train loss 3.060, Val loss 6.172\n",
            "Every effort moves you,  I\n",
            "Ep 7 (Step 000055): Train loss 2.739, Val loss 6.195\n",
            "Ep 7 (Step 000060): Train loss 2.200, Val loss 6.244\n",
            "Every effort moves you,  through\n",
            "Ep 8 (Step 000065): Train loss 1.956, Val loss 6.195\n",
            "Ep 8 (Step 000070): Train loss 1.393, Val loss 6.221\n",
            "Every effort moves you,  through\n",
            "Ep 9 (Step 000075): Train loss 1.106, Val loss 6.318\n",
            "Ep 9 (Step 000080): Train loss 0.824, Val loss 6.337\n",
            "Every effort moves you,  through\n",
            "Ep 10 (Step 000085): Train loss 0.677, Val loss 6.411\n",
            "Every effort moves you,  through\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot to show training and validation losses"
      ],
      "metadata": {
        "id": "sU62bhh6lE0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator"
      ],
      "metadata": {
        "id": "p4hMpp-An0Bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis for tokens seen\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for alignment\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "xi2NLfJRpNOs",
        "outputId": "f8499d85-7790-480e-bd57-80bdfeb88b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generation Strategies"
      ],
      "metadata": {
        "id": "iweExsNKsIVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(\"cpu\")\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmmDgx-On1xk",
        "outputId": "2f5f0575-d73d-408e-e3d4-c4b721bda4b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "token_ids = generate_text_simple(\n",
        " model=model,\n",
        " idx=text_to_token_ids(\"Every effort moves you,\", tokenizer),\n",
        " max_new_tokens=25,\n",
        " context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2r1astlsN5G",
        "outputId": "29e87dc1-e1ad-47f7-fd2d-b4f1f57c1acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you, through\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Temperature scaling** - It is just dividing logits by a numer greater than 0"
      ],
      "metadata": {
        "id": "zWKH4l2_uecJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding a probabilistic selection\n",
        "process to the next-token generation task"
      ],
      "metadata": {
        "id": "LSMH8W2avkQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {\n",
        " \"closer\": 0,\n",
        " \"every\": 1,\n",
        " \"effort\": 2,\n",
        " \"forward\": 3,\n",
        " \"inches\": 4,\n",
        " \"moves\": 5,\n",
        " \"pizza\": 6,\n",
        " \"toward\": 7,\n",
        " \"you\": 8,\n",
        "}\n",
        "inverse_vocab = {v: k for k, v in vocab.items()}"
      ],
      "metadata": {
        "id": "Iex2yw3kvn8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "assume the LLM is given the start context \"every effort moves you\" and gener\u0002ates the following next-token logits"
      ],
      "metadata": {
        "id": "SkKu0tXbv2rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next_token_logits = torch.tensor(\n",
        " [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
        ")"
      ],
      "metadata": {
        "id": "eTAmgV5UvuXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we convert the logits into\n",
        "probabilities via the softmax function and obtain the token ID corresponding to the\n",
        "generated token"
      ],
      "metadata": {
        "id": "MtWxIMjYwJYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probas = torch.softmax(next_token_logits, dim=0)\n",
        "next_token_id = torch.argmax(probas).item()\n",
        "print(inverse_vocab[next_token_id])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxRUq7Rwv6Ei",
        "outputId": "e8f8e3df-f45f-423f-e3df-c439458bcf93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To implement a probabilistic sampling process, we can now replace argmax with\n",
        "the multinomial function"
      ],
      "metadata": {
        "id": "wsmQRePiwT96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
        "print(inverse_vocab[next_token_id])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R58S0XtwV8F",
        "outputId": "6e85007f-6460-4eed-b0b6-ada3d4b0bae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The multinomial\n",
        "function samples the next token proportional to its probability score"
      ],
      "metadata": {
        "id": "B2xAaf6XwiGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_with_temperature(logits, temperature):\n",
        " scaled_logits = logits / temperature\n",
        " return torch.softmax(scaled_logits, dim=0)"
      ],
      "metadata": {
        "id": "t6vW3pMTsc8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the original probabilities alongside proba\u0002bilities scaled with different temperature values"
      ],
      "metadata": {
        "id": "v1IUL7Mbw841"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temperatures = [1, 0.1, 5] # original,lower and higher confidence\n",
        "scaled_probas = [softmax_with_temperature(next_token_logits, T)\n",
        " for T in temperatures]\n",
        "x = torch.arange(len(vocab))\n",
        "bar_width = 0.15\n",
        "fig, ax = plt.subplots(figsize=(5, 3))\n",
        "for i, T in enumerate(temperatures):\n",
        " rects = ax.bar(x + i * bar_width, scaled_probas[i],\n",
        "  bar_width, label=f'Temperature = {T}')\n",
        "ax.set_ylabel('Probability')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "4HcY1emiuwZV",
        "outputId": "6cc9bc03-d4af-4777-db68-6d3a93abcd39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Top-k sampling**"
      ],
      "metadata": {
        "id": "aVPPmiyYzFkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can restrict the\n",
        "sampled tokens to the top-k most likely tokens and exclude all other tokens from the\n",
        "selection process by masking their probability scores,"
      ],
      "metadata": {
        "id": "envEaPq2zRBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_k = 3 # selection of the tokens with the largest logit values\n",
        "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
        "print(\"Top logits:\", top_logits)\n",
        "print(\"Top positions:\", top_pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kaNXaTHwz3K",
        "outputId": "68b6fa36-76b3-42f9-f160-0c89bb60efb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
            "Top positions: tensor([3, 7, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "set the logit values of tokens that are\n",
        "below the lowest logit value within our top-three selection to negative infinity using where function"
      ],
      "metadata": {
        "id": "83b0COLsz2zJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_logits = torch.where(\n",
        " condition=next_token_logits < top_logits[-1], #identifies logits less than the minimum in top 3\n",
        " input=torch.tensor(float('-inf')), #assigns -inf to the lower logits\n",
        " other=next_token_logits #retains original logits for other tokens\n",
        ")\n",
        "print(new_logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0DjVp3izoAw",
        "outputId": "2039ed26-bd3e-448e-a785-18be0a0aafa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topk_probas = torch.softmax(new_logits, dim=0)\n",
        "print(\"Probabilities: \",topk_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii_O7Nju0aJp",
        "outputId": "396493e7-36d0-4df5-bd3f-c1e33ea6fe83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilities:  tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modifying text generation function** - Combining top-k and temperature scaling to text generation\n"
      ],
      "metadata": {
        "id": "kNPc6bQXEXxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, idx, max_new_tokens, context_size,\n",
        "             temperature=0.0, top_k=None, eos_id=None):\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        if top_k is not None:\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(\n",
        "                logits < min_val,\n",
        "                torch.tensor(float('-inf')).to(logits.device),\n",
        "                logits\n",
        "            )\n",
        "\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "            if idx_next == eos_id:\n",
        "                break\n",
        "\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # Append the new token\n",
        "\n",
        "    return idx  # Function returns after completing the loop"
      ],
      "metadata": {
        "id": "jPB-kbzC0fw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "token_ids = generate(\n",
        " model=model,\n",
        " idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        " max_new_tokens=45,\n",
        " context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        " top_k=20,\n",
        " temperature=1.3\n",
        ")\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WsUt8XkHQQV",
        "outputId": "6abaf887-2285-44bd-8a0b-cf299580f0d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you know Jack Gisburn said a little it was such a good fellow enough--so it was no great surprise to Jack's resolve had gone a smile behind back the honour being _ up had again run over from Monte Carlo;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weight saving & Loading"
      ],
      "metadata": {
        "id": "I2MMiIqGMq_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving both the model and optimizer *state_dict* contents."
      ],
      "metadata": {
        "id": "3sckPg65OqPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        " \"model_state_dict\": model.state_dict(),\n",
        " \"optimizer_state_dict\": optimizer.state_dict(),\n",
        " },\n",
        " \"model_and_optimizer.pth\"\n",
        ")"
      ],
      "metadata": {
        "id": "YOflSUOTHSLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*state_dict()* - a dictionary mapping each layer to its parameters.\n",
        "*model.pth* - the filename where the state_dict is saved, the .pth extension is a\n",
        "convention for PyTorch files,"
      ],
      "metadata": {
        "id": "sf4r2lRUNHd5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting to drive so that I can import the model for finetuning"
      ],
      "metadata": {
        "id": "ndokJTUiliyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the saved model and optimizer states to GPTModel instance**"
      ],
      "metadata": {
        "id": "PqsQc6N1Nopt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "model.train();"
      ],
      "metadata": {
        "id": "3GY38r54NR6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e87eadba-ade8-4649-8aa3-1f4c062c948b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-62-2e32dcdb1060>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading pretrained weights from OpenAI"
      ],
      "metadata": {
        "id": "82MRvvyNQGyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow>=2.15.0 tqdm>=4.66"
      ],
      "metadata": {
        "id": "AKH_3xFaNypZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "url = (\n",
        " \"https://raw.githubusercontent.com/rasbt/\"\n",
        " \"LLMs-from-scratch/main/ch05/\"\n",
        " \"01_main-chapter-code/gpt_download.py\"\n",
        ")\n",
        "filename = url.split('/')[-1]\n",
        "urllib.request.urlretrieve(url, filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1hVVvCuQu7E",
        "outputId": "5570f5d1-8589-43dd-9ca0-234cbe235787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('gpt_download.py', <http.client.HTTPMessage at 0x7a001fd3a7d0>)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "settings, params = download_and_load_gpt2(\n",
        " model_size=\"124M\", models_dir=\"gpt2\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdnAoq_OQzl0",
        "outputId": "15c8cb7f-4c54-4c81-9cba-7f613458c9e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 57.0kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 2.00MiB/s]\n",
            "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 189kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:47<00:00, 10.4MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 6.73MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 1.45MiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.49MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "inspect the contents\n",
        "of settings and params"
      ],
      "metadata": {
        "id": "jJpm2ROHR-_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Settings:\", settings)\n",
        "print(\"Parameter dictionary keys:\", params.keys())"
      ],
      "metadata": {
        "id": "kNo9OHBmRFF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef30440-2c1f-4269-8c4c-0d73e76c690f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
            "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The weights of the token embedding layer"
      ],
      "metadata": {
        "id": "tm9OK8cKSfb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(params[\"wte\"])\n",
        "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
      ],
      "metadata": {
        "id": "endypKrUSCSs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7e0d2a7-506f-4216-b671-d3cc48d7d791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
            "   0.04531523]\n",
            " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
            "   0.04318958]\n",
            " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
            "  -0.08785918]\n",
            " ...\n",
            " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
            "  -0.06952604]\n",
            " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
            "  -0.02245961]\n",
            " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
            "   0.12067825]]\n",
            "Token embedding weight tensor dimensions: (50257, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_configs = {\n",
        " \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        " \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        " \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        " \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}"
      ],
      "metadata": {
        "id": "a_DXnEYFSabe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt2-small (124M)\"\n",
        "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
        "NEW_CONFIG.update(model_configs[model_name])"
      ],
      "metadata": {
        "id": "-WpRj2g-S630"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NEW_CONFIG.update({\"context_length\": 1024})"
      ],
      "metadata": {
        "id": "hSDdJcGaTEQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NEW_CONFIG.update({\"qkv_bias\": True})"
      ],
      "metadata": {
        "id": "SBvdfSPOTHQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt = GPTModel(NEW_CONFIG)\n",
        "gpt.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8qAdB7CTPE6",
        "outputId": "d10efa22-2148-4f87-f582-a9e8188a3353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "assign utility function that checks whether two tensors or arrays (left and\n",
        "right) have the same dimensions or shape and returns the right tensor as trainable\n",
        "PyTorch parameters"
      ],
      "metadata": {
        "id": "nat1RG1kT2U2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assign(left, right):\n",
        " if left.shape != right.shape:\n",
        "  raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
        "  \"Right: {right.shape}\"\n",
        "  )\n",
        " return torch.nn.Parameter(torch.tensor(right))"
      ],
      "metadata": {
        "id": "_ZQSPemnTSxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading OpenAI weights into GPT model code**"
      ],
      "metadata": {
        "id": "oR3epLhuVUKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "  gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "  gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "  for b in range(len(params[\"blocks\"])):\n",
        "    q_w, k_w, v_w = np.split(\n",
        "      (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "    gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "      gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "    gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "      gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "    gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "      gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "    q_b, k_b, v_b = np.split(\n",
        "      (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "    gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "      gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "    gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "      gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "    gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "      gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "    gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "      gpt.trf_blocks[b].att.out_proj.weight,\n",
        "      params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "      gpt.trf_blocks[b].att.out_proj.bias,\n",
        "      params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "    gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "      gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "      params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "      gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "      params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "\n",
        "    gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "      gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "      params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "      gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "      params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "    gpt.trf_blocks[b].norm1.scale = assign(\n",
        "      gpt.trf_blocks[b].norm1.scale,\n",
        "      params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "    gpt.trf_blocks[b].norm1.shift = assign(\n",
        "      gpt.trf_blocks[b].norm1.shift,\n",
        "      params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "\n",
        "  gpt.trf_blocks[b].norm2.scale = assign(\n",
        "    gpt.trf_blocks[b].norm2.scale,\n",
        "    params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "  gpt.trf_blocks[b].norm2.shift = assign(\n",
        "    gpt.trf_blocks[b].norm2.shift,\n",
        "    params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "  gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "  gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "  gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
      ],
      "metadata": {
        "id": "AJeqFhEnTu8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_weights_into_gpt(gpt, params)\n",
        "gpt.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRCKgudoVgFS",
        "outputId": "00fda622-3bd4-434f-b681-2ac75ad4d2c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "token_ids = generate(\n",
        " model=gpt,\n",
        " idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
        " max_new_tokens=30,\n",
        " context_size=NEW_CONFIG[\"context_length\"],\n",
        " top_k=50,\n",
        " temperature=1.4\n",
        ")\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "Iw3MD8-OV00l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a025ed48-785b-4d18-9031-ddfbd095c79d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you as as the A the the many the ( the that. - of. a\n",
            " an it at more you ( a I you the one a of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-U16ue54V6hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning"
      ],
      "metadata": {
        "id": "KnXoF5M9tcy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "def download_and_unzip_spam_data(\n",
        " url, zip_path, extracted_path, data_file_path):\n",
        " if data_file_path.exists():\n",
        "  print(f\"{data_file_path} already exists. Skipping download \"\n",
        "  \"and extraction.\"\n",
        "  )\n",
        "  return\n",
        "\n",
        "with urllib.request.urlopen(url) as response: #Download File\n",
        " with open(zip_path, \"wb\") as out_file:\n",
        "  out_file.write(response.read())\n",
        "\n",
        " with zipfile.ZipFile(zip_path, \"r\") as zip_ref: # Unzips the file\n",
        "  zip_ref.extractall(extracted_path)\n",
        "\n",
        " original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        " os.rename(original_file_path, data_file_path)  #Adds a .tsv extension\n",
        " print(f\"File downloaded and saved as {data_file_path}\")\n",
        "\n",
        "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETM4f4vNtgtz",
        "outputId": "3d6e97a7-1a1d-4354-f3d6-afbc41886ef4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\n",
            "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\n",
        " data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"]\n",
        ")\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VtvxwECtonU",
        "outputId": "7c5f671d-32f1-4f0b-a1cd-549bcd77c172"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Label                                               Text\n",
            "0      ham  Go until jurong point, crazy.. Available only ...\n",
            "1      ham                      Ok lar... Joking wif u oni...\n",
            "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3      ham  U dun say so early hor... U c already then say...\n",
            "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
            "...    ...                                                ...\n",
            "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
            "5568   ham               Will ü b going to esplanade fr home?\n",
            "5569   ham  Pity, * was in mood for that. So...any other s...\n",
            "5570   ham  The guy did some bitching but I acted like i'd...\n",
            "5571   ham                         Rofl. Its true to its name\n",
            "\n",
            "[5572 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eifj-rpHtsZN",
        "outputId": "8b7ae122-d80d-40e4-ffcc-e072e63e880e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_balanced_dataset(df):\n",
        " num_spam = df[df[\"Label\"] == \"spam\"].shape[0] # Counts spam instances\n",
        " ham_subset = df[df[\"Label\"] == \"ham\"].sample(\n",
        " num_spam, random_state=123\n",
        " )\n",
        "\n",
        " balanced_df = pd.concat([\n",
        " ham_subset, df[df[\"Label\"] == \"spam\"]\n",
        " ])\n",
        " return balanced_df\n",
        "\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "print(balanced_df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb17TojltwJo",
        "outputId": "5a54db7d-7299-4555-aa42-2f26595677ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     747\n",
            "spam    747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
      ],
      "metadata": {
        "id": "9uz9FKuotylC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_split(df, train_frac, validation_frac):\n",
        "\n",
        " df = df.sample(\n",
        " frac=1, random_state=123\n",
        " ).reset_index(drop=True) #Shuffles the entire dataframe\n",
        " train_end = int(len(df) * train_frac) #Calculate split indices\n",
        " validation_end = train_end + int(len(df) * validation_frac)\n",
        "\n",
        " #Split dataframe\n",
        " train_df = df[:train_end]\n",
        " validation_df = df[train_end:validation_end]\n",
        " test_df = df[validation_end:]\n",
        " return train_df, validation_df, test_df\n",
        "\n",
        "train_df, validation_df, test_df = random_split(\n",
        " balanced_df, 0.7, 0.1)"
      ],
      "metadata": {
        "id": "1YQp93Vxt1wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ],
      "metadata": {
        "id": "aBN8E4uqt5B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGwgKsUjt7e2",
        "outputId": "223e0ba4-1770-41ab-e5be-4717b1d53719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Smm3dGhtuBFO",
        "outputId": "d844bac0-831d-4bbe-a556-4bcf97f4a126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "gxAz7cD-uESY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpamDataset(Dataset):\n",
        " def __init__(self, csv_file, tokenizer, max_length=None,\n",
        " pad_token_id=50256):\n",
        "  self.data = pd.read_csv(csv_file)\n",
        "\n",
        " #Pretokenizes text\n",
        "  self.encoded_texts = [\n",
        "  tokenizer.encode(text) for text in self.data[\"Text\"]\n",
        "  ]\n",
        "\n",
        "  if max_length is None:\n",
        "    self.max_length = self._longest_encoded_length()\n",
        "  else:\n",
        "    self.max_length = max_length\n",
        "\n",
        "  #Truncates sequences if they are longer than max length\n",
        "  self.encoded_texts = [\n",
        "  encoded_text[:self.max_length]\n",
        "  for encoded_text in self.encoded_texts\n",
        "  ]\n",
        "\n",
        "  self.encoded_texts = [\n",
        "    encoded_text + [pad_token_id] *\n",
        "    (self.max_length - len(encoded_text))\n",
        "    for encoded_text in self.encoded_texts\n",
        "    ]\n",
        "\n",
        " def __getitem__(self, index):\n",
        "  encoded = self.encoded_texts[index]\n",
        "  label = self.data.iloc[index][\"Label\"]\n",
        "  return (\n",
        "    torch.tensor(encoded, dtype=torch.long),\n",
        "    torch.tensor(label, dtype=torch.long)\n",
        "    )\n",
        "\n",
        " def __len__(self):\n",
        "  return len(self.data)\n",
        "\n",
        " def _longest_encoded_length(self):\n",
        "  max_length = 0\n",
        "  for encoded_text in self.encoded_texts:\n",
        "    encoded_length = len(encoded_text)\n",
        "    if encoded_length > max_length:\n",
        "      max_length = encoded_length\n",
        "  return max_length"
      ],
      "metadata": {
        "id": "yCN9qIzwuG3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SpamDataset(\n",
        " csv_file=\"train.csv\",\n",
        " max_length=None,\n",
        " tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "_RFZBDxbuLPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset.max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp9UQ_-xuN2g",
        "outputId": "77004b8f-9bc6-4ac8-fe6e-fbdd82bbe4e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = SpamDataset(\n",
        " csv_file=\"validation.csv\",\n",
        " max_length=train_dataset.max_length,\n",
        " tokenizer=tokenizer\n",
        ")\n",
        "test_dataset = SpamDataset(\n",
        " csv_file=\"test.csv\",\n",
        " max_length=train_dataset.max_length,\n",
        " tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "dZbpuTSCuQNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "torch.manual_seed(123)\n",
        "train_loader = DataLoader(\n",
        " dataset=train_dataset,\n",
        " batch_size=batch_size,\n",
        " shuffle=True,\n",
        " num_workers=num_workers,\n",
        " drop_last=True,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        " dataset=val_dataset,\n",
        " batch_size=batch_size,\n",
        " num_workers=num_workers,\n",
        " drop_last=False,\n",
        ")\n",
        "test_loader = DataLoader(\n",
        " dataset=test_dataset,\n",
        " batch_size=batch_size,\n",
        " num_workers=num_workers,\n",
        " drop_last=False,\n",
        ")"
      ],
      "metadata": {
        "id": "xLlZ1b16uS9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_batch, target_batch in train_loader:\n",
        " pass\n",
        "print(\"Input batch dimensions:\", input_batch.shape)\n",
        "print(\"Label batch dimensions\", target_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2a1IEoiuWcB",
        "outputId": "5a326596-8822-4160-812a-54d9aeef3e09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch dimensions: torch.Size([8, 120])\n",
            "Label batch dimensions torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EExQZHwfuZrg",
        "outputId": "7ebba285-6211-49cd-b248-7aec47a47196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 training batches\n",
            "19 validation batches\n",
            "38 test batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initializing pretrained weights**"
      ],
      "metadata": {
        "id": "VnHvGROqudCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "INPUT_PROMPT = \"Every effort moves\""
      ],
      "metadata": {
        "id": "uO4gNz7HucZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_CONFIG = {\n",
        " \"vocab_size\": 50257,\n",
        " \"context_length\": 1024,\n",
        " \"drop_rate\": 0.0,\n",
        " \"qkv_bias\": True\n",
        "}\n",
        "model_configs = {\n",
        " \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        " \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        " \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        " \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
      ],
      "metadata": {
        "id": "GB0iNB-wulgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(\n",
        " model_size=model_size, models_dir=\"gpt2\"\n",
        ")\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_fc3t_7uonS",
        "outputId": "bdd5d404-e9a0-41c7-c4e5-ca255bc40ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
            "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = \"Every effort moves you\"\n",
        "token_ids = generate_text_simple(\n",
        " model=model,\n",
        " idx=text_to_token_ids(text_1, tokenizer),\n",
        " max_new_tokens=25,\n",
        " context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jErPIIlYu1xM",
        "outputId": "5e370e8e-873a-46de-e7be-f0fced3b5400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every effort moves you the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = (\n",
        " \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
        " \" 'You are a winner you have been specially\"\n",
        " \" selected to receive $1000 cash or a $2000 award.'\"\n",
        ")\n",
        "token_ids = generate_text_simple(\n",
        " model=model,\n",
        " idx=text_to_token_ids(text_2, tokenizer),\n",
        " max_new_tokens=23,\n",
        " context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2JhYcvnxy8P",
        "outputId": "92b5a86a-b854-47d0-9a6f-46238d4c10e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.' the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding classification head**"
      ],
      "metadata": {
        "id": "FqvJf2soyecP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Architecture"
      ],
      "metadata": {
        "id": "CGFyvtkozLAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng-yWcEzyUp5",
        "outputId": "f65bb50f-ce20-462d-cff4-3269f2b7d97d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freeze the model"
      ],
      "metadata": {
        "id": "NXkyrho1z-qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        " param.requires_grad = False"
      ],
      "metadata": {
        "id": "9E3D7h59zRM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding a classification layer**"
      ],
      "metadata": {
        "id": "yl3G85nEpSrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "num_classes = 2\n",
        "model.out_head = torch.nn.Linear(\n",
        " in_features=BASE_CONFIG[\"emb_dim\"],\n",
        " out_features=num_classes\n",
        ")"
      ],
      "metadata": {
        "id": "ng1MYNOs0DCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "make the final LayerNorm and last transformer block trainable"
      ],
      "metadata": {
        "id": "faDWDOj8qaXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.trf_blocks[-1].parameters():\n",
        " param.requires_grad = True\n",
        "for param in model.final_norm.parameters():\n",
        " param.requires_grad = True"
      ],
      "metadata": {
        "id": "CTodtCLap5Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer.encode(\"Do you have time\")\n",
        "inputs = torch.tensor(inputs).unsqueeze(0)\n",
        "print(\"Inputs:\", inputs)\n",
        "print(\"Inputs dimensions:\", inputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fv8Gvcrq3pW",
        "outputId": "f1e3c663-7614-46a9-ad8a-8b5940611763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs: tensor([[5211,  345,  423,  640]])\n",
            "Inputs dimensions: torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ayBg9DMXrE3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pass the encoded token IDs to the model"
      ],
      "metadata": {
        "id": "AdoSK_BJrHvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        " outputs = model(inputs)\n",
        "print(\"Outputs:\\n\", outputs)\n",
        "print(\"Outputs dimensions:\", outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E43L59pprGtN",
        "outputId": "ab65f98a-3eea-4dab-bebf-212bbe048b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs:\n",
            " tensor([[[0.3708, 1.2060],\n",
            "         [0.2238, 1.4616],\n",
            "         [0.2839, 1.4423],\n",
            "         [0.2767, 1.3516]]])\n",
            "Outputs dimensions: torch.Size([1, 4, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Last output token:\", outputs[:, -1, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FALaR0sCriVl",
        "outputId": "ac00c49e-b07b-4332-c8a1-5c4435123332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last output token: tensor([[0.2767, 1.3516]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "last token in a sequence accu\u0002mulates the most information since it is the only token with access to data from all the\n",
        "previous tokens. Therefore, in our spam classification task, we focus on this last token\n",
        "during the fine-tuning process."
      ],
      "metadata": {
        "id": "ge4wzNtTsjG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "83NxYq1pq3Bk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calaculating classification loss and accuracy"
      ],
      "metadata": {
        "id": "AY9ECXi6tBr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtain class label"
      ],
      "metadata": {
        "id": "A5r7k4sruW5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits = outputs[:, -1, :]\n",
        "label = torch.argmax(logits)\n",
        "print(\"Class label:\", label.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOcMUsV8tJpg",
        "outputId": "f6485d8a-4170-4a55-eca9-25d2969c240c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "  model.eval()\n",
        "  correct_predictions, num_examples = 0, 0\n",
        "  if num_batches is None:\n",
        "    num_batches = len(data_loader)\n",
        "  else:\n",
        "    num_batches = min(num_batches, len(data_loader))\n",
        "  for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "    if i < num_batches:\n",
        "      input_batch = input_batch.to(device)\n",
        "      target_batch = target_batch.to(device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        logits = model(input_batch)[:, -1, :]\n",
        "      predicted_labels = torch.argmax(logits, dim=-1)\n",
        "      num_examples += predicted_labels.shape[0]\n",
        "      correct_predictions += (\n",
        "          (predicted_labels == target_batch).sum().item()\n",
        "  )\n",
        "    else:\n",
        "      break\n",
        "  return correct_predictions / num_examples"
      ],
      "metadata": {
        "id": "N-gIWcfNuaGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "classification accuracies across various datasets"
      ],
      "metadata": {
        "id": "kYUSX4HWRqd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "torch.manual_seed(123)\n",
        "train_accuracy = calc_accuracy_loader(\n",
        " train_loader, model, device, num_batches=10\n",
        ")\n",
        "val_accuracy = calc_accuracy_loader(\n",
        " val_loader, model, device, num_batches=10\n",
        ")\n",
        "test_accuracy = calc_accuracy_loader(\n",
        " test_loader, model, device, num_batches=10\n",
        ")\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPOJRmcCRUPR",
        "outputId": "b1d6d25e-167e-43a0-d324-5c5159ad88b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 46.25%\n",
            "Validation accuracy: 45.00%\n",
            "Test accuracy: 48.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To improve the prediction accuracies, we need to fine-tune the model."
      ],
      "metadata": {
        "id": "DzLZ9WynRx_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        " input_batch = input_batch.to(device)\n",
        " target_batch = target_batch.to(device)\n",
        " logits = model(input_batch)[:, -1, :]\n",
        " loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
        " return loss"
      ],
      "metadata": {
        "id": "73mAEePMRinv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the calc_loss_batch function to compute the loss for a single batch obtained\n",
        "from the previously defined data loaders."
      ],
      "metadata": {
        "id": "GXXUlMn7TFcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating classification loss**"
      ],
      "metadata": {
        "id": "Z0qh1F-1TNo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        " total_loss = 0.\n",
        " if len(data_loader) == 0:\n",
        "  return float(\"nan\")\n",
        " elif num_batches is None:\n",
        "  num_batches = len(data_loader)\n",
        " else:\n",
        "  num_batches = min(num_batches, len(data_loader))\n",
        " for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "  if i < num_batches:\n",
        "    loss = calc_loss_batch(\n",
        "    input_batch, target_batch, model, device\n",
        "    )\n",
        "    total_loss += loss.item()\n",
        "  else:\n",
        "    break\n",
        " return total_loss / num_batches"
      ],
      "metadata": {
        "id": "x78Q9qwHTEmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "compute the initial loss for each\n",
        "data set"
      ],
      "metadata": {
        "id": "lVD5ZBGeT1v7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        " train_loss = calc_loss_loader(\n",
        " train_loader, model, device, num_batches=5\n",
        " )\n",
        " val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        " test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
        "print(f\"Training loss: {train_loss:.3f}\")\n",
        "print(f\"Validation loss: {val_loss:.3f}\")\n",
        "print(f\"Test loss: {test_loss:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u20bN6gTZxe",
        "outputId": "4b8a88ba-e3a5-482f-b3ff-4160c6abf3ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.767\n",
            "Validation loss: 0.785\n",
            "Test loss: 0.741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning the model on supervised data"
      ],
      "metadata": {
        "id": "Lw2V5A-GUDSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifier_simple(\n",
        " model, train_loader, val_loader, optimizer, device,\n",
        " num_epochs, eval_freq, eval_iter):\n",
        "\n",
        "  train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "  examples_seen, global_step = 0, -1\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      for input_batch, target_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = calc_loss_batch(\n",
        "        input_batch, target_batch, model, device\n",
        "        )\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        examples_seen += input_batch.shape[0]\n",
        "        global_step += 1\n",
        "\n",
        "        if global_step % eval_freq == 0:\n",
        "          train_loss, val_loss = evaluate_model(\n",
        "          model, train_loader, val_loader, device, eval_iter)\n",
        "          train_losses.append(train_loss)\n",
        "          val_losses.append(val_loss)\n",
        "          print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "          f\"Train loss {train_loss:.3f}, \"\n",
        "          f\"Val loss {val_loss:.3f}\"\n",
        "          )\n",
        "\n",
        "      train_accuracy = calc_accuracy_loader(\n",
        "        train_loader, model, device, num_batches=eval_iter\n",
        "        )\n",
        "      val_accuracy = calc_accuracy_loader(\n",
        "        val_loader, model, device, num_batches=eval_iter\n",
        "        )\n",
        "\n",
        "      print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "      print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "      train_accs.append(train_accuracy)\n",
        "      val_accs.append(val_accuracy)\n",
        "\n",
        "  return train_losses, val_losses, train_accs, val_accs, examples_seen"
      ],
      "metadata": {
        "id": "nN-4_clhT6Er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        " model.eval()\n",
        " with torch.no_grad():\n",
        "  train_loss = calc_loss_loader(\n",
        "    train_loader, model, device, num_batches=eval_iter\n",
        "    )\n",
        "  val_loss = calc_loss_loader(\n",
        "    val_loader, model, device, num_batches=eval_iter\n",
        "    )\n",
        " model.train()\n",
        "\n",
        " return train_loss, val_loss"
      ],
      "metadata": {
        "id": "oNXsmv96PwOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "torch.manual_seed(123)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = \\\n",
        "  train_classifier_simple(\n",
        "  model, train_loader, val_loader, optimizer, device,\n",
        "  num_epochs=num_epochs, eval_freq=50,\n",
        "  eval_iter=5\n",
        "  )\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsmuKvAxQIe4",
        "outputId": "77cd7d7e-1242-4a8d-80bc-77b0cfb8d210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 0.724, Val loss 0.761\n",
            "Ep 1 (Step 000050): Train loss 0.642, Val loss 0.651\n",
            "Ep 1 (Step 000100): Train loss 0.569, Val loss 0.616\n",
            "Training accuracy: 52.50% | Validation accuracy: 62.50%\n",
            "Ep 2 (Step 000150): Train loss 0.584, Val loss 0.561\n",
            "Ep 2 (Step 000200): Train loss 0.508, Val loss 0.507\n",
            "Ep 2 (Step 000250): Train loss 0.457, Val loss 0.466\n",
            "Training accuracy: 80.00% | Validation accuracy: 82.50%\n",
            "Ep 3 (Step 000300): Train loss 0.387, Val loss 0.414\n",
            "Ep 3 (Step 000350): Train loss 0.395, Val loss 0.393\n",
            "Training accuracy: 85.00% | Validation accuracy: 87.50%\n",
            "Ep 4 (Step 000400): Train loss 0.224, Val loss 0.378\n",
            "Ep 4 (Step 000450): Train loss 0.413, Val loss 0.348\n",
            "Ep 4 (Step 000500): Train loss 0.339, Val loss 0.369\n",
            "Training accuracy: 92.50% | Validation accuracy: 85.00%\n",
            "Ep 5 (Step 000550): Train loss 0.341, Val loss 0.338\n",
            "Ep 5 (Step 000600): Train loss 0.525, Val loss 0.320\n",
            "Training accuracy: 92.50% | Validation accuracy: 85.00%\n",
            "Ep 6 (Step 000650): Train loss 0.305, Val loss 0.325\n",
            "Ep 6 (Step 000700): Train loss 0.398, Val loss 0.348\n",
            "Ep 6 (Step 000750): Train loss 0.320, Val loss 0.310\n",
            "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
            "Ep 7 (Step 000800): Train loss 0.401, Val loss 0.335\n",
            "Ep 7 (Step 000850): Train loss 0.203, Val loss 0.307\n",
            "Ep 7 (Step 000900): Train loss 0.345, Val loss 0.315\n",
            "Training accuracy: 92.50% | Validation accuracy: 87.50%\n",
            "Ep 8 (Step 000950): Train loss 0.403, Val loss 0.308\n",
            "Ep 8 (Step 001000): Train loss 0.356, Val loss 0.312\n",
            "Training accuracy: 95.00% | Validation accuracy: 87.50%\n",
            "Ep 9 (Step 001050): Train loss 0.226, Val loss 0.333\n",
            "Ep 9 (Step 001100): Train loss 0.335, Val loss 0.293\n",
            "Ep 9 (Step 001150): Train loss 0.341, Val loss 0.308\n",
            "Training accuracy: 82.50% | Validation accuracy: 87.50%\n",
            "Ep 10 (Step 001200): Train loss 0.294, Val loss 0.280\n",
            "Ep 10 (Step 001250): Train loss 0.276, Val loss 0.267\n",
            "Training accuracy: 97.50% | Validation accuracy: 87.50%\n",
            "Training completed in 1.76 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "plot the loss function for the training and validation set"
      ],
      "metadata": {
        "id": "IJae2P7CYTR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_values(\n",
        "    epochs_seen, examples_seen, train_values, val_values,\n",
        "    label=\"loss\"):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "    ax1.plot(\n",
        "    epochs_seen, val_values, linestyle=\"-.\",\n",
        "    label=f\"Validation {label}\"\n",
        "    )\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        "\n",
        "    ax2 = ax1.twiny()\n",
        "    ax2.plot(examples_seen, train_values, alpha=0)\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "    fig.tight_layout()\n",
        "    plt.savefig(f\"{label}-plot.pdf\")\n",
        "    plt.show()\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
      ],
      "metadata": {
        "id": "TmpeLsWRQu5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "67953c7f-52d5-4137-f9d1-fc73b82fa8a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "plot the classification accuracies"
      ],
      "metadata": {
        "id": "QOKXEl6va4l3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
        "plot_values(\n",
        " epochs_tensor, examples_seen_tensor, train_accs, val_accs,\n",
        " label=\"accuracy\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "8PQ-uF4fYNnq",
        "outputId": "31aa9be0-e03b-4dbb-9913-973b3f7da2dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gweur0aXa78d",
        "outputId": "cc761129-7e05-47fa-9cc3-b4affbd69b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 87.60%\n",
            "Validation accuracy: 90.60%\n",
            "Test accuracy: 89.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using LLM as a spam classifier**"
      ],
      "metadata": {
        "id": "wO00PPR4dEUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_review(\n",
        " text, model, tokenizer, device, max_length=None,\n",
        " pad_token_id=50256):\n",
        " model.eval()\n",
        "\n",
        " input_ids = tokenizer.encode(text)   # Prepares inputs to the model\n",
        " supported_context_length = model.pos_emb.weight.shape[1]\n",
        "\n",
        " input_ids = input_ids[:min(      #Truncates the sequence if they are too long\n",
        " max_length, supported_context_length\n",
        " )]\n",
        "\n",
        " input_ids += [pad_token_id] * (max_length - len(input_ids)) # Pads sequences to the longest sequence\n",
        "\n",
        " input_tensor = torch.tensor(\n",
        " input_ids, device=device\n",
        " ).unsqueeze(0) #Adds batch dimension\n",
        "\n",
        " with torch.no_grad(): #Model inference without gradient tracking\n",
        "  logits = model(input_tensor)[:, -1, :]\n",
        " predicted_label = torch.argmax(logits, dim=-1).item()\n",
        " return \"spam\" if predicted_label == 1 else \"not spam\" # Returns classified results"
      ],
      "metadata": {
        "id": "Ich3sgPpbOKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = (\n",
        " \"You are a winner you have been specially\"\n",
        " \" selected to receive $1000 cash or a $2000 award.\"\n",
        ")\n",
        "print(classify_review(\n",
        " text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cv8Cnn2euXb",
        "outputId": "115a0a47-00ea-495b-fce2-469f973fa921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = (\n",
        " \"Hey, just wanted to check if we're still on\"\n",
        " \" for dinner tonight? Let me know!\"\n",
        ")\n",
        "print(classify_review(\n",
        " text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl0ss1Rye3Vg",
        "outputId": "a59bedb5-a8fb-4f22-e145-4830689fc3f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the model"
      ],
      "metadata": {
        "id": "Vv-LQlsjfExv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"review_classifier.pth\")"
      ],
      "metadata": {
        "id": "Whuk9_8Ye73a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instruction fine-tuning"
      ],
      "metadata": {
        "id": "o_r_-04kvA7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instruction fine-tuning involves training a model on a dataset where the input-output\n",
        "pairs, are explicitly provided."
      ],
      "metadata": {
        "id": "g6flYbYUwqs8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preparation**"
      ],
      "metadata": {
        "id": "glzWg3mNvJqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import urllib"
      ],
      "metadata": {
        "id": "EXUPD-F3vjlX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading dataset\n",
        "def download_and_load_file(file_path, url):\n",
        "  if not os.path.exists(file_path):\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "      text_data = response.read().decode(\"utf-8\")\n",
        "\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "      file.write(text_data)\n",
        "  else:\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "      text_data = file.read()\n",
        "    with open(file_path, \"r\") as file:\n",
        "      data = json.load(file)\n",
        "\n",
        "    return data\n",
        "\n",
        "file_path = \"instruction-data.json\"\n",
        "url = (\n",
        " \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
        " \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
        ")\n",
        "\n",
        "data = download_and_load_file(file_path, url)\n",
        "print(\"Number of entries:\", len(data))"
      ],
      "metadata": {
        "id": "JJNSlwDmfIKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7777a06f-df42-4d17-8442-4a3fd3b295d9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries: 1100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Example entry:\\n\", data[50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ji73PmqwGWN",
        "outputId": "5b5fd926-0f12-46c9-f66c-2d8730efe978"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example entry:\n",
            " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Another example entry:\\n\", data[999])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5S-1HDbwSK3",
        "outputId": "db4b0fbb-eee3-4499-dd46-f029032837be"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Another example entry:\n",
            " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing prompt formating"
      ],
      "metadata": {
        "id": "QgY6ZN0Mx45u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alpaca style format"
      ],
      "metadata": {
        "id": "3ggmdPXPyIU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def format_input(entry):\n",
        "  instruction_text = (\n",
        "  f\"Below is an instruction that describes a task. \"\n",
        "  f\"Write a response that appropriately completes the request.\"\n",
        "  f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "  )\n",
        "\n",
        "  input_text = (\n",
        "  f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "  )\n",
        "  return instruction_text + input_text"
      ],
      "metadata": {
        "id": "bN6ucSn2wc0u"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_input = format_input(data[50])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
        "print(model_input + desired_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNsq8tF7yR4p",
        "outputId": "c2306c00-43d2-4ce5-da35-22c57e796e7f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Identify the correct spelling of the following word.\n",
            "\n",
            "### Input:\n",
            "Ocassion\n",
            "\n",
            "### Response:\n",
            "The correct spelling is 'Occasion.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_input = format_input(data[999])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
        "print(model_input + desired_response)"
      ],
      "metadata": {
        "id": "CYi26CF4yYY7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7a12a6b-33d6-4e56-a5a0-1531207a39a3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What is an antonym of 'complicated'?\n",
            "\n",
            "### Response:\n",
            "An antonym of 'complicated' is 'simple'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divide dataset to training, validation and test sets"
      ],
      "metadata": {
        "id": "AYfUydOUyPz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_portion = int(len(data) * 0.85)\n",
        "test_portion = int(len(data) * 0.1)\n",
        "val_portion = len(data) - train_portion - test_portion\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]\n",
        "\n",
        "print(\"Training set length:\", len(train_data))\n",
        "print(\"Validation set length:\", len(val_data))\n",
        "print(\"Test set length:\", len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUCCG1Xpx-f5",
        "outputId": "19ab998c-e4e9-4461-e05d-85b18b8499a5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set length: 935\n",
            "Validation set length: 55\n",
            "Test set length: 110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Organizing data into training batches**"
      ],
      "metadata": {
        "id": "RS2qfWZNzCL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batching process"
      ],
      "metadata": {
        "id": "8erPg9es0qbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "class InstructionDataset(Dataset):\n",
        "  def __init__(self, data, tokenizer):\n",
        "    self.data = data\n",
        "    self.encoded_texts = []\n",
        "    for entry in data:\n",
        "      instruction_plus_input = format_input(entry)\n",
        "      response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "      full_text = instruction_plus_input + response_text\n",
        "      self.encoded_texts.append(\n",
        "      tokenizer.encode(full_text)\n",
        "      )\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.encoded_texts[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "metadata": {
        "id": "enuPjHn7y6xw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing padding process with a custom collate function"
      ],
      "metadata": {
        "id": "e3rEMbWT18pC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_draft_1(batch,pad_token_id=50256,device=\"cpu\"):\n",
        " batch_max_length = max(len(item)+1 for item in batch) # Find the longest sequence in the batch\n",
        " inputs_lst = []\n",
        "\n",
        "#Pads and prepares input\n",
        " for item in batch:\n",
        "  new_item = item.copy()\n",
        "  new_item += [pad_token_id]\n",
        "\n",
        "  padded = (\n",
        "  new_item + [pad_token_id] *\n",
        "  (batch_max_length - len(new_item))\n",
        "  )\n",
        "\n",
        "  inputs = torch.tensor(padded[:-1]) #Removes extra padded token added earlier\n",
        "  inputs_lst.append(inputs)\n",
        "\n",
        " inputs_tensor = torch.stack(inputs_lst).to(device) #Converts the lists of inputs to tensor and transfers it to the target device\n",
        " return inputs_tensor"
      ],
      "metadata": {
        "id": "ZDMSjBB708PH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "batch = (\n",
        " inputs_1,\n",
        " inputs_2,\n",
        " inputs_3\n",
        ")\n",
        "print(custom_collate_draft_1(batch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zWrFqXl3B0O",
        "outputId": "ea51b3c0-9dfe-4fe9-ff54-b627d61d6e7a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Updated collate function generates the target token IDs from the input\n",
        "token IDs"
      ],
      "metadata": {
        "id": "ODVpjpRp3yND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_draft_2(\n",
        " batch,\n",
        " pad_token_id=50256,\n",
        " device=\"cpu\"\n",
        "):\n",
        "\n",
        " batch_max_length = max(len(item)+1 for item in batch)\n",
        " inputs_lst, targets_lst = [], []\n",
        "\n",
        " for item in batch:\n",
        "  new_item = item.copy()\n",
        "  new_item += [pad_token_id]\n",
        "\n",
        "  padded = (\n",
        "  new_item + [pad_token_id] *\n",
        "  (batch_max_length - len(new_item))\n",
        "  )\n",
        "  inputs = torch.tensor(padded[:-1])\n",
        "  targets = torch.tensor(padded[1:])\n",
        "  inputs_lst.append(inputs)\n",
        "  targets_lst.append(targets)\n",
        "\n",
        " inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        " targets_tensor = torch.stack(targets_lst).to(device)\n",
        " return inputs_tensor, targets_tensor\n",
        "\n",
        "inputs, targets = custom_collate_draft_2(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrZ4PkdE3Lfv",
        "outputId": "44528029-aa65-4e66-cea3-d8fe847267cb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256, 50256, 50256, 50256],\n",
            "        [    8,     9, 50256, 50256, 50256]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Update collate function to replace the padding tokens with placeholder(-100)"
      ],
      "metadata": {
        "id": "zrB5huHa5zWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(batch,pad_token_id=50256,ignore_index=-100,\n",
        " allowed_max_length=None,\n",
        " device=\"cpu\"\n",
        "):\n",
        "\n",
        " batch_max_length = max(len(item)+1 for item in batch)\n",
        " inputs_lst, targets_lst = [], []\n",
        " for item in batch:\n",
        "  new_item = item.copy()\n",
        "  new_item += [pad_token_id]\n",
        "\n",
        "  # Pads sequence to the max length\n",
        "  padded = (\n",
        "    new_item + [pad_token_id] *\n",
        "    (batch_max_length - len(new_item))\n",
        "    )\n",
        "\n",
        "  inputs = torch.tensor(padded[:-1]) # Truncates the last token for inputs\n",
        "  targets = torch.tensor(padded[1:]) # Shifts +1 to the right for targets\n",
        "\n",
        "# Replace all but the first padding tokens in targets by ignore_index\n",
        "  mask = targets == pad_token_id\n",
        "  indices = torch.nonzero(mask).squeeze()\n",
        "  if indices.numel() > 1:\n",
        "    targets[indices[1:]] = ignore_index\n",
        "\n",
        "  # Optionally truncates to the max sequence length\n",
        "  if allowed_max_length is not None:\n",
        "    inputs = inputs[:allowed_max_length]\n",
        "  targets = targets[:allowed_max_length]\n",
        "\n",
        "  inputs_lst.append(inputs)\n",
        "  targets_lst.append(targets)\n",
        "\n",
        " inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        " targets_tensor = torch.stack(targets_lst).to(device)\n",
        " return inputs_tensor, targets_tensor"
      ],
      "metadata": {
        "id": "L0jkbvcb4NrB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, targets = custom_collate_fn(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koRynGwC7kJ1",
        "outputId": "5d1530ef-bc9c-4bf8-ba2e-aa0207a1bef9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256,  -100,  -100,  -100],\n",
            "        [    8,     9, 50256,  -100,  -100]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building Dataloader"
      ],
      "metadata": {
        "id": "dpaBqG2AZZTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "customized_collate_fn = partial(\n",
        " custom_collate_fn,\n",
        " device=device,\n",
        " allowed_max_length=1024\n",
        ")"
      ],
      "metadata": {
        "id": "NqkKjruz7pfP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken\n",
        "import tiktoken\n",
        "# Define the tokenizer here\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d4TvE8vaTrw",
        "outputId": "81fc9db0-cb1c-493d-86fe-3fe5795a8d6a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "torch.manual_seed(123)\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        " train_dataset,\n",
        " batch_size=batch_size,\n",
        " collate_fn=customized_collate_fn,\n",
        " shuffle=True,\n",
        " drop_last=True,\n",
        " num_workers=num_workers\n",
        ")\n",
        "\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        " val_dataset,\n",
        " batch_size=batch_size,\n",
        " collate_fn=customized_collate_fn,\n",
        " shuffle=False,\n",
        " drop_last=False,\n",
        " num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        " test_dataset,\n",
        " batch_size=batch_size,\n",
        " collate_fn=customized_collate_fn,\n",
        " shuffle=False,\n",
        " drop_last=False,\n",
        " num_workers=num_workers\n",
        ")"
      ],
      "metadata": {
        "id": "jKcaVaFXZfDf"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader:\")\n",
        "for inputs, targets in train_loader:\n",
        " print(inputs.shape, targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faEWfykUaA2k",
        "outputId": "34177177-d9de-4c4b-9464-12c0e1c03b1c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 57]) torch.Size([8, 57])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading a pretrained LLM**"
      ],
      "metadata": {
        "id": "hFmVgYFRapdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EHQXn8jxafMm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}