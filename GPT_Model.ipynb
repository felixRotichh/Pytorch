{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM757/V73+hZrSImQBIW4m4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyLEgAZs3-Be",
        "outputId": "561ead2c-3f07-45c2-c646-cf191d820307"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4tp8rop76re4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        " \"vocab_size\": 50257, # Vocabulary size\n",
        " \"context_length\": 1024, # Context length\n",
        " \"emb_dim\": 768, # Embedding dimension\n",
        " \"n_heads\": 12, # Number of attention heads\n",
        " \"n_layers\": 12, # Number of layers\n",
        " \"drop_rate\": 0.1, # Dropout rate\n",
        " \"qkv_bias\": False # Query-Key-Value bias\n",
        "}"
      ],
      "metadata": {
        "id": "D_5syb9L-g7N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length,\n",
        "                 dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads) == 0, \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.tril(torch.ones(context_length, context_length)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        keys = keys.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "\n",
        "        attn_scores = queries @ keys.transpose(2,3)\n",
        "\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "        attn_scores.masked_fill_(~mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(\n",
        "                attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = (attn_weights @ values).transpose(1,2)\n",
        "        context_vec = context_vec.contiguous().view(\n",
        "                b, num_tokens, self.d_out\n",
        "            )\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "        return context_vec\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        " def __init__(self, emb_dim):\n",
        "  super().__init__()\n",
        "  self.eps = 1e-6\n",
        "  self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "  self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        " def forward(self, x):\n",
        "  mean = x.mean(dim=-1, keepdim=True)\n",
        "  var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "  norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "  return self.scale * norm_x + self.shift\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "    nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "    nn.GELU(),\n",
        "    nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.att = MultiHeadAttention(\n",
        "    d_in=cfg[\"emb_dim\"],\n",
        "    d_out=cfg[\"emb_dim\"],\n",
        "    context_length=cfg[\"context_length\"],\n",
        "    num_heads=cfg[\"n_heads\"],\n",
        "    dropout=cfg[\"drop_rate\"],\n",
        "    qkv_bias=cfg[\"qkv_bias\"])\n",
        "    self.ff = FeedForward(cfg)\n",
        "    self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "  def forward(self, x):\n",
        "    shortcut = x\n",
        "    x = self.norm1(x)\n",
        "    x = self.att(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "    shortcut = x\n",
        "    x = self.norm2(x)\n",
        "    x = self.ff(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "    return x\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        " def __init__(self, cfg):\n",
        "  super().__init__()\n",
        "  self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "  self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "  self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "  self.trf_blocks = nn.Sequential(\n",
        "  *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "  self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "  self.out_head = nn.Linear(\n",
        "  cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "  )\n",
        " def forward(self, in_idx):\n",
        "  batch_size, seq_len = in_idx.shape\n",
        "  tok_embeds = self.tok_emb(in_idx)\n",
        "\n",
        "  pos_embeds = self.pos_emb(\n",
        "  torch.arange(seq_len, device=in_idx.device)\n",
        "  )\n",
        "  x = tok_embeds + pos_embeds\n",
        "  x = self.drop_emb(x)\n",
        "  x = self.trf_blocks(x)\n",
        "  x = self.final_norm(x)\n",
        "  logits = self.out_head(x)\n",
        "  return logits"
      ],
      "metadata": {
        "id": "OKWY9VWZ-Kx6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "batch = torch.randint(0, GPT_CONFIG_124M[\"vocab_size\"], (2, GPT_CONFIG_124M[\"context_length\"]))\n",
        "out = model(batch)\n",
        "print(\"Input batch:\\n\", batch)\n",
        "print(\"\\nOutput shape:\", out.shape)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_dX18cq-TG1",
        "outputId": "635bf6de-c7a3-4085-e0c9-8e2c6f56d947"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch:\n",
            " tensor([[ 3397, 40754, 26433,  ..., 35345, 40953, 24547],\n",
            "        [34307, 49980, 24558,  ..., 29291, 23668, 40982]])\n",
            "\n",
            "Output shape: torch.Size([2, 1024, 50257])\n",
            "tensor([[[-4.4988e-01,  3.7144e-01, -2.6064e-01,  ...,  4.6247e-01,\n",
            "          -8.3105e-01,  6.2966e-02],\n",
            "         [-4.4622e-01, -5.5609e-01, -1.4426e-01,  ..., -5.6610e-01,\n",
            "           2.4956e-02,  5.0456e-01],\n",
            "         [-7.3955e-01, -6.8164e-02, -6.2195e-01,  ...,  1.1588e+00,\n",
            "          -2.7165e-01,  6.1499e-01],\n",
            "         ...,\n",
            "         [ 5.3372e-01, -3.7606e-01,  3.3681e-01,  ..., -3.8556e-01,\n",
            "          -1.1487e+00, -9.2615e-01],\n",
            "         [ 1.9850e-01, -6.9179e-01, -1.0179e+00,  ...,  6.7727e-01,\n",
            "           3.5975e-01, -1.8631e-01],\n",
            "         [-6.3795e-02, -2.6473e-01, -5.2965e-02,  ...,  4.1374e-01,\n",
            "           3.4266e-01,  3.7704e-01]],\n",
            "\n",
            "        [[-1.1963e+00, -4.4219e-01, -1.0411e+00,  ...,  4.3231e-01,\n",
            "          -9.1801e-01,  6.0357e-01],\n",
            "         [-1.6158e-01, -3.4724e-01,  1.7501e-01,  ..., -5.4028e-01,\n",
            "          -2.1249e-01,  1.4158e-01],\n",
            "         [ 1.9585e-04,  5.0858e-01, -1.1520e+00,  ...,  1.1257e+00,\n",
            "           1.4296e-01,  1.6363e-01],\n",
            "         ...,\n",
            "         [ 3.0075e-01, -4.5933e-01,  4.3516e-01,  ..., -8.5221e-01,\n",
            "          -7.9998e-01, -1.0335e+00],\n",
            "         [-3.5162e-01, -8.6008e-02, -2.2035e-01,  ...,  7.4838e-01,\n",
            "           1.3715e-01, -1.0452e-01],\n",
            "         [-3.9482e-01, -3.0221e-02,  1.4346e-01,  ..., -3.2870e-01,\n",
            "          -4.5294e-01,  2.8199e-01]]], grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters: {total_params:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG5OZmArEha5",
        "outputId": "69a17f7b-4207-4f16-f09c-fdc22648d451"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 163,018,752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
        "print(\"Output layer shape:\", model.out_head.weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIiQpP7swD7J",
        "outputId": "e855fac3-95f4-4c77-ba10-264e2b2252b2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token embedding layer shape: torch.Size([50257, 768])\n",
            "Output layer shape: torch.Size([50257, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Weight tying reduces the overall memory footprint and computational complexity\n",
        "of the model**"
      ],
      "metadata": {
        "id": "Icrq3hn5yMG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_params_gpt2 = (\n",
        " total_params - sum(p.numel()\n",
        " for p in model.out_head.parameters())\n",
        ")\n",
        "print(f\"Number of trainable parameters \"\n",
        " f\"considering weight tying: {total_params_gpt2:,}\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRKPB9HExpUA",
        "outputId": "46b1095a-7d49-434c-86d0-f4ca79bdb659"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters considering weight tying: 124,421,376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memory requirements of the 163 million parameters in our GPTModel object\n",
        "\n",
        "total_size_bytes = total_params * 4\n",
        "total_size_mb = total_size_bytes / (1024 * 1024)\n",
        "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du1TTVHOx00L",
        "outputId": "a3c478be-6281-4353-edc7-0da5dd76eb5a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total size of the model: 621.87 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generating Texts**"
      ],
      "metadata": {
        "id": "l2XEg2HJ2o5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_simple(model, idx,\n",
        "  max_new_tokens, context_size):\n",
        "  for _ in range(max_new_tokens):\n",
        "    idx_cond = idx[:, -context_size:]\n",
        "    with torch.no_grad():\n",
        "      logits = model(idx_cond)\n",
        "\n",
        "    logits = logits[:, -1, :]\n",
        "    probas = torch.softmax(logits, dim=-1)\n",
        "    idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "    idx = torch.cat((idx, idx_next), dim=1)\n",
        "    return idx"
      ],
      "metadata": {
        "id": "PgdFoEIxyhxc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "start_context = \"Hello, I am\"\n",
        "encoded = tokenizer.encode(start_context)\n",
        "print(\"encoded:\", encoded)\n",
        "\n",
        "encoded_tensor = torch.tensor(encoded).unsqueeze(0) #Add batch dimension\n",
        "print(\"encoded_tensor.shape:\", encoded_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQwQqxrt2xSY",
        "outputId": "578654ce-9194-400c-d73a-f61cd5837e8a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoded: [15496, 11, 314, 716]\n",
            "encoded_tensor.shape: torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Put the model into .eval() mode. This disables random components like\n",
        "dropout, which are only used during training**"
      ],
      "metadata": {
        "id": "rdRGexi44x8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "out = generate_text_simple(\n",
        " model=model,\n",
        " idx=encoded_tensor,\n",
        " max_new_tokens=6,\n",
        " context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "print(\"Output:\", out)\n",
        "print(\"Output length:\", len(out[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPc3Yc1b4MbT",
        "outputId": "34d13b11-bae1-4dea-c68c-e3bcfd300076"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: tensor([[15496,    11,   314,   716, 35325]])\n",
            "Output length: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using the .decode method of the tokenizer, we can convert the IDs back into text**"
      ],
      "metadata": {
        "id": "qW7vAUma5Lvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
        "print(decoded_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9_SfNTk5ETc",
        "outputId": "e8552ae2-fe0f-49e5-d4e9-6a556511de4c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, I am epilepsy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using GPT to generate text"
      ],
      "metadata": {
        "id": "RcbclCD77Qvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        " \"vocab_size\": 50257,\n",
        " \"context_length\": 256, #Reduced Context length to 256\n",
        " \"emb_dim\": 768,\n",
        " \"n_heads\": 12,\n",
        " \"n_layers\": 12,\n",
        " \"drop_rate\": 0.1,\n",
        " \"qkv_bias\": False\n",
        "}\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxKART6-5RI_",
        "outputId": "4b5c6aa2-0abf-4b88-ee73-c3f00ddb16c1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Utility functions for text to token ids conversion**"
      ],
      "metadata": {
        "id": "gGtqrPc0PO6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_token_ids(text, tokenizer):\n",
        " encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        " encoded_tensor = torch.tensor(encoded).unsqueeze(0) #.unsqueeze(0) adds batch dimension\n",
        " return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        " flat = token_ids.squeeze(0) #removes batch dimension\n",
        " return tokenizer.decode(flat.tolist())"
      ],
      "metadata": {
        "id": "CgIZJEEN7jqt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_context = \"Every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        " model=model,\n",
        " idx=text_to_token_ids(start_context, tokenizer),\n",
        " max_new_tokens=10,\n",
        " context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")"
      ],
      "metadata": {
        "id": "NChGX4wQNwq8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQANOU6OOUNo",
        "outputId": "9d6960f6-359d-4cb8-c120-72e5ab5290c8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves youLee\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Evaluation"
      ],
      "metadata": {
        "id": "qlqeMPaqWiWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inputs have been mapped to token IDs\n",
        "inputs = torch.tensor([[16833, 3626, 6100], # [\"every effort moves\",\n",
        "                          [40, 1107, 588]]) # \"I really like\"]"
      ],
      "metadata": {
        "id": "qxxHpRYfOgjI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Targets contain Token IDs we want the model to produce\n",
        "targets = torch.tensor([[3626, 6100, 345 ], # [\" effort moves you\",\n",
        " [1107, 588, 11311]]) # \" really like chocolate\"]"
      ],
      "metadata": {
        "id": "elmObceaJjy6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feed the inputs into model to calculate logits vectors for the inputs\n",
        "**"
      ],
      "metadata": {
        "id": "Yi6BBpddOlcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        " logits = model(inputs)\n",
        "probas = torch.softmax(logits, dim=-1)  #Probability of each token in the vocabulary\n",
        "print(probas.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Myk9PF4DKb_Y",
        "outputId": "a7b227a0-5356-4683-b064-a960e6178811"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 50257])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Applying argmax function to the probability scores to get token IDs**"
      ],
      "metadata": {
        "id": "rQ8GBKorLeZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "print(\"Token IDs:\\n\", token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It5hS3wFK1_M",
        "outputId": "88ab073e-b70a-4c55-b800-6fc3e8b3dc40"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[[13195],\n",
            "         [41034],\n",
            "         [ 8429]],\n",
            "\n",
            "        [[19385],\n",
            "         [40202],\n",
            "         [23677]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Convert token IDs back into text. The model produces random text that is different from the target text because it has\n",
        "not been trained yet**\n",
        "\n"
      ],
      "metadata": {
        "id": "xRpc22mTL2lK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
        "print(f\"Outputs batch 1:\"\n",
        " f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZQbfDihLsDh",
        "outputId": "407929d7-66f5-4ad5-8695-f98c5ea0e9f3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Targets batch 1:  effort moves you\n",
            "Outputs batch 1: War probing sword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**initial softmax probability scores cor\u0002responding to the target tokens**"
      ],
      "metadata": {
        "id": "lPV_9EM0N7CV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_idx = 0\n",
        "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 1:\", target_probas_1)\n",
        "\n",
        "text_idx = 1\n",
        "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 2:\", target_probas_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GycObu7-MEsc",
        "outputId": "f1ad5602-a206-41f5-85e2-ece2e1b9c859"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1: tensor([1.4403e-05, 1.6720e-05, 8.6229e-06])\n",
            "Text 2: tensor([1.2030e-05, 4.5597e-05, 6.2099e-05])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**calculate the loss for the probability scores of the two example batches. We apply logarithm to the probability scores**"
      ],
      "metadata": {
        "id": "Oh1jMz67Pm7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
        "print(log_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw3_Q2e9N5UO",
        "outputId": "bc5414ac-6f02-423b-9e8e-b4e0f0698d75"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-11.1481, -10.9989, -11.6611, -11.3281,  -9.9957,  -9.6868])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combine these log probabilities into a single score by computing the aver\u0002age**"
      ],
      "metadata": {
        "id": "o-eajB7FQX5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_log_probas = torch.mean(log_probas)\n",
        "print(avg_log_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5LhXhVcP3wN",
        "outputId": "87c1ad88-6822-4531-9be6-8d8911dec3a3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-10.8031)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating the average negative log probability**"
      ],
      "metadata": {
        "id": "IdUOeJjdQ4r9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neg_avg_log_probas = avg_log_probas * -1\n",
        "print(neg_avg_log_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFZTtPgDQgFU",
        "outputId": "59aec472-d4ea-43d7-9ee3-6ce160eefb47"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.8031)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The term for turning -10.8031 to 10.8031 is called cross entropy loss"
      ],
      "metadata": {
        "id": "lKgSfca4R-NV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Logits shape:\", logits.shape)\n",
        "print(\"Targets shape:\", targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMKuDcH4R84d",
        "outputId": "06364f77-665e-408a-b185-42ffe3c8a3cd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape: torch.Size([2, 3, 50257])\n",
            "Targets shape: torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the cross_entropy loss function in PyTorch, we want to flatten these tensors\n",
        "by combining them over the batch dimension"
      ],
      "metadata": {
        "id": "1hHwzdbpTRnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits_flat = logits.flatten(0, 1)\n",
        "targets_flat = targets.flatten()\n",
        "print(\"Flattened logits:\", logits_flat.shape)\n",
        "print(\"Flattened targets:\", targets_flat.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj-DOEGMS1Fp",
        "outputId": "af57ff10-20f8-4236-b548-98063e330d1f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flattened logits: torch.Size([6, 50257])\n",
            "Flattened targets: torch.Size([6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using PyTorch's cross entropy function to calculate loss**"
      ],
      "metadata": {
        "id": "9zvdPzVsTxW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN6nJpnNTPyj",
        "outputId": "94899a68-e75f-4d38-be88-75db5dfc11ed"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.8031)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating Perplexity"
      ],
      "metadata": {
        "id": "4vsKYLR8VIPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity = torch.exp(loss)\n",
        "print(perplexity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mNQP5ywTv0H",
        "outputId": "469e95a2-82f4-4c5f-c841-fd34f47c5b34"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(49173.1719)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perplexity can provide a more interpre\u0002table way to understand the uncertainty of a model in predicting the next token in a\n",
        "sequence**"
      ],
      "metadata": {
        "id": "ShyyMuZKVTeG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating the training and validation set losses"
      ],
      "metadata": {
        "id": "wbfOMv2BWJrb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train on \"The Verdict\" short story"
      ],
      "metadata": {
        "id": "ef-hfnkBdLu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
        " \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
        " \"the-verdict.txt\")\n",
        "file_path = \"the-verdict.txt\"\n",
        "urllib.request.urlretrieve(url, file_path)"
      ],
      "metadata": {
        "id": "AKyVSLyZVMcN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "167f72fd-0ed2-435c-d89d-3ee1a3e88eea"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('the-verdict.txt', <http.client.HTTPMessage at 0x7b2583c35e90>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"the-verdict.txt\"\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        " text_data = file.read()"
      ],
      "metadata": {
        "id": "Fu3wnVKHdyJj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check number of characters and tokens in the dataset"
      ],
      "metadata": {
        "id": "dMUmamCyeqil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_characters = len(text_data)\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "print(\"Characters:\", total_characters)\n",
        "print(\"Tokens:\", total_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAToJQIpelIE",
        "outputId": "03f87602-3b95-4628-a833-8bb0a9bfc383"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Characters: 20479\n",
            "Tokens: 5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dividing dataset into a training and a validation set**"
      ],
      "metadata": {
        "id": "WGk4wrnqfkdg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataloader"
      ],
      "metadata": {
        "id": "Z9YxzUUmg2UM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "1zpn9gP1hgLe"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        token_ids = tokenizer.encode(txt) #tokenizes the entire text\n",
        "\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i+max_length]\n",
        "            target_chunk = token_ids[i+1:i+max_length+1]\n",
        "\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "     #Returns total number of rows in the dataset\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    #Returns a single row from the dataset\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "    #Dataloader to generate batches with input pairs\n",
        "    def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128,\n",
        "                             shuffle=True, drop_last=True, num_workers=0):\n",
        "        tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "        dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "        dataloader = DataLoader(\n",
        "            dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=shuffle,\n",
        "            drop_last=drop_last,\n",
        "            num_workers=num_workers\n",
        "        )\n",
        "\n",
        "\n",
        "        return dataloader"
      ],
      "metadata": {
        "id": "fnfCkgnag1sO"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a train_ratio"
      ],
      "metadata": {
        "id": "H3b7eXwNf2iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]"
      ],
      "metadata": {
        "id": "CZ_8xm_oe0bn"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating dataloaders for train_data and val_data"
      ],
      "metadata": {
        "id": "9K8cTuYpiEWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = GPTDatasetV1.create_dataloader_v1(\n",
        " train_data,\n",
        " batch_size=2,\n",
        " max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        " stride=GPT_CONFIG_124M[\"context_length\"],\n",
        " drop_last=True,\n",
        " shuffle=True,\n",
        " num_workers=0\n",
        ")\n",
        "val_loader = GPTDatasetV1.create_dataloader_v1(\n",
        " val_data,\n",
        " batch_size=2,\n",
        " max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        " stride=GPT_CONFIG_124M[\"context_length\"],\n",
        " drop_last=False,\n",
        " shuffle=False,\n",
        " num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "UypJpdu_gDxi"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if dataloaders were created"
      ],
      "metadata": {
        "id": "fluJNds2mFQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader:\")\n",
        "for x, y in train_loader:\n",
        " print(x.shape, y.shape)\n",
        "\n",
        "print(\"\\nValidation loader:\")\n",
        "for x, y in val_loader:\n",
        " print(x.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OBHKi7ok8mY",
        "outputId": "c94e8b00-83d8-406d-8a87-35988c1fde1d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            "Validation loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement utility function to calculate cross entropy loss of a given batch"
      ],
      "metadata": {
        "id": "dsS8mYkWiYL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        " input_batch = input_batch.to(device)\n",
        " target_batch = target_batch.to(device)\n",
        " logits = model(input_batch)\n",
        " loss = torch.nn.functional.cross_entropy(\n",
        " logits.flatten(0, 1), target_batch.flatten()\n",
        " )\n",
        " return loss"
      ],
      "metadata": {
        "id": "etYoTe6EmJpD"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to compute training and validation loss**"
      ],
      "metadata": {
        "id": "v7NI94KQiqIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        " total_loss = 0.\n",
        " if len(data_loader) == 0:\n",
        "  return float(\"nan\")\n",
        " elif num_batches is None:\n",
        "  num_batches = len(data_loader)\n",
        " else:\n",
        "  num_batches = min(num_batches, len(data_loader))\n",
        " for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "  if i < num_batches:\n",
        "    loss = calc_loss_batch(\n",
        "      input_batch, target_batch, model, device\n",
        "    )\n",
        "    total_loss += loss.item() # Sums loss for each batch\n",
        "  else:\n",
        "    break\n",
        " return total_loss / num_batches  #Avgs loss over all the batches"
      ],
      "metadata": {
        "id": "9J6Ws5iAik4g"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "with torch.no_grad():\n",
        " train_loss = calc_loss_loader(train_loader, model, device)\n",
        " val_loss = calc_loss_loader(val_loader, model, device)\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdAI6QwHjcTJ",
        "outputId": "9381aed0-6722-48d3-b260-fdfdff4d5adf"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 11.002762688530815\n",
            "Validation loss: 11.05290699005127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training an LLM"
      ],
      "metadata": {
        "id": "OlhlHZPWk9LO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing LLM training flow"
      ],
      "metadata": {
        "id": "X4EJNFJUmgkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        " model.eval()\n",
        " with torch.no_grad():\n",
        "  train_loss = calc_loss_loader(\n",
        "    train_loader, model, device, num_batches=eval_iter\n",
        "    )\n",
        "  val_loss = calc_loss_loader(\n",
        "    val_loader, model, device, num_batches=eval_iter\n",
        "  )\n",
        " model.train()\n",
        " return train_loss, val_loss"
      ],
      "metadata": {
        "id": "jG_J8Ij6oYZj"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        " model.eval()\n",
        " context_size = model.pos_emb.weight.shape[0]\n",
        " encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        " with torch.no_grad():\n",
        "  token_ids = generate_text_simple(\n",
        "  model=model, idx=encoded,\n",
        "  max_new_tokens=50, context_size=context_size\n",
        "  )\n",
        " decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        " print(decoded_text.replace(\"\\n\", \" \"))\n",
        " model.train()"
      ],
      "metadata": {
        "id": "i50CYcfdo6fB"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_simple(model, train_loader, val_loader,\n",
        " optimizer, device, num_epochs,\n",
        " eval_freq, eval_iter, start_context, tokenizer):\n",
        " train_losses, val_losses, track_tokens_seen = [], [], []\n",
        " tokens_seen, global_step = 0, -1\n",
        " for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  for input_batch, target_batch in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    loss = calc_loss_batch(\n",
        "      input_batch, target_batch, model, device\n",
        "      )\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    tokens_seen += input_batch.numel()\n",
        "    global_step += 1\n",
        "    if global_step % eval_freq == 0:\n",
        "      train_loss, val_loss = evaluate_model(\n",
        "        model, train_loader, val_loader, device, eval_iter)\n",
        "      train_losses.append(train_loss)\n",
        "      val_losses.append(val_loss)\n",
        "      track_tokens_seen.append(tokens_seen)\n",
        "      print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "      f\"Train loss {train_loss:.3f}, \"\n",
        "      f\"Val loss {val_loss:.3f}\"\n",
        "      )\n",
        "  generate_and_print_sample(\n",
        "    model, tokenizer, device, start_context\n",
        "  )\n",
        " return train_losses, val_losses, track_tokens_seen"
      ],
      "metadata": {
        "id": "hcLa5AD1kdgq"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(\n",
        " model.parameters(),\n",
        " lr=0.0004, weight_decay=0.1\n",
        ")\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        " model, train_loader, val_loader, optimizer, device,\n",
        " num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        " start_context=\"Every effort moves you, \", tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laOQ8VhDo_fO",
        "outputId": "367e514a-b998-4342-ce1e-9a11c4caef04"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.868, Val loss 10.099\n",
            "Ep 1 (Step 000005): Train loss 8.115, Val loss 8.253\n",
            "Every effort moves you, ,\n",
            "Ep 2 (Step 000010): Train loss 6.662, Val loss 7.041\n",
            "Ep 2 (Step 000015): Train loss 5.962, Val loss 6.549\n",
            "Every effort moves you, ,\n",
            "Ep 3 (Step 000020): Train loss 5.650, Val loss 6.538\n",
            "Ep 3 (Step 000025): Train loss 6.298, Val loss 7.969\n",
            "Every effort moves you, ,\n",
            "Ep 4 (Step 000030): Train loss 5.091, Val loss 6.421\n",
            "Ep 4 (Step 000035): Train loss 4.599, Val loss 6.404\n",
            "Every effort moves you,  was\n",
            "Ep 5 (Step 000040): Train loss 3.691, Val loss 6.291\n",
            "Every effort moves you,  through\n",
            "Ep 6 (Step 000045): Train loss 3.679, Val loss 6.202\n",
            "Ep 6 (Step 000050): Train loss 3.060, Val loss 6.172\n",
            "Every effort moves you,  I\n",
            "Ep 7 (Step 000055): Train loss 2.739, Val loss 6.195\n",
            "Ep 7 (Step 000060): Train loss 2.200, Val loss 6.244\n",
            "Every effort moves you,  through\n",
            "Ep 8 (Step 000065): Train loss 1.956, Val loss 6.195\n",
            "Ep 8 (Step 000070): Train loss 1.393, Val loss 6.221\n",
            "Every effort moves you,  through\n",
            "Ep 9 (Step 000075): Train loss 1.106, Val loss 6.318\n",
            "Ep 9 (Step 000080): Train loss 0.824, Val loss 6.337\n",
            "Every effort moves you,  through\n",
            "Ep 10 (Step 000085): Train loss 0.677, Val loss 6.411\n",
            "Every effort moves you,  through\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot to show training and validation losses"
      ],
      "metadata": {
        "id": "sU62bhh6lE0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator"
      ],
      "metadata": {
        "id": "p4hMpp-An0Bc"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis for tokens seen\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for alignment\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "xi2NLfJRpNOs",
        "outputId": "194f373b-8daf-4884-d38b-a72400b11e34"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAWaFJREFUeJzt3Xd4FFUXwOHfbnpvpAIJAUJCQieEErCBBESkiCBGDaKgSBUrKgjyISqIiAUFFSw0UUCkCkivoYQiEFogoYRQ0iFt935/LCyJ1ISE3YTzPs882Zm5M3N2ks3ZO3PnXo1SSiGEEEIIs6Q1dQBCCCGEuDlJ1EIIIYQZk0QthBBCmDFJ1EIIIYQZk0QthBBCmDFJ1EIIIYQZk0QthBBCmDFJ1EIIIYQZk0QthBBCmDFJ1EJUAMePH0ej0RAXF2fqUIQQpUwStRBmQqPR3HIaOXKkqUMUQpiApakDEEIYnDlzxvh6zpw5jBgxgvj4eOMyR0dHU4QlhDAxqVELYSZ8fHyMk4uLCxqNxjjv5eXFhAkTqFKlCjY2NjRo0IBly5bddF86nY7evXsTEhJCYmIiAH/++SeNGjXC1taW6tWrM2rUKAoKCozbaDQavv/+e7p06YK9vT1BQUEsXLjQuD41NZXo6Gg8PT2xs7MjKCiIadOm3TSG33//nbp162JnZ4eHhwdt2rQhOzvbuP7777+ndu3a2NraEhISwjfffFNk+6SkJLp3746rqyvu7u506tSJ48ePG9f36tWLzp07M378eHx9ffHw8KB///7k5+ff8TkXolxQQgizM23aNOXi4mKcnzBhgnJ2dlazZs1SBw8eVG+99ZaysrJShw4dUkoplZCQoAC1a9culZOTo7p06aIaNmyoUlJSlFJKrVu3Tjk7O6vp06ero0ePqr///ltVq1ZNjRw50ngMQFWpUkXNnDlTHT58WA0aNEg5OjqqCxcuKKWU6t+/v2rQoIGKjY1VCQkJasWKFWrhwoU3jP/06dPK0tJSTZgwQSUkJKg9e/aor7/+WmVmZiqllPr111+Vr6+v+uOPP9SxY8fUH3/8odzd3dX06dOVUkrl5eWp2rVrq969e6s9e/ao/fv3q2eeeUYFBwer3NxcpZRSMTExytnZWb3yyivqwIED6q+//lL29vZqypQppfvLEMLEJFELYYb+m6j9/PzUmDFjipRp0qSJevXVV5VS1xL1+vXrVevWrVXLli1VWlqasWzr1q3VRx99VGT7X375Rfn6+hrnAfX+++8b57OyshSgli5dqpRSqmPHjuqFF164o/h37NihAHX8+PEbrq9Ro4aaOXNmkWWjR49WzZs3N8YWHBys9Hq9cX1ubq6ys7NTy5cvV0oZEnVAQIAqKCgwlnnqqadUjx497ihGIcoLuUcthJnLyMjg9OnTREZGFlkeGRnJ7t27iyzr2bMnVapU4Z9//sHOzs64fPfu3WzcuJExY8YYl+l0OnJycrh06RL29vYA1KtXz7jewcEBZ2dnUlJSAOjXrx9PPvkkO3fupG3btnTu3JkWLVrcMOb69evTunVr6tatS1RUFG3btqVbt264ubmRnZ3N0aNHefHFF+nTp49xm4KCAlxcXIzxHjlyBCcnpyL7zcnJ4ejRo8b5sLAwLCwsjPO+vr7s3bv3FmdTiPJHErUQFchjjz3Gr7/+yubNm3nkkUeMy7Oyshg1ahRdu3a9bhtbW1vjaysrqyLrNBoNer0egPbt23PixAmWLFnCihUraN26Nf3792f8+PHX7dPCwoIVK1awadMm/v77b7788kvee+89tm7davxSMHXqVJo2bXrddlfjbdy4MTNmzLhu356enncUrxAVhSRqIcycs7Mzfn5+bNy4kQcffNC4fOPGjURERBQp269fP+rUqcMTTzzB4sWLjeUbNWpEfHw8NWvWvKtYPD09iYmJISYmhlatWvHmm2/eMFGDIWlGRkYSGRnJiBEjCAgIYP78+QwdOhQ/Pz+OHTtGdHT0Dbdt1KgRc+bMwcvLC2dn57uKWYjyThK1EOXAm2++yQcffECNGjVo0KAB06ZNIy4u7oY1zoEDB6LT6Xj88cdZunQpLVu2ZMSIETz++OP4+/vTrVs3tFotu3fvZt++ffzvf/+7oxhGjBhB48aNCQsLIzc3l0WLFlG7du0blt26dSurVq2ibdu2eHl5sXXrVs6dO2csP2rUKAYNGoSLiwvt2rUjNzeX7du3k5qaytChQ4mOjmbcuHF06tSJDz/8kCpVqnDixAnmzZvHW2+9RZUqVUp+MoUoZyRRC1EODBo0iPT0dF5//XVSUlIIDQ1l4cKFBAUF3bD8kCFD0Ov1PPbYYyxbtoyoqCgWLVrEhx9+yCeffIKVlRUhISG89NJLdxyDtbU1w4YN4/jx49jZ2dGqVStmz559w7LOzs6sW7eOiRMnkpGRQUBAAJ999hnt27cH4KWXXsLe3p5x48bx5ptv4uDgQN26dRkyZAgA9vb2rFu3jrfffpuuXbuSmZlJ5cqVad26tdSwxX1Ho5RSpg5CCCGEEDcmHZ4IIYQQZkwStRBCCGHGJFELIYQQZkwStRBCCGHGJFELIYQQZkwStRBCCGHGJFHfxNdff021atWwtbWladOmbNu2zdQhmYV169bRsWNH/Pz80Gg0LFiwoMh6pRQjRozA19cXOzs72rRpw+HDh4uUuXjxItHR0Tg7O+Pq6sqLL75IVlZWkTJ79uyhVatW2NraUrVqVT799NPrYpk7dy4hISHY2tpSt25dlixZUurv914aO3YsTZo0wcnJCS8vLzp37lxkPGow9HXdv39/PDw8cHR05Mknn+Ts2bNFyiQmJtKhQwfs7e3x8vLizTffLDKcJcCaNWto1KgRNjY21KxZk+nTp18XT0X8DEyePJl69erh7OyMs7MzzZs3Z+nSpcb1cn5L18cff4xGozE+Hw9yjkvExIOCmKXZs2cra2tr9eOPP6p///1X9enTR7m6uqqzZ8+aOjSTW7JkiXrvvffUvHnzFKDmz59fZP3HH3+sXFxc1IIFC9Tu3bvVE088oQIDA9Xly5eNZdq1a6fq16+vtmzZotavX69q1qypevbsaVyfnp6uvL29VXR0tNq3b5+aNWuWsrOzU999952xzMaNG5WFhYX69NNP1f79+9X777+vrKys1N69e8v8HJSVqKgoNW3aNLVv3z4VFxenHnvsMeXv76+ysrKMZV555RVVtWpVtWrVKrV9+3bVrFkz1aJFC+P6goICVadOHdWmTRu1a9cutWTJElWpUiU1bNgwY5ljx44pe3t7NXToULV//3715ZdfKgsLC7Vs2TJjmYr6GVi4cKFavHixOnTokIqPj1fvvvuusrKyUvv27VNKyfktTdu2bVPVqlVT9erVU4MHDzYul3NcfJKobyAiIkL179/fOK/T6ZSfn58aO3asCaMyP/9N1Hq9Xvn4+Khx48YZl6WlpSkbGxs1a9YspZRS+/fvV4CKjY01llm6dKnSaDTq1KlTSimlvvnmG+Xm5mYcd1gppd5++20VHBxsnO/evbvq0KFDkXiaNm2qXn755VJ9j6aUkpKiALV27VqllOFcWllZqblz5xrLHDhwQAFq8+bNSinDFymtVquSk5ONZSZPnqycnZ2N5/Ott95SYWFhRY7Vo0cPFRUVZZy/nz4Dbm5u6vvvv5fzW4oyMzNVUFCQWrFihXrwwQeNiVrOccnIpe//yMvLY8eOHbRp08a4TKvV0qZNGzZv3mzCyMxfQkICycnJRc6di4sLTZs2NZ67zZs34+rqSnh4uLFMmzZt0Gq1bN261VjmgQcewNra2lgmKiqK+Ph4UlNTjWUKH+dqmYr0O0pPTwfA3d0dgB07dpCfn1/kfYeEhODv71/k/NatWxdvb29jmaioKDIyMvj333+NZW517u6Xz4BOp2P27NlkZ2fTvHlzOb+lqH///nTo0OG68yDnuGSkr+//OH/+PDqdrsgfCYC3tzcHDx40UVTlQ3JyMsANz93VdcnJyXh5eRVZb2lpibu7e5EygYGB1+3j6jo3NzeSk5NveZzyTq/XM2TIECIjI6lTpw5geO/W1ta4uroWKfvf83uj83J13a3KZGRkcPnyZVJTUyv0Z2Dv3r00b96cnJwcHB0dmT9/PqGhocTFxcn5LQWzZ89m586dxMbGXrdO/oZLRhK1EGaof//+7Nu3jw0bNpg6lAonODiYuLg40tPT+f3334mJiWHt2rWmDqtCSEpKYvDgwaxYsaLIOOfi7sil7/+oVKkSFhYW17VCPHv2LD4+PiaKqny4en5ude58fHxISUkpsr6goICLFy8WKXOjfRQ+xs3KVITf0YABA1i0aBGrV68uMpyjj48PeXl5pKWlFSn/3/Nb0nPn7OyMnZ1dhf8MWFtbU7NmTRo3bszYsWOpX78+X3zxhZzfUrBjxw5SUlJo1KgRlpaWWFpasnbtWiZNmoSlpSXe3t5yjktAEvV/WFtb07hxY1atWmVcptfrWbVqFc2bNzdhZOYvMDAQHx+fIucuIyODrVu3Gs9d8+bNSUtLY8eOHcYy//zzD3q9nqZNmxrLrFu3jvz8fGOZFStWEBwcjJubm7FM4eNcLVOef0dKKQYMGMD8+fP5559/rrv837hxY6ysrIq87/j4eBITE4uc37179xb5MrRixQqcnZ0JDQ01lrnVubvfPgN6vZ7c3Fw5v6WgdevW7N27l7i4OOMUHh5OdHS08bWc4xIwdWs2czR79mxlY2Ojpk+frvbv36/69u2rXF1di7RCvF9lZmaqXbt2qV27dilATZgwQe3atUudOHFCKWV4PMvV1VX9+eefas+ePapTp043fDyrYcOGauvWrWrDhg0qKCioyONZaWlpytvbWz333HNq3759avbs2cre3v66x7MsLS3V+PHj1YEDB9QHH3xQ7h/P6tevn3JxcVFr1qxRZ86cMU6XLl0ylnnllVeUv7+/+ueff9T27dtV8+bNVfPmzY3rrz7a0rZtWxUXF6eWLVumPD09b/hoy5tvvqkOHDigvv766xs+2lIRPwPvvPOOWrt2rUpISFB79uxR77zzjtJoNOrvv/9WSsn5LQuFW30rJee4JCRR38SXX36p/P39lbW1tYqIiFBbtmwxdUhmYfXq1Qq4boqJiVFKGR7RGj58uPL29lY2NjaqdevWKj4+vsg+Lly4oHr27KkcHR2Vs7OzeuGFF1RmZmaRMrt371YtW7ZUNjY2qnLlyurjjz++LpbffvtN1apVS1lbW6uwsDC1ePHiMnvf98KNziugpk2bZixz+fJl9eqrryo3Nzdlb2+vunTpos6cOVNkP8ePH1ft27dXdnZ2qlKlSur1119X+fn5RcqsXr1aNWjQQFlbW6vq1asXOcZVFfEz0Lt3bxUQEKCsra2Vp6enat26tTFJKyXntyz8N1HLOS4+jVJKmaYuL4QQQojbkXvUQgghhBmTRC2EEEKYMUnUQgghhBmTRC2EEEKYMUnUQgghhBmTRC2EEEKYMUnUt5Cbm8vIkSPJzc01dSgVkpzfsiXnt+zJOS5bcn4N5DnqW8jIyMDFxYX09HScnZ1NHU6FI+e3bMn5LXtyjsuWnF8DqVELIYQQZkwStRBCCGHGKvx41AUFBezatQtvb2+02uJ9L8nMzATg1KlTZGRklEV49zU5v2VLzm/Zk3Nctiry+dXr9Zw9e5aGDRtiaXnrVFzh71HHxsYSERFh6jCEEEKI62zbto0mTZrcskyFr1F7e3sDhpPh6+tr4miEEEIIOHPmDBEREcYcdSsVPlFfvdzt6+tLlSpVTByNEEIIcc2d3JKVxmRCCCGEGZNELYQQQpgxSdRCCCGEGTPpPep169Yxbtw4duzYwZkzZ5g/fz6dO3c2rldK8cEHHzB16lTS0tKIjIxk8uTJBAUFmS5oIUSFptPpyM/PN3UYopyzsrLCwsKiVPZl0kSdnZ1N/fr16d27N127dr1u/aeffsqkSZP46aefCAwMZPjw4URFRbF//35sbW1NELEQoqJSSpGcnExaWpqpQxEVhKurKz4+Pmg0mrvaj0kTdfv27Wnfvv0N1ymlmDhxIu+//z6dOnUC4Oeff8bb25sFCxbw9NNP38tQDXT5sG48VH8IAprf++MLIcrM1STt5eWFvb39Xf9zFfcvpRSXLl0iJSUF4K4fDTbbx7MSEhJITk6mTZs2xmUuLi40bdqUzZs3myZRr/8M1n4Me2bDKxvBxvHexyCEKHU6nc6YpD08PEwdjqgA7OzsAEhJScHLy+uuLoObbWOy5ORkgOseBvf29jauu5Hc3FwyMjKM09Uu6EpFs37gXAVSj8PKD0pvv0IIk7p6T9re3t7EkYiK5Orf0922eTDbRF1SY8eOxcXFxTiFhoaW2r6zNA78G/GRYSb2ezj6T6ntWwhhenK5W5Sm0vp7MttE7ePjA8DZs2eLLD979qxx3Y0MGzaM9PR047R///5SiSc5PYfHvljPk8utSasTY1j45wC4nFYq+xdCCCFuxGwTdWBgID4+Pqxatcq4LCMjg61bt9K8+c0bctnY2ODs7GycnJycSiUeLycb/N3tycnX0+tkR/Ru1SHjFCwbVir7F0IIc1GtWjUmTpx4x+XXrFmDRqMp8xbz06dPx9XVtUyPYY5MmqizsrKIi4sjLi4OMDQgi4uLIzExEY1Gw5AhQ/jf//7HwoUL2bt3L88//zx+fn5FnrW+V7RaDRO618fdwZq45Dx+9n4bNFrYPRMOLr7n8QghhEajueU0cuTIEu03NjaWvn373nH5Fi1acObMGVxcXEp0PHFrJm31vX37dh5++GHj/NChQwGIiYlh+vTpvPXWW2RnZ9O3b1/S0tJo2bIly5YtM9kz1F7Otnz6ZD1e+nk7I+OceKTRS/jvnwJ/DYaqTcGhkkniEkLcn86cOWN8PWfOHEaMGEF8fLxxmaPjtSdTlFLodLrbjn0M4OnpWaw4rK2tb3lLUtwdk9aoH3roIZRS103Tp08HDN8WP/zwQ5KTk8nJyWHlypXUqlXLlCHTJtSb55oFANAj/hEKKtWG7HOw6DWo2EN7CyHMjI+Pj3FycXFBo9EY5w8ePIiTkxNLly6lcePG2NjYsGHDBo4ePUqnTp3w9vbG0dGRJk2asHLlyiL7/e+lb41Gw/fff0+XLl2wt7cnKCiIhQsXGtf/99L31UvUy5cvp3bt2jg6OtKuXbsiXywKCgoYNGgQrq6ueHh48PbbbxMTE1PsK6aTJ0+mRo0aWFtbExwczC+//GJcp5Ri5MiR+Pv7Y2Njg5+fH4MGDTKu/+abbwgKCsLW1hZvb2+6detWrGPfK2Z7j9qcvdehNkFejpzJ1vM/q0EorSUcWAj7/jB1aEKIUqKU4lJegUkmVYpf+t955x0+/vhjDhw4QL169cjKyuKxxx5j1apV7Nq1i3bt2tGxY0cSExNvuZ9Ro0bRvXt39uzZw2OPPUZ0dDQXL168aflLly4xfvx4fvnlF9atW0diYiJvvPGGcf0nn3zCjBkzmDZtGhs3biQjI4MFCxYU673Nnz+fwYMH8/rrr7Nv3z5efvllXnjhBVavXg3AH3/8weeff853333H4cOHWbBgAXXr1gUMV3QHDRrEhx9+SHx8PMuWLeOBBx4o1vHvFbPt8MSc2VpZMKlnQzp9vZHpCS50CutLw6PfwOLXISASnO+uFxohhOldztcROmK5SY69/8Mo7K1L59/zhx9+yKOPPmqcd3d3p379+sb50aNHM3/+fBYuXMiAAQNuup9evXrRs2dPAD766CMmTZrEtm3baNeu3Q3L5+fn8+2331KjRg0ABgwYwIcffmhc/+WXXzJs2DC6dOkCwFdffcWSJUuK9d7Gjx9Pr169ePXVVwHD7dMtW7Ywfvx4Hn74YRITE/Hx8aFNmzZYWVnh7+9PREQEAImJiTg4OPD444/j5OREQEAADRs2LNbx7xWpUZdQbV9n3m0fAkB0fAsue9YDR2/ISTNtYEIIUUh4eHiR+aysLN544w1q166Nq6srjo6OHDhw4LY16nr16hlfOzg44OzsbOwi80bs7e2NSRoM3WheLZ+ens7Zs2eNSRPAwsKCxo0bF+u9HThwgMjIyCLLIiMjOXDgAABPPfUUly9fpnr16vTp04f58+dTUFAAwKOPPkpAQADVq1fnueeeY8aMGVy6dKlYx79XpEZ9F2JaVGPtoXOsjj/HizlD+LFfFLb20q2oEBWBnZUF+z+MMtmxS4uDg0OR+TfeeIMVK1Ywfvx4atasiZ2dHd26dSMvL++W+7Gysioyr9Fo0Ov1xSpfmpf070TVqlWJj49n5cqVrFixgldffZVx48axdu1anJyc2LlzJ2vWrOHvv/9mxIgRjBw5ktjYWLN7BExq1HdBo9Ew7qn6VHK0YdM5W8auOH5tpTQsE6Jc02g02FtbmmQqyx7SNm7cSK9evejSpQt169bFx8eH48ePl9nxbsTFxQVvb29iY2ONy3Q6HTt37izWfmrXrs3GjRuLLNu4cWORHint7Ozo2LEjkyZNYs2aNWzevJm9e/cCYGlpSZs2bfj000/Zs2cPx48f559/zK/HSalR36VKjjaMf6oevabF8tPmEzxQ053WqXPg2Fp4dh5o5buQEMJ8BAUFMW/ePDp27IhGo2H48OG3rBmXlYEDBzJ27Fhq1qxJSEgIX375JampqcX6kvLmm2/SvXt3GjZsSJs2bfjrr7+YN2+esRX79OnT0el0NG3aFHt7e3799Vfs7OwICAhg0aJFHDt2jAceeAA3NzeWLFmCXq8nODi4rN5yiUkWKQUPBXvxYstAAD77Yw36tZ/CsdVwcJGJIxNCiKImTJiAm5sbLVq0oGPHjkRFRdGoUaN7Hsfbb79Nz549ef7552nevDmOjo5ERUUVq5+Mzp0788UXXzB+/HjCwsL47rvvmDZtGg899BBgGA966tSpREZGUq9ePVauXMlff/2Fh4cHrq6uzJs3j0ceeYTatWvz7bffMmvWLMLCwsroHZecRt3rmwb32MmTJ6latSpJSUlUqVKlzI6TW6Cj89ebOHAmg3f9dvJSy2poGz4L0sm/EGYvJyeHhIQEAgMDTdah0v1Or9dTu3ZtunfvzujRo00dTqm41d9VcXKT1KhLiY2lBV/2bICtlZaPTjfix+xISdJCCHETJ06cYOrUqRw6dIi9e/fSr18/EhISeOaZZ0wdmtmRRF2Kano5MfxxQyOGT5YdZN+pdLicCgeL92ygEEJUdFqtlunTp9OkSRMiIyPZu3cvK1eupHbt2qYOzexIY7JS9kyEP2vjz/H3/rOMnLmK37Tvos0+D33+Ad96t9+BEELcB6pWrXpdi21xY1KjLmUajYZPnqyHt7MN2y9Ys18TBPp8mP8KFOSaOjwhhBDljCTqMuDmYM3n3Rug0WiISelJro07pPwLaz42dWhCCCHKGUnUZaRFzUq8/EANLuDCsNzehoUbJ0LSNpPGJYQQonyRRF2Ghj5ai3pVXJiX04j1dq1B6Q2XwPPMsz9ZIYQQ5kcSdRmyttTyxdMNsbe2oH9qD7KsveDiUVg50tShCSGEKCckUZexwEoOjHwijAwcGZh95RL4tu8MXYwKIYQQtyGJ+h54qnEVOtTzZbWuHn9aXhm79c/+kJNh2sCEEAJ46KGHGDJkiHG+WrVqTJw48ZbbaDQaFixYcNfHLq393MrIkSNp0KBBmR6jLEmivgc0Gg0fda5LZVc7hmV154KVL6QnwfJhpg5NCFGOdezYkXbt2t1w3fr169FoNOzZs6fY+42NjaVv3753G14RN0uWZ86coX379qV6rIpGEvU94mJvxec9GpCjseWVrD4oNLDrV4hfZurQhBDl1IsvvsiKFSs4efLkdeumTZtGeHg49eoVv6MlT09P7O3tSyPE2/Lx8cHGxuaeHKu8kkR9D0UEujPgkSBiVQg/0cGw8N95pg1KCFFuPf7443h6ejJ9+vQiy7Oyspg7dy4vvvgiFy5coGfPnlSuXBl7e3vq1q3LrFmzbrnf/176Pnz4MA888AC2traEhoayYsWK67Z5++23qVWrFvb29lSvXp3hw4eTn58PGIabHDVqFLt370aj0aDRaIwx//fS9969e3nkkUews7PDw8ODvn37kpWVZVzfq1cvOnfuzPjx4/H19cXDw4P+/fsbj3Un9Ho9H374IVWqVMHGxoYGDRqwbNm1SlNeXh4DBgzA19cXW1tbAgICGDt2LABKKUaOHIm/vz82Njb4+fkxaNCgOz52SUgXovfYoEdqsuHwOcYmdiPTK5h+T7wnvwQhzFledvG3sbABiyufbF0B6HJBowUru9vv19rhjg9jaWnJ888/z/Tp03nvvfeMYznPnTsXnU5Hz549ycrKonHjxrz99ts4OzuzePFinnvuOWrUqEFERMRtj6HX6+natSve3t5s3bqV9PT0Ivezr3JycmL69On4+fmxd+9e+vTpg5OTE2+99RY9evRg3759LFu2zDhWtIuLy3X7yM7OJioqiubNmxMbG0tKSgovvfQSAwYMKPJlZPXq1fj6+rJ69WqOHDlCjx49aNCgAX369Lmj8/bFF1/w2Wef8d1339GwYUN+/PFHnnjiCf7991+CgoKYNGkSCxcu5LfffsPf35+kpCSSkpIA+OOPP/j888+ZPXs2YWFhJCcns3v37js6bklJjrjHLC0Mj2y1/2I9n6U0Rr/mGIPbBJk6LCHEzXzkV/xtnpoOYV0Mrw/+BXN7QUBLeGHxtTIT68KlC9dvOzK9WIfq3bs348aNY+3atcZxmKdNm8aTTz6Ji4sLLi4uvPHGG8byAwcOZPny5fz22293lKhXrlzJwYMHWb58OX5+hnPx0UcfXXdf+f333ze+rlatGm+88QazZ8/mrbfews7ODkdHRywtLfHx8bnpsWbOnElOTg4///wzDg6GLyxfffUVHTt25JNPPsHb2xsANzc3vvrqKywsLAgJCaFDhw6sWrXqjhP1+PHjefvtt3n66acB+OSTT1i9ejUTJ07k66+/JjExkaCgIFq2bIlGoyEgIMC4bWJiIj4+PrRp0wYrKyv8/f3v6DzeDbn0bQJV3e0Z06UOAF+sOsTOw4mw9B3IPGviyIQQ5U1ISAgtWrTgxx9/BODIkSOsX7+eF198EQCdTsfo0aOpW7cu7u7uODo6snz5chITE+9o/wcOHKBq1arGJA3QvHnz68rNmTOHyMhIfHx8cHR05P3337/jYxQ+Vv369Y1JGiAyMhK9Xk98fLxxWVhYGBYWFsZ5X19fUlJS7ugYGRkZnD59msjIyCLLIyMjOXDgAGC4vB4XF0dwcDCDBg3i77//NpZ76qmnuHz5MtWrV6dPnz7Mnz+fgoKCYr3P4pIatYl0alCZtfHnmLfrFJmzXgL9Vsg4CT1+NXVoQojC3j1d/G0sCjWOCulo2IfmP/WiIXvvLq5CXnzxRQYOHMjXX3/NtGnTqFGjBg8++CAA48aN44svvmDixInUrVsXBwcHhgwZQl5eXqkdf/PmzURHRzNq1CiioqJwcXFh9uzZfPbZZ6V2jMKsrKyKzGs0GvR6fantv1GjRiQkJLB06VJWrlxJ9+7dadOmDb///jtVq1YlPj6elStXsmLFCl599VXjFY3/xlVazLpGrdPpGD58OIGBgdjZ2VGjRg1Gjx6NUsrUoZWKUZ3C8He3Z8zlrqRZVkK1HGrqkIQQ/2XtUPzJolAdyMLSsKzw/elb7bcEunfvjlarZebMmfz888/07t3beL9648aNdOrUiWeffZb69etTvXp1Dh06dMf7rl27NklJSZw5c8a4bMuWLUXKbNq0iYCAAN577z3Cw8MJCgrixIkTRd+utTU6ne62x9q9ezfZ2dfu32/cuBGtVktwcPAdx3wrzs7O+Pn5XTfE5saNGwkNDS1SrkePHkydOpU5c+bwxx9/cPHiRQDs7Ozo2LEjkyZNYs2aNWzevJm9e0vvi9d/mXWN+pNPPmHy5Mn89NNPhIWFsX37dl544QVcXFzKvJXdveBka8XEpxvw1LeXaZo1no+SvXiy8pWVSsGVD5oQQtyKo6MjPXr0YNiwYWRkZNCrVy/juqCgIH7//Xc2bdqEm5sbEyZM4OzZs0WS0q20adOGWrVqERMTw7hx48jIyOC9994rUiYoKIjExERmz55NkyZNWLx4MfPnzy9Splq1aiQkJBAXF0eVKlVwcnK67rGs6OhoPvjgA2JiYhg5ciTnzp1j4MCBPPfcc8b706XhzTff5IMPPqBGjRo0aNCAadOmERcXx4wZMwCYMGECvr6+NGzYEK1Wy9y5c/Hx8cHV1ZXp06ej0+lo2rQp9vb2/Prrr9jZ2RW5j13azLpGvWnTJjp16kSHDh2oVq0a3bp1o23btmzbVnFGoGrk78ZrbYLIxZph8/ey40QqnNwO0ztA9g0amgghxA28+OKLpKamEhUVVeR+8vvvv0+jRo2IiorioYcewsfHh86dO9/xfrVaLfPnz+fy5ctERETw0ksvMWbMmCJlnnjiCV577TUGDBhAgwYN2LRpE8OHDy9S5sknn6Rdu3Y8/PDDeHp63vARMXt7e5YvX87Fixdp0qQJ3bp1o3Xr1nz11VfFOxm3MWjQIIYOHcrrr79O3bp1WbZsGQsXLiQoyNCw18nJiU8//ZTw8HCaNGnC8ePHWbJkCVqtFldXV6ZOnUpkZCT16tVj5cqV/PXXX3h4eJRqjIVplBlfR/7oo4+YMmUKf//9N7Vq1WL37t20bduWCRMmEB0dfUf7OHnyJFWrViUpKYkqVaqUccQlo9MrXv5lOysPpFDJ3oLNzu9ilXYUPGvD83+CU+l9kxRCXC8nJ4eEhAQCAwOxtbU1dTiigrjV31VxcpNZ16jfeecdnn76aUJCQrCysqJhw4YMGTLklkk6NzeXjIwM45SZmXkPIy4ZC62GST0bUreyC+cv6Xgpbyh6Rx84dwCmtYf063sdEkIIcX8w60T922+/MWPGDGbOnMnOnTv56aefGD9+PD/99NNNtxk7dqzx2UEXF5c7vg9javbWlvwQE05lVzvWXnRjsO1HKJeqhmExp7WH1OOmDrH8O7nj2mulStaRhRBC3GNmnajffPNNY626bt26PPfcc7z22mvGrtxuZNiwYaSnpxun/fv338OI746Xsy3TXmiCk40lf520ZaTHeJR7dUhLhB/bw/kjpg6x/Nr5M3z/CPw9HPIvw/yXYWYP0N15t4NCCGEKZp2oL126hFZbNEQLC4tbPi9nY2ODs7OzcXJycirrMEtVLW8nJj/bGEuthp/26/g28CuoFAyZpw0167Pl54uHWck+b/hpYW24lXBwMRxfD8vfNW1cQghxG2adqDt27MiYMWNYvHgxx48fZ/78+UyYMIEuXbqYOrQy1TKoEh91rQvAJxvT+LPBFPCuC9kphtbgZ8q2X9kKqdVQeGEpPPI+VAqCrlMNy7dNgR03v5UihBCmZtaJ+ssvv6Rbt268+uqr1K5dmzfeeIOXX36Z0aNHmzq0Mtc9vCoDH6kJwOtLTrOl1XTwawSXL8L0jpAUa9oAy4OM05B7bdQdAlpcezY95DF4+ErfxItfh8St9z4+YXZKs3crIUrr78msH88qDeXh8aybUUoxZE4cf8adxsnGknkv1iVoZW9I3AzWjvDMb1At8vY7uh9dToUfogy9QT3z240fcVMK5sbA/j/BwQv6rgGXyteXExWeXq/n8OHDWFhY4OnpibW1tbFnLyGKSylFXl4e586dQ6fTERQUdN1t3OLkJrPumex+p9Fo+LRbPc6k5bDt+EViZhxgft8ZeC/qBQnrDA2kJFFfryAXZj8L5+PByQ/0N+kwX6OBTt/AhaNwdh/MiTZcHv9vV4+iwtNqtQQGBnLmzBlOny5B395C3IC9vT3+/v7XJenikhp1OZB2KY+ukzdx7Fw2dSo7M+eFBjjs/BZaDAZLa1OHZ170epj3Euz7A2ycofcy8A679Tapx2HKw4bbCvV6QJfvpPvW+5RSioKCgtv2SS3E7VhYWGBpaXnTKzNSo65gXO2tmdarCV2+2cS+UxkM+v0gU55/AwvtlT8AvR7O7ILKjU0bqDlYNdKQpLVW0OOX2ydpALdq0P0n+Lkz7JkDPnWhxcAyDlSYI41Gg5WVVZmNgiRESZh1YzJxTYCHA1OfD8fGUsuqgyl8+Ne/hlHElIKlb8L3bWD3HFOHaVrbpsLGLwyvO30F1R+6820DH4B2HxterxgBR1aWenhCCFESkqjLkcYBbnzeowEAP20+wY8bj4PSGzrwUAqo0Hcxbu3gYlj6luH1I+9D/aeLv4+IPtDwOcM5ndtbOpgRQpgFSdTlzGN1fXn3sRAA/rd4P8v2n4MnvjI0gipJcqoITm6H3180JNhGMdDqjZLtR6OBDp9BlQjQWsCl86UbpxBClIAk6nKoT6vqRDf1RykYMmcXcacyIKD5tQKZyfdPJx4XjsLM7lBwGYLaQocJd9cQzNIGevwKfVeDf7PSi1MIIUpIEnU5pNFoGPVEGA8Fe5KTr+eln2JJunjJsDIvG37uBH8NgrWfXrkkXkFln4cZ3eDSBfBtAN2mgUUptI908jY0MLvq0sW736cQQpSQJOpyytJCy1fPNCLU15nzWXn0mraN9Ev5YO0AdbsZCq0eA6s+rLjJetFrcPEYuPobOjWxcSz9Y8Qvgy8awL/zS3/fQghxByRRl2OONpb82KsJPs62HD2Xzcu/bievQA8PvAltxxgKbZgAy4aB7iadfpRn7cZCQEuI/uPGPY+VhuPrITcddv1acb/wCCHMmiTqcs7HxTA0pqONJVuOXeSdP/YYHttqMcDQMApg62T4PMxQu754zLQBlyaXKtBrEXjWKrtjtBkF7T+Fp2dJJyhCCJOQRF0B1PZ15uvoRlhoNczbdYqJKw8bVjR5yTBKlL0HZCXD+s9gUkP4qSPs/R3yc0wbeElsmQz/Lrg2X9bJ08ISmr5ctAc4qVkLIe4hSdQVxIO1PBndqQ4AX6w6zO87ThpW1OsOQw/CUz9BjdaAxtBP+B8vwmfBsPTtoiNMmbPjG2DZOzC3F5zede+Prysw3Ea4+ry2EELcA9KFaAXyTFN/Ei9e4tu1Rxk2bw9+rra0qFHJUBsM62yY0hJh1wzDPdeMkxC/BKLGXtuJXmd4htgc+TeHJn1AozW08r7XTm6DLd8YXnvXgcYx9z4GIcR9R2rUFcxbUcF0qOdLvk7x8i87OHw2s2gBV394eBgM2WNohNX2f3B1ZJeCPJjUAP7sbxgm0txoLeCxcYauPk1xvzighYxhLYS45yRRVzBarYbPnqpP4wA3MnMK6DUtlpTMG9yL1lpAUBsI7XRt2dFVhhr34ZVg7XRtuS6/7AO/mcyzhr63r8ag0Vz7YmEKD7xhOGf6fJjzLKSfMl0sQoj7giTqCsjWyoKpz4dTzcOeU2mXeemn7YZnrG+nVjt4YRk89um1jkN0BfBVOMx9AY6uNozUda/kZsHMpwwDbSwpYbegpe3qGNbedSA7xTCGdf5lU0clhKjAJFFXUO4O1kx7IQI3eyv2nEznwfGr+XFDguE565vRaAxdkRauZSduNozX/O88+KUzTKoPa8eVfU1SV2BoNHZmN9hXgsjBZXu84rBxhKdngJ27oVHbX4OlJbgQosxolKrY/2GKMzh3RbTnZBqv/7abwymGlt3VPOx5p30IUWE+Nx3Q/DpndsPOX2DPb4bOP8DQoKtmG6jxCGgtDUleY2FY7ugFwe2vbX9wMRTkGMrauRmWXTgK5w8bymu0V7bXGi7Ja7QQNxPiZoClHfRaDFXMcKztY2vhly6gdIZ7/TKGtRDiDhUnN0mivg8U6PT8tv0kE1bEcz4rD4Am1dx4r0MoDaq63vmO8i/D/oWw82c4seHm5apEwEsrrs1/FgKZZ+DldeBb37Bs3Xj4Z/Stj6fRQo8ZEPLYncd4r239zvC4lkYL0XMNX16EEOI2ipOb5PGs+4ClhZZnmvrzRAM/vlt7lKnrjxF7PJXOX2+kY30/3ooKpqq7/e13ZGUH9XsYpvNHYPdMQ09nSm+Y9Fd+VqpZdLuqTQ0DZ9gUaqDm5AN+ja5tq5ShZnp1XmsFLYeYd5IGiOgLyXsMj7v93huemw/eda91kFKQC7o8sLA2jMwlhBDFJDXq+9CZ9MuMWx7P/F2nUAqsLbW8EFmNVx+qiYudlanDK38KcmF6BzgZa5h/aRVUCTe83viFodV6vaeh63eGZfmXYWwVw60CraXhcr/W4sr8lWXG11fLWEHb0VDjYcM+Lhw1tB/wCAL/pvf+PQtRHillGGEwNwNyMgr9TP/PfIahbcxDb1/b9vtHDRWMHr+USihSoxa35Otix4TuDegdGciYxQfYfOwC3609xm+xSQxpU4tnmvpjZSHtDO/Y1TGs5zwLZ/YU7TBGrzP81Bb6qOkLDBMFoMstxoEKfac+sREWDjSMwR0999ryCWGGKx+OXuDgeeWnFzh6XvlZaLmVXUnerRB3T6+DY2sMn4PAB8HK1rD81E44F2+4unb1c6LXXZkKzRde71wZIvpc2/ff70PWOXh0lCGxAmz4HDZMhNxMw7Z3wjOkaKLOzbjyub33JFHfx+pUdmFmn6b8czCFj5Yc4Oi5bD5Y+C8/bTrOO+1DeDTU+84bnJUDx85l8eU/RziSksXYrnWpU9ml9Hbu5AMvrbx+eYtB0KwfUOg8WjnA0APX/vkofaHXV/8B6QvN6wwJvXBvbA6ehvvhlcOvLcu7ZOhtDuDC4dvHbO0EDpWg40So/pBhWfJeiF8KXrWhdsdrZdOSwNYZbJxlcBJhqJnmXzLc0rp0wTBm+6WLheYLTZdTDT8DH7x2VQng1ycBZfgsWPkZlu35zTCIUHFUiSiaqPf+bmgT06zftUSt9JCTdq2MRmv4W7Z1BhuXa3/bhX86Vy56nG4/gqVt8WIrJZKo73MajYbWtb15sJYns2KTmLjiEMfOZ9P3lx00DXTnvQ61qVfF1dRh3pWki5eYtOow83adQqc31EqfmbqFn3pH0NDfrWwPbmF57Zn0q7RacPa7u/0Gty/ash4MNftXtxqe785KgexzV36mGGoYhX/q8iAv0zAVdmqHYRzzWu2LJuqvwg0t9zUWhpb7/53s3f+zzBV86htq8mD4EpGbaajF2zrf3XsvbUoZ/pHDtash+ZcNX06UHrxCrpU9tBwykw3r8y/95+eNll2CRs9f+bIGZJyBH9qCnQu8UqhB5voJkHLAcH6s7MHa/trrG/60A0dvwwhyYPhid+mCoSOewn9bFxMMCVSfb/id6/INXwB1V+avvtbnX1mWD+6B1/62CnINNdRLF6Dzt9faXix41dBGpTgyT197rbUwdAl89W/qKs9ahjEJtJZFbwsVntcUnrcEt4Cix4kcYvhi61ho6NuGz0Fwh2uJ2Nqh+F84vcOKV74UmX2iPnXqFG+//TZLly7l0qVL1KxZk2nTphEeHn77jcUds7TQ8lyzADo38GPymqP8sCGBrQkXeeKrjXRpWJk3ooKp7Fq+LpUmp+fw1erDzIlNIl9nSNCtQ7xIu5zPjhOpPPv9Vn7o1YRm1T1MHGkp0VpcSSohty6nlOEy3tWk7VX72jr3GtAoxtChy1X5ORivCCgdXDpvmG7nqekQ1sXwOn6JYSCYwAchZuG1MuNqGpK4hZWhwZ2F9bXXltbXL7OwNowKV7O1YftTO2DNx+AWaOio56qZPQzP+l9NQFcvkxZ+XThJATw6GiIHGV4n74Mf2oBrgKG73atWjzE8rlgcGYX6HMjLgvREyP3P1ZyEtYZLwcXR8Fno9LXh9eWLMP5KI84P0q4loZUjYf+C4u23dsdriVprBbHfG76wRH10rYZqeyV+C2vD6Hz2HoYva8bXHoZ+BgovL5w4AXovvf7Y4b0N091o9sr1yxyv3PYpp8w6UaemphIZGcnDDz/M0qVL8fT05PDhw7i5lXEt6D7mZGvFW+1CiG4WwPgrDc7m7zrFkr1neLFlIP0eqoGTrXk3ODuflcvkNUf5ZcsJYwcvLWtWYmjbWjTyd+NSXgEv/bSdTUcv0GvaNr57LpwHa3maOOp7SKMx/KO1dbm+hX5gK8NUmJUtvH+lFnk5zXAp8/LFKz8LTZcKL0sDp0I1O30BoDH8Yy8sL/tK7bMY8QcXehLgUioc/ht86hUtc+6goaOe4tAXCsLaAWxdr6/9+7cwvK//1m7/W+O1tr/22rVQjc+lCrz0T9FjgWGwmZqP3qBWfoMa+tXau0Ohv9mrbSC0loYvH1drvg6e4FLV8EVHa3Xlp+W1Lz83el25UJ8FWi08/K7hdk3hy74PD4NH3i9ZzVQUm1m3+n7nnXfYuHEj69evL/E+pNX33dlzMo3/LT7AtoSLAHg4WDPk0Vr0bFIVSzNrcJZ2KY8p644xfdNxLuUZGow0qebG622Dr6s15+Tr6PfrDlbHn8PaQsvX0Y14NNT7RrsVpUmvL9pXe8ZpwyXYgrwrl2bzrl2WvdnrgBZQKeja9kf/MbTQDW53bb8J6688FnclQWmv3IIwvra6dun06msr+2uNmsqbq//GJWmWGxWmw5PQ0FCioqI4efIka9eupXLlyrz66qv06dPnptvk5uaSm3utJe2pU6cIDQ2VRH0XlFKs2H+Wj5ce5Nj5bABqeDrw7mO1eSTEy+QNzjJz8vlxw3G+X3+MzFxDq8z6VVx4vW0wrYIq3TS+vAI9g2fvYum+ZCy1Gj7v0YCO9e/y3rEQQtyBMk/USUlJaDQa4863bdvGzJkzCQ0NpW/fviWL+gZsbQ3fbocOHcpTTz1FbGwsgwcP5ttvvyUm5sZjAY8cOZJRo0bdMGZJ1HcnX6dn5tZEJq48ROqVQT7qVXGhZc1KNKvuQeMANxxs7t3dlEt5Bfy06QTfrTtK2pV4QnyceL1tMG1q39kXiAKdnjfm7mZB3Gm0Gvi0W326NZa/EyFE2SrzRN2qVSv69u3Lc889R3JyMsHBwYSFhXH48GEGDhzIiBEjShx8YdbW1oSHh7Np0ybjskGDBhEbG8vmzZtvuI3UqMteRk4+X68+wrQNx8nTXRvkw1KroW4VF5oGetCsujvh1dxxLIPEnZOvY+bWRL5Zc8TYJWoNTwdee7QWj9XxRastXg1fp1e8N38vs2OTABjduQ7PNQu4zVZCCFFyZd7hyb59+4iIiADgt99+o06dOmzcuJG///6bV155pdQSta+vL6GhoUWW1a5dmz/++OOm29jY2GBjc62rxoyMjFKJRVzjbGvFsPa16R0ZyNpD59h67CJbjl3gVNpldiWmsSsxjW/XHsVCq6GOnzPNqnvQ9Eridr6Lhmh5BXrm7kjiy1VHSM4wjLHt727PkDZBdGpQGYtiJuirLLQaxnati62VBdM3HWf4gn3k5Ono80D1EscqhBClpUSJOj8/35gMV65cyRNPPAFASEgIZ86cKbXgIiMjiY+PL7Ls0KFDBARIbccceDvb0j28Kt3DqwKG55W3Jlxk67ELbEm4QNLFy+w+mc7uk+l8t+4YWg2E+bnQrLo7TQM9aBLofkddlhbo9CyIO80Xqw6RdNEw9rOviy2DWgfRrXGVUulFTaPR8EHHUOytLfhmzVHGLDnA5XwdAx+pafJ78EKI+1uJEnVYWBjffvstHTp0YMWKFYwebRgF6fTp03h4lN4zqa+99hotWrTgo48+onv37mzbto0pU6YwZcqUUjuGKD1V3e2p6m5vvMd7Ou0yWxMusOXoRbYmXOD4hUvsPZXO3lPpTF2fgEYDob5XatyB7kQEuuNqf+3xHb1esWjvGSauPMSxc4ZGbJUcbRjwcA2ejvDH1srihnGUlEaj4a12IdhbWzD+70NMWHGIy/k63ooKlmQthDCZEt2jXrNmDV26dCEjI4OYmBh+/PFHAN59910OHjzIvHnzSi3ARYsWMWzYMA4fPkxgYCBDhw69Zavv/5LHs8xHcnqOIXEfu8DWYxeNLciv0mggxMeZpoHu1PByZMaWExxMNvSc5WZvxSsP1uD55tWwsy7dBH0j368/xv8WHwCgV4tqjHg8tNj3voUQ4mbuyeNZOp2OjIyMIp2PHD9+HHt7e7y8zKcHGEnU5utsRg5bEy5eSdwXOHou+7oyTjaW9HmgOi9EVrvnHa38uuUE7y/YB8DTTaoypkvdEt8HF0KIwsq8Mdnly5dRShmT9IkTJ5g/fz61a9cmKiqqJLsU9yFvZ1ueqO/HE1eeXU7JzGFbwkW2HrvIgTMZNK3uTp9W1YtcDr+Xnm0WgK2VBW/9vpvZsUlcztfx2VP1za6jFyFExVaiRN2pUye6du3KK6+8QlpaGk2bNsXKyorz588zYcIE+vXrV9pxivuAl5Mtj9fz4/F65tPpSLfGVbC10jJkdhx/xp0mN1/PpJ4NsbaUZC2EuDdK9N9m586dtGpl6A/4999/x9vbmxMnTvDzzz8zadKkUg1QCFN7vJ4f3z7bGGsLLcv+TeblX7aTk3+HY9oKIcRdKlGivnTpEk5OTgD8/fffdO3aFa1WS7NmzThx4kSpBiiEOWgT6s0PvcKxtdKyOv4cvafHkp1rmkHkhRD3lxIl6po1a7JgwQKSkpJYvnw5bdu2BSAlJQVnZzMba1aIUtIqyJOfXojAwdqCTUcv8PyP28jIKc6wT0IIUXwlStQjRozgjTfeoFq1akRERNC8eXPAULtu2LBhqQYohDlpWt2DGX2a4WxryY4TqURP3Upqdp6pwxJCVGAlStTdunUjMTGR7du3s3z5cuPy1q1b8/nnn5dacEKYowZVXZnVtxnuDtbsPZVOz6lbOJeZe/sNhRCiBErcdNXHx4eGDRty+vRpTp48CUBERAQhISGlFpwQ5irMz4U5fZvh5WTDweRMekzZzJn0y6YOSwhRAZUoUev1ej788ENcXFwICAggICAAV1dXRo8ejV6vv/0OhKgAgryd+O3l5lR2tePYuWy6f7eZpIuXTB2WEKKCKdFz1O+99x4//PADH3/8MZGRkQBs2LCBkSNHkpOTw5gxY0o1SCHMVbVKDsx5uRnR32/lxIVLtJ6wlvZ1fOjRpCrNAj2k21EhxF0rUReifn5+fPvtt8ZRs676888/efXVVzl16lSpBXi3pAtRcS+kZOTwyq872JmYZlwW4GFP9/CqPNW4Cl7OtqYLTghhdsq8C9GLFy/e8F50SEgIFy9eLMkuhSjXvJxt+aNfC/adymB2bCJ/xp3mxIVLjFsez4QVh3g42Iunm1TloWBP6YJUCFEsJfqPUb9+fb766qvrln/11VfUq1fvroMSojzSaDTUreLCmC512fZea8Y/VZ8m1dzQ6RUrD5zlpZ+30+Ljfxi3/CAnLlw/AIkQQtxIiS59r127lg4dOuDv7298hnrz5s0kJSWxZMkSY/ei5kAufQtTO5KSxW/bk/hjx0kuFHrmukUND56O8KdtqHepj60thDBvxclNJapRP/jggxw6dIguXbqQlpZGWloaXbt25d9//+WXX34pUdBCVFQ1vRx597HabB7Wmm+iG/FALU80Gth09AKDZu2i2dhVjPrrX+KvjL0thBCFlXg86hvZvXs3jRo1QqcznwELpEYtzNHJ1EvM3X6SuduTOJ2eY1zeoKorTzepyuP1/XC0KVETEiFEOVDmjcmEEHenips9rz1ai0Gtg1h/+BxzYpNYsf8scUlpxCWl8eGi/XSs50ePiKo0rOqKRiOPeQlxv5JELYQJWWg1PBTsxUPBXpzPymXezpPMjk3i2Lls5mxPYs72JGp5O9KjiT89I6piby0fWSHuN/KciBBmopKjDX0fqMGqoQ8y95XmPNmoCrZWWg6dzWL0ov08/uUG9p1KN3WYQoh7rFhfz7t27XrL9WlpaXcTixACw2NeTaq506SaOx88EcrCuNN89c8Rjp3Lpus3m3irXTC9IwOl1zMh7hPFStQuLi63Xf/888/fVUBCiGucba14tlkAHer68vYfe/h7/1n+t/gA6w+fZ/xT9fF0sjF1iEKIMlaqrb7NkbT6FhWFUooZWxMZvWg/uQV6KjlaM/6p+jwU7GXq0IQQxVTmz1ELIe49jUbDs80C+GtgS0J8nDiflUevabFXErf5PBIphChdkqiFKGdqeTuxoH8kvVpUA+CHDQl0+XoTR1KyTBuYEKJMSKIWohyytbJg5BNh/BATjruDNfvPZNDxyw3M3pZIBb+bJcR9p1wl6o8//hiNRsOQIUNMHYoQZqF1bW+WDm5Fy5qVuJyv4515e+k/cyfpl/JNHZoQopSUm0QdGxvLd999J6NzCfEf3s62/Nw7gnfah2Cp1bBkbzLtv1hH7HEZclaIiqBcJOqsrCyio6OZOnUqbm5upg5HCLOj1Wp45cEa/NGvBdU87DmdnkOP7zbz+YpDFOj0pg5PCHEXykWi7t+/Px06dKBNmza3LZubm0tGRoZxysyUEYnE/aN+VVcWDWrFk42qoFfwxarDPD1lCydTL5k6NCFECZl9op49ezY7d+5k7Nixd1R+7NixuLi4GKfQ0NAyjlAI8+JoY8ln3evzxdMNcLKxZPuJVNp/sZ6/dp82dWhCiBIw60SdlJTE4MGDmTFjBra2tne0zbBhw0hPTzdO+/fvL+MohTBPnRpUZsngVjT0dyUzp4CBs3bx5tzdZOcWmDo0IUQxmHXPZAsWLKBLly5YWFgYl+l0OjQaDVqtltzc3CLrbkR6JhP3u3ydni9WHubrNUdQCqpXcmBSz4bUqXzrLoGFEGWnwvRM1rp1a/bu3UtcXJxxCg8PJzo6mri4uNsmaSEEWFloeSMqmFl9muHrYsux89l0+WYjU9cdQ6832+/pQogrzHpwWycnJ+rUqVNkmYODAx4eHtctF0LcWrPqHiwd3Iq3/9jD8n/PMmbJAdYdPse4bobBPbQaQzelQgjzYtaJWghRulztrfn22cbM3GYY3GP94fM0G7vKuF6jAQuNBq1Gg1YLWo0GC43GsFx7dbnmShnDY2FajQYLreY/22qw1GpoGuhO3weq4+V8Z21MhBDXK3eJes2aNaYOQYhyTaPREN00gIhq7rz2Wxz7TmUY1ykFBUoBCkphnI+9p9L5ecsJejapyisP1cDXxe7udyrEfabcJWohROkI8nbirwEtycgpQCmFTq/QKYVSoNMr9Eqh14NeGZbr9Qp94XVXttErrpS9Ws4wn3Y5n582HWfHiVR+2nyCWduSeCq8Cv0eqkEVN3tTv30hyg1J1ELcxzQaDS52VmW2/471fNl89AITVx1mW8JFZmxNZE5sEt0aV+HVh2ri7yEJW4jbkUQthCgzGo2GFjUr0aJmJbYcu8CX/xxm45ELzI5NYu6Ok3RpWJn+D9cksJKDqUMVwmxJohZC3BPNqnvQrLoH249fZNI/R1h36By/7zjJvJ0n6dTAkLBrejmaOkwhzI5ZP0cthKh4wqu583PvCBb0j6R1iBd6BfN3neLRz9cycNYuDp2V/vmFKEwStRDCJBpUdeWHXk34a0BL2oZ6oxT8tfs0bT9fR79fd7D/dMbtdyLEfUAStRDCpOpWcWHK8+EsGdSKx+r6ALB0XzKPTVpPn5+3s/dkuokjFMK0JFELIcxCqJ8z30Q3ZvmQB+hY3w+NBlbsP0vHrzbQe3osuxJTTR2iECYhiVoIYVaCfZz4smdDVrz2IF0bVkargX8OptDlm008/+M2dpy4aOoQhbinzHr0rNIgo2cJUb4lnM/mm9VHmLfrFLorg4g0r+5Buzo+tKjhQU0vR+mjXJQ7xclN8niWEMKsBVZyYNxT9Rn4SBCT1x7h9x0n2XzsApuPXQCgkqMNzaq706JGJZrX8KCah70kblGhSI1aCFGunEq7zIJdp9hy7AKxxy+Sk68vst7H2ZYWNTxoVsOD5tU9qOouvZ8J81Oc3CSJWghRbuUW6NidlM6mo+fZfPQCuxLTyNMVTdxV3e1oXt3DWOP2lpG8hBmQRF2IJGoh7h85+Tp2nEhl89ELbDp6nj0n0ynQF/0XV72SA81reNC8hqGntEqONiaKVtzP5B61EOK+ZGtlQWTNSkTWrAQEk5VbQOzxi2w5arinve9UOsfOZ3PsfDYztiYCEOztZEzazaq742pvbdo3IcR/SKIWQlRYjjaWPBzsxcPBXgCkX85nW8JF46Xyg8mZxJ81TNM3HUejgcb+bjzXPID2dXyxtpQnWIXpSaIWQtw3XOyseDTUm0dDvQG4kJXL1oSLxkvlR89ls/1EKttPpPI/pwM82zSAZ5r64+kkl8eF6cg9aiGEuOJM+mV+iz3Jr1tPcC4zFwBrCy0d6vnSq0U16ld1NW2AosKQxmSFSKIWQhRXXoGepfvOMH3TcXYlphmXN/R3pVeLanJZXNw1aUwmhBB3wdpSS6cGlenUoDJxSWn8tOk4i/acZldiGrsS4+SyuLinpEYthBB3ICUzh1lbk667LP54PV9i5LK4KCa59F2IJGohRGmSy+KiNMilbyGEKCO3uyw+xukAzzYLoGeEXBYXpUNq1EIIcZdSMnOYuTWRGVsTr7ss3iuyGvWquJo2QGF25NJ3IZKohRD3ytXL4tM2HicuKc24/Opl8UdCvHCytTJdgMJsVJhL32PHjmXevHkcPHgQOzs7WrRowSeffEJwcLCpQxNCiOvc7rI4QDUPe8Iqu1DHz4UwP2fC/JzxkP7GxS2YdY26Xbt2PP300zRp0oSCggLeffdd9u3bx/79+3FwcLijfUiNWghhSlcvi/++4yQnUy/fsIyviy1hfi7Uqexs/OnjbCvjaldgFfbS97lz5/Dy8mLt2rU88MADd7SNJGohhLm4kJXLv6cz+Pd0BvtOp/PvqXSOX7h0w7LuDtaE+TlTp7Kh5l3HzwV/d3u0WkneFUGFufT9X+np6QC4u7vftExubi65ubnG+czMzDKPSwgh7oSHow0P1PLkgVqexmWZOfnsL5K8MzhyLouL2XmsP3ye9YfPG8s62lgSeiVpX03iNTwdsLSQx8EqsnJTo9br9TzxxBOkpaWxYcOGm5YbOXIko0aNum651KiFEOVFTr6Og8mZ/Hs6nX2nMth/Op0DyZnkFeivK2tjqaVeFReimwbQoZ4vVpK0y4UKeem7X79+LF26lA0bNtzyTf23Rn3q1ClCQ0MlUQshyrV8nZ4jKVmGmvep9Cu18HSy83TGMj7OtvSKrEbPCH9c7KR1uTmrcIl6wIAB/Pnnn6xbt47AwMBibSv3qIUQFZVerzh+IZsle88wfdMJzmcZKikO1hZ0b1KV3pGBVHW3N3GU4kYqTKJWSjFw4EDmz5/PmjVrCAoKKvY+JFELIe4HuQU6Fsad5vv1CcSfNbTN0WqgXR0fXmpVnUb+biaOUBRWYRqT9e/fn5kzZ/Lnn3/i5OREcnIyAC4uLtjZ2Zk4OiGEMB82lhY8FV6Vbo2rsP7web7fkMC6Q+dYsjeZJXuTaeTvSp9W1Wkb5oOFtBwvV8y6Rn2zZwinTZtGr1697mgfUqMWQtyv4pMz+X79Mf6MO02eztAQraq7Hb0jA+keXhUHG7Ouq1VoFebSd2mQRC2EuN+lZObwy+YT/LrlBKmX8gFwtrXkmaYBxLQIwNdFrlDea5KoC5FELYQQBpfzdPyx8yQ/bkjg2PlsACy1GjrW9+PFloHUqexi4gjvHxXmHrUQQojSY2dtwbPNAngmwp9/DqYwdf0xtiZcZP6uU8zfdYrm1T3o80AgD9Xykh7QzIgkaiGEuM9otRrahHrTJtSbPSfT+GFDAov2nGHzsQtsPnaBGp4OvNiyOl0bVcbWysLU4d735NK3EEIITqddZvqm48zamkhmbgFg6G/8ifp+hFdzo3GAm9zLLkVyj7oQSdRCCHHnsnILmBObxI8bEjiVVnS0r8qudjQKcKOxvyvh1dwJ8XGSfsZLSO5RCyGEKBFHG0tebBlITPMAVh1MYdOR8+xITOXAmUxOpV3mVNpl/tp9GgA7KwsaVHUlvJobjQLcaFTVDRd76bq0tEmiFkIIcR1LCy1RYT5EhfkAkJ1bwO6kNHacSGX7iVR2JqaSmVNgvK99VS1vRxoHuNHI343wau5U87CXcbXvkiRqIYQQt+VgY0mLmpVoUbMSYOhn/Mi5LEPiPm5I3Annszl0NotDZ7OYtS0JMNznNiRtw33uupVdpIFaMUmiFkIIUWxarYZa3k7U8naiZ4Q/ABeyctlxIpUdiansPJHK7pPpXMzOY+WBs6w8cBYAKwsNdSq70NjfcLm8cYAb3s62pnwrZk8StRBCiFLh4WhD2zAf2l65XJ5boOPf0xnsvFLr3n4ilfNZuexKTGNXYhpsSACuNVJr5O9KI383Qv2cZVztQiRRCyGEKBM2lhY08jfcr36plWFExJOpl9l+4iI7TqSy80QaB5MzrmukZmulpV5l12vJO8CNSo42Jn43piOJWgghxD2h0Wio6m5PVXd7ujQ0PJKUlVvAniuN1HYmprIzMY30y/lsO36RbccvGrcN8LA3JP0ryTvY+/55NEwStRBCCJNxvEEjtWPns9mZmMquxFR2nEjlcEoWJy5c4sSFS8zfdQoAe2vDo2GG5O1Kw6puuDlYm/KtlBlJ1EIIIcyGVquhppcjNb0c6R5eFYCMnHziEq/VuuMS08jMLWDT0QtsOnrt0bDqng408je0LK/iZoefq2FytrUs14+ISaIWQghh1pxtrXiglicP1PIEQKdXHEnJYueVGvfOxFSOncs2Tr/vOFlke0cbS/xcbY2Ju7KrnWHexTDv42Jr1o3XJFELIYQoVyy0GoJ9nAj2ufZoWGp2HruSDA3U4s9mcib9MqfTcriYnUdWboHx+e4b0WrAy8kWP1dbKrvZG3662hkTeWVXO5ztTFcrl0QthBCi3HNzsOaREG8eCfEusvxyno7T6Zc5nWaYTqXlGF8bphzydHqSM3JIzshhZ2LaDffvYG2Bn6sdYX7OTHy64T14R9dIohZCCFFh2VlbUMPTkRqejjdcr9crLmTnFUrkhuR9Ou2yMcGfz8ojO0/H4ZQs7G3ufdqURC2EEOK+pdVq8HSywdPJhvpVXW9YJidfx5l0Q/I2xcVvSdRCCCHELdhaWRBYyYHASg4mOb75NnMTQgghhCRqIYQQwpxJohZCCCHMmCRqIYQQwoxJohZCCCHMWIVv9a3X6wE4c+aMiSMRQgghDK7mpKs56lYqfKI+e/YsABERESaORAghhCjq7Nmz+Pv737KMRiml7lE8JlFQUMCuXbvw9vZGq727K/2ZmZmEhoayf/9+nJycSinCik3OWfHJOSs+OWfFJ+es+ErznOn1es6ePUvDhg2xtLx1nbnCJ+rSlJGRgYuLC+np6Tg7O5s6nHJBzlnxyTkrPjlnxSfnrPhMdc6kMZkQQghhxiRRCyGEEGZMEnUx2NjY8MEHH2BjY2PqUMoNOWfFJ+es+OScFZ+cs+Iz1TmTe9RCCCGEGZMatRBCCGHGJFELIYQQZkwStRBCCGHGJFEXw9dff021atWwtbWladOmbNu2zdQhma2xY8fSpEkTnJyc8PLyonPnzsTHx5s6rHLj448/RqPRMGTIEFOHYtZOnTrFs88+i4eHB3Z2dtStW5ft27ebOiyzpdPpGD58OIGBgdjZ2VGjRg1Gjx6NNFUqat26dXTs2BE/Pz80Gg0LFiwosl4pxYgRI/D19cXOzo42bdpw+PDhMotHEvUdmjNnDkOHDuWDDz5g586d1K9fn6ioKFJSUkwdmllau3Yt/fv3Z8uWLaxYsYL8/Hzatm1Ldna2qUMze7GxsXz33XfUq1fP1KGYtdTUVCIjI7GysmLp0qXs37+fzz77DDc3N1OHZrY++eQTJk+ezFdffcWBAwf45JNP+PTTT/nyyy9NHZpZyc7Opn79+nz99dc3XP/pp58yadIkvv32W7Zu3YqDgwNRUVHk5OSUTUBK3JGIiAjVv39/47xOp1N+fn5q7NixJoyq/EhJSVGAWrt2ralDMWuZmZkqKChIrVixQj344INq8ODBpg7JbL399tuqZcuWpg6jXOnQoYPq3bt3kWVdu3ZV0dHRJorI/AFq/vz5xnm9Xq98fHzUuHHjjMvS0tKUjY2NmjVrVpnEIDXqO5CXl8eOHTto06aNcZlWq6VNmzZs3rzZhJGVH+np6QC4u7ubOBLz1r9/fzp06FDkb03c2MKFCwkPD+epp57Cy8uLhg0bMnXqVFOHZdZatGjBqlWrOHToEAC7d+9mw4YNtG/f3sSRlR8JCQkkJycX+Yy6uLjQtGnTMssHFX70rNJw/vx5dDod3t7eRZZ7e3tz8OBBE0VVfuj1eoYMGUJkZCR16tQxdThma/bs2ezcuZPY2FhTh1IuHDt2jMmTJzN06FDeffddYmNjGTRoENbW1sTExJg6PLP0zjvvkJGRQUhICBYWFuh0OsaMGUN0dLSpQys3kpOTAW6YD66uK22SqEWZ69+/P/v27WPDhg2mDsVsJSUlMXjwYFasWIGtra2pwykX9Ho94eHhfPTRRwA0bNiQffv28e2330qivonffvuNGTNmMHPmTMLCwoiLi2PIkCH4+fnJOTNjcun7DlSqVAkLCwvj2NZXnT17Fh8fHxNFVT4MGDCARYsWsXr1aqpUqWLqcMzWjh07SElJoVGjRlhaWmJpacnatWuZNGkSlpaW6HQ6U4dodnx9fQkNDS2yrHbt2iQmJpooIvP35ptv8s477/D0009Tt25dnnvuOV577TXGjh1r6tDKjav/8+9lPpBEfQesra1p3Lgxq1atMi7T6/WsWrWK5s2bmzAy86WUYsCAAcyfP59//vmHwMBAU4dk1lq3bs3evXuJi4szTuHh4URHRxMXF4eFhYWpQzQ7kZGR1z3yd+jQIQICAkwUkfm7dOkSWm3Rf/sWFhbo9XoTRVT+BAYG4uPjUyQfZGRksHXr1jLLB3Lp+w4NHTqUmJgYwsPDiYiIYOLEiWRnZ/PCCy+YOjSz1L9/f2bOnMmff/6Jk5OT8d6Ni4sLdnZ2Jo7O/Dg5OV13/97BwQEPDw+5r38Tr732Gi1atOCjjz6ie/fubNu2jSlTpjBlyhRTh2a2OnbsyJgxY/D39ycsLIxdu3YxYcIEevfuberQzEpWVhZHjhwxzickJBAXF4e7uzv+/v4MGTKE//3vfwQFBREYGMjw4cPx8/Ojc+fOZRNQmbQlr6C+/PJL5e/vr6ytrVVERITasmWLqUMyW8ANp2nTppk6tHJDHs+6vb/++kvVqVNH2djYqJCQEDVlyhRTh2TWMjIy1ODBg5W/v7+ytbVV1atXV++9957Kzc01dWhmZfXq1Tf8/xUTE6OUMjyiNXz4cOXt7a1sbGxU69atVXx8fJnFI6NnCSGEEGZM7lELIYQQZkwStRBCCGHGJFELIYQQZkwStRBCCGHGJFELIYQQZkwStRBCCGHGJFELIYQQZkwStRBCCGHGJFELIUqdRqNhwYIFpg5DiApBErUQFUyvXr3QaDTXTe3atTN1aEKIEpBBOYSogNq1a8e0adOKLLOxsTFRNEKIuyE1aiEqIBsbG3x8fIpMbm5ugOGy9OTJk2nfvj12dnZUr16d33//vcj2e/fu5ZFHHsHOzg4PDw/69u1LVlZWkTI//vgjYWFh2NjY4Ovry4ABA4qsP3/+PF26dMHe3p6goCAWLlxoXJeamkp0dDSenp7Y2dkRFBR03RcLIYSBJGoh7kPDhw/nySefZPfu3URHR/P0009z4MABALKzs4mKisLNzY3Y2Fjmzp3LypUriyTiyZMn079/f/r27cvevXtZuHAhNWvWLHKMUaNG0b17d/bs2cNjjz1GdHQ0Fy9eNB5///79LF26lAMHDjB58mQqVap0706AEOVJmY3LJYQwiZiYGGVhYaEcHByKTGPGjFFKGYYgfeWVV4ps07RpU9WvXz+llFJTpkxRbm5uKisry7h+8eLFSqvVquTkZKWUUn5+fuq99967aQyAev/9943zWVlZClBLly5VSinVsWNH9cILL5TOGxaigpN71EJUQA8//DCTJ08usszd3d34unnz5kXWNW/enLi4OAAOHDhA/fr1cXBwMK6PjIxEr9cTHx+PRqPh9OnTtG7d+pYx1KtXz/jawcEBZ2dnUlJSAOjXrx9PPvkkO3fupG3btnTu3JkWLVqU6L0KUdFJohaiAnJwcLjuUnRpsbOzu6NyVlZWReY1Gg16vR6A9u3bc+LECZYsWcKKFSto3bo1/fv3Z/z48aUerxDlndyjFuI+tGXLluvma9euDUDt2rXZvXs32dnZxvUbN25Eq9USHByMk5MT1apVY9WqVXcVg6enJzExMfz6669MnDiRKVOm3NX+hKiopEYtRAWUm5tLcnJykWWWlpbGBltz584lPDycli1bMmPGDLZt28YPP/wAQHR0NB988AExMTGMHDmSc+fOMXDgQJ577jm8vb0BGDlyJK+88gpeXl60b9+ezMxMNm7cyMCBA+8ovhEjRtC4cWPCwsLIzc1l0aJFxi8KQoiiJFELUQEtW7YMX1/fIsuCg4M5ePAgYGiRPXv2bF599VV8fX2ZNWsWoaGhANjb27N8+XIGDx5MkyZNsLe358knn2TChAnGfcXExJCTk8Pnn3/OG2+8QaVKlejWrdsdx2dtbc2wYcM4fvw4dnZ2tGrVitmzZ5fCOxei4tEopZSpgxBC3DsajYb58+fTuXNnU4cihLgDco9aCCGEMGOSqIUQQggzJveohbjPyN0uIcoXqVELIYQQZkwStRBCCGHGJFELIYQQZkwStRBCCGHGJFELIYQQZkwStRBCCGHGJFELIYQQZkwStRBCCGHGJFELIYQQZuz/8daQ9NaewBAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generation Strategies"
      ],
      "metadata": {
        "id": "iweExsNKsIVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(\"cpu\")\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmmDgx-On1xk",
        "outputId": "a8510a47-e8c5-4703-80e5-5957b9620304"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "token_ids = generate_text_simple(\n",
        " model=model,\n",
        " idx=text_to_token_ids(\"Every effort moves you,\", tokenizer),\n",
        " max_new_tokens=25,\n",
        " context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2r1astlsN5G",
        "outputId": "eb86bff8-3b3c-45e1-b28a-f74e603015f0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you, through\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Temperature scaling** - It is just dividing logits by a numer greater than 0"
      ],
      "metadata": {
        "id": "zWKH4l2_uecJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding a probabilistic selection\n",
        "process to the next-token generation task"
      ],
      "metadata": {
        "id": "LSMH8W2avkQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {\n",
        " \"closer\": 0,\n",
        " \"every\": 1,\n",
        " \"effort\": 2,\n",
        " \"forward\": 3,\n",
        " \"inches\": 4,\n",
        " \"moves\": 5,\n",
        " \"pizza\": 6,\n",
        " \"toward\": 7,\n",
        " \"you\": 8,\n",
        "}\n",
        "inverse_vocab = {v: k for k, v in vocab.items()}"
      ],
      "metadata": {
        "id": "Iex2yw3kvn8G"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "assume the LLM is given the start context \"every effort moves you\" and gener\u0002ates the following next-token logits"
      ],
      "metadata": {
        "id": "SkKu0tXbv2rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next_token_logits = torch.tensor(\n",
        " [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
        ")"
      ],
      "metadata": {
        "id": "eTAmgV5UvuXK"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we convert the logits into\n",
        "probabilities via the softmax function and obtain the token ID corresponding to the\n",
        "generated token"
      ],
      "metadata": {
        "id": "MtWxIMjYwJYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probas = torch.softmax(next_token_logits, dim=0)\n",
        "next_token_id = torch.argmax(probas).item()\n",
        "print(inverse_vocab[next_token_id])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxRUq7Rwv6Ei",
        "outputId": "5e459b72-f333-4d9f-e1b0-9489cfd9483a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To implement a probabilistic sampling process, we can now replace argmax with\n",
        "the multinomial function"
      ],
      "metadata": {
        "id": "wsmQRePiwT96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
        "print(inverse_vocab[next_token_id])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R58S0XtwV8F",
        "outputId": "dfcc5465-c4a7-476f-8919-e2d7ad7519b0"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toward\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The multinomial\n",
        "function samples the next token proportional to its probability score"
      ],
      "metadata": {
        "id": "B2xAaf6XwiGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_with_temperature(logits, temperature):\n",
        " scaled_logits = logits / temperature\n",
        " return torch.softmax(scaled_logits, dim=0)"
      ],
      "metadata": {
        "id": "t6vW3pMTsc8l"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the original probabilities alongside proba\u0002bilities scaled with different temperature values"
      ],
      "metadata": {
        "id": "v1IUL7Mbw841"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temperatures = [1, 0.1, 5] # original,lower and higher confidence\n",
        "scaled_probas = [softmax_with_temperature(next_token_logits, T)\n",
        " for T in temperatures]\n",
        "x = torch.arange(len(vocab))\n",
        "bar_width = 0.15\n",
        "fig, ax = plt.subplots(figsize=(5, 3))\n",
        "for i, T in enumerate(temperatures):\n",
        " rects = ax.bar(x + i * bar_width, scaled_probas[i],\n",
        "  bar_width, label=f'Temperature = {T}')\n",
        "ax.set_ylabel('Probability')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "4HcY1emiuwZV",
        "outputId": "198e67d6-b651-40b6-9111-716a431aa428"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Top-k sampling**"
      ],
      "metadata": {
        "id": "aVPPmiyYzFkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can restrict the\n",
        "sampled tokens to the top-k most likely tokens and exclude all other tokens from the\n",
        "selection process by masking their probability scores,"
      ],
      "metadata": {
        "id": "envEaPq2zRBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_k = 3 # selection of the tokens with the largest logit values\n",
        "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
        "print(\"Top logits:\", top_logits)\n",
        "print(\"Top positions:\", top_pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kaNXaTHwz3K",
        "outputId": "4c4da6d1-0668-47e6-a835-0e49d751f7e3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
            "Top positions: tensor([3, 7, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "set the logit values of tokens that are\n",
        "below the lowest logit value within our top-three selection to negative infinity using where function"
      ],
      "metadata": {
        "id": "83b0COLsz2zJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_logits = torch.where(\n",
        " condition=next_token_logits < top_logits[-1], #identifies logits less than the minimum in top 3\n",
        " input=torch.tensor(float('-inf')), #assigns -inf to the lower logits\n",
        " other=next_token_logits #retains original logits for other tokens\n",
        ")\n",
        "print(new_logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0DjVp3izoAw",
        "outputId": "a9ca353f-0873-4947-adb2-c00af0d8e39d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topk_probas = torch.softmax(new_logits, dim=0)\n",
        "print(\"Probabilities: \",topk_probas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii_O7Nju0aJp",
        "outputId": "f4df94ea-848e-48e3-f1b3-9c503a2e3e0d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probabilities:  tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modifying text generation function** - Combining top-k and temperature scaling to text generation\n"
      ],
      "metadata": {
        "id": "kNPc6bQXEXxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, idx, max_new_tokens, context_size,\n",
        "             temperature=0.0, top_k=None, eos_id=None):\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        if top_k is not None:\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(\n",
        "                logits < min_val,\n",
        "                torch.tensor(float('-inf')).to(logits.device),\n",
        "                logits\n",
        "            )\n",
        "\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "            if idx_next == eos_id:\n",
        "                break\n",
        "\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # Append the new token\n",
        "\n",
        "    return idx  # Function returns after completing the loop"
      ],
      "metadata": {
        "id": "jPB-kbzC0fw9"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "token_ids = generate(\n",
        " model=model,\n",
        " idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        " max_new_tokens=45,\n",
        " context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        " top_k=20,\n",
        " temperature=1.3\n",
        ")\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WsUt8XkHQQV",
        "outputId": "68c4ecf7-7658-4f74-fca6-9c796bec79a6"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you know Jack Gisburn said a little it was such a good fellow enough--so it was no great surprise to Jack's resolve had gone a smile behind back the honour being _ up had again run over from Monte Carlo;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weight saving & Loading"
      ],
      "metadata": {
        "id": "I2MMiIqGMq_4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving both the model and optimizer *state_dict* contents."
      ],
      "metadata": {
        "id": "3sckPg65OqPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        " \"model_state_dict\": model.state_dict(),\n",
        " \"optimizer_state_dict\": optimizer.state_dict(),\n",
        " },\n",
        " \"model_and_optimizer.pth\"\n",
        ")"
      ],
      "metadata": {
        "id": "YOflSUOTHSLu"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*state_dict()* - a dictionary mapping each layer to its parameters.\n",
        "*model.pth* - the filename where the state_dict is saved, the .pth extension is a\n",
        "convention for PyTorch files,"
      ],
      "metadata": {
        "id": "sf4r2lRUNHd5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting to drive so that I can import the model for finetuning"
      ],
      "metadata": {
        "id": "ndokJTUiliyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the saved model and optimizer states to GPTModel instance**"
      ],
      "metadata": {
        "id": "PqsQc6N1Nopt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "model.train();"
      ],
      "metadata": {
        "id": "3GY38r54NR6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e03d0f47-8703-4276-cd3f-2162f91b3f56"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-63-2e32dcdb1060>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading pretrained weights from OpenAI"
      ],
      "metadata": {
        "id": "82MRvvyNQGyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow>=2.15.0 tqdm>=4.66"
      ],
      "metadata": {
        "id": "AKH_3xFaNypZ"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "url = (\n",
        " \"https://raw.githubusercontent.com/rasbt/\"\n",
        " \"LLMs-from-scratch/main/ch05/\"\n",
        " \"01_main-chapter-code/gpt_download.py\"\n",
        ")\n",
        "filename = url.split('/')[-1]\n",
        "urllib.request.urlretrieve(url, filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1hVVvCuQu7E",
        "outputId": "8d841617-53a5-43bd-8f07-e3786ffe1a5e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('gpt_download.py', <http.client.HTTPMessage at 0x7b257819c050>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "settings, params = download_and_load_gpt2(\n",
        " model_size=\"124M\", models_dir=\"gpt2\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdnAoq_OQzl0",
        "outputId": "8db12e74-3134-46ed-c2b5-7a75ce67f8c1"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
            "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "inspect the contents\n",
        "of settings and params"
      ],
      "metadata": {
        "id": "jJpm2ROHR-_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Settings:\", settings)\n",
        "print(\"Parameter dictionary keys:\", params.keys())"
      ],
      "metadata": {
        "id": "kNo9OHBmRFF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "400a25a5-ebca-4dba-e449-6ac668b4c1e2"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
            "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The weights of the token embedding layer"
      ],
      "metadata": {
        "id": "tm9OK8cKSfb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(params[\"wte\"])\n",
        "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
      ],
      "metadata": {
        "id": "endypKrUSCSs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f43d248d-a2ce-4cdd-8264-f6afeaaf0761"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
            "   0.04531523]\n",
            " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
            "   0.04318958]\n",
            " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
            "  -0.08785918]\n",
            " ...\n",
            " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
            "  -0.06952604]\n",
            " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
            "  -0.02245961]\n",
            " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
            "   0.12067825]]\n",
            "Token embedding weight tensor dimensions: (50257, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_configs = {\n",
        " \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        " \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        " \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        " \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}"
      ],
      "metadata": {
        "id": "a_DXnEYFSabe"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt2-small (124M)\"\n",
        "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
        "NEW_CONFIG.update(model_configs[model_name])"
      ],
      "metadata": {
        "id": "-WpRj2g-S630"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NEW_CONFIG.update({\"context_length\": 1024})"
      ],
      "metadata": {
        "id": "hSDdJcGaTEQ-"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NEW_CONFIG.update({\"qkv_bias\": True})"
      ],
      "metadata": {
        "id": "SBvdfSPOTHQV"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt = GPTModel(NEW_CONFIG)\n",
        "gpt.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8qAdB7CTPE6",
        "outputId": "45b3b3f9-6213-443e-fd8b-130e6a12315b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "assign utility function that checks whether two tensors or arrays (left and\n",
        "right) have the same dimensions or shape and returns the right tensor as trainable\n",
        "PyTorch parameters"
      ],
      "metadata": {
        "id": "nat1RG1kT2U2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assign(left, right):\n",
        " if left.shape != right.shape:\n",
        "  raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
        "  \"Right: {right.shape}\"\n",
        "  )\n",
        " return torch.nn.Parameter(torch.tensor(right))"
      ],
      "metadata": {
        "id": "_ZQSPemnTSxO"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading OpenAI weights into GPT model code**"
      ],
      "metadata": {
        "id": "oR3epLhuVUKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "  gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "  gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "  for b in range(len(params[\"blocks\"])):\n",
        "    q_w, k_w, v_w = np.split(\n",
        "      (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "    gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "      gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "    gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "      gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "    gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "      gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "    q_b, k_b, v_b = np.split(\n",
        "      (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "    gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "      gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "    gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "      gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "    gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "      gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "    gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "      gpt.trf_blocks[b].att.out_proj.weight,\n",
        "      params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "      gpt.trf_blocks[b].att.out_proj.bias,\n",
        "      params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "    gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "      gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "      params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "      gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "      params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "\n",
        "    gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "      gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "      params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "      gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "      params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "    gpt.trf_blocks[b].norm1.scale = assign(\n",
        "      gpt.trf_blocks[b].norm1.scale,\n",
        "      params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "    gpt.trf_blocks[b].norm1.shift = assign(\n",
        "      gpt.trf_blocks[b].norm1.shift,\n",
        "      params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "\n",
        "  gpt.trf_blocks[b].norm2.scale = assign(\n",
        "    gpt.trf_blocks[b].norm2.scale,\n",
        "    params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "  gpt.trf_blocks[b].norm2.shift = assign(\n",
        "    gpt.trf_blocks[b].norm2.shift,\n",
        "    params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "  gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "  gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "  gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
      ],
      "metadata": {
        "id": "AJeqFhEnTu8A"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_weights_into_gpt(gpt, params)\n",
        "gpt.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRCKgudoVgFS",
        "outputId": "ea909e77-55af-4f49-c4e2-9c2aacfef78d"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "token_ids = generate(\n",
        " model=gpt,\n",
        " idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
        " max_new_tokens=30,\n",
        " context_size=NEW_CONFIG[\"context_length\"],\n",
        " top_k=50,\n",
        " temperature=1.4\n",
        ")\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "Iw3MD8-OV00l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86ebd091-c2cc-473e-edaa-7be985c2d502"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you as as the A the the many the ( the that. - of. a\n",
            " an it at more you ( a I you the one a of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-U16ue54V6hF"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning"
      ],
      "metadata": {
        "id": "KnXoF5M9tcy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "def download_and_unzip_spam_data(\n",
        " url, zip_path, extracted_path, data_file_path):\n",
        " if data_file_path.exists():\n",
        "  print(f\"{data_file_path} already exists. Skipping download \"\n",
        "  \"and extraction.\"\n",
        "  )\n",
        "  return\n",
        "\n",
        "with urllib.request.urlopen(url) as response: #Download File\n",
        " with open(zip_path, \"wb\") as out_file:\n",
        "  out_file.write(response.read())\n",
        "\n",
        " with zipfile.ZipFile(zip_path, \"r\") as zip_ref: # Unzips the file\n",
        "  zip_ref.extractall(extracted_path)\n",
        "\n",
        " original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        " os.rename(original_file_path, data_file_path)  #Adds a .tsv extension\n",
        " print(f\"File downloaded and saved as {data_file_path}\")\n",
        "\n",
        "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETM4f4vNtgtz",
        "outputId": "d30622d4-44e0-4428-a1d0-9e8ae4973031"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\n",
            "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\n",
        " data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"]\n",
        ")\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VtvxwECtonU",
        "outputId": "77402905-e1bf-4ff4-e158-3f35ea05517f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Label                                               Text\n",
            "0      ham  Go until jurong point, crazy.. Available only ...\n",
            "1      ham                      Ok lar... Joking wif u oni...\n",
            "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3      ham  U dun say so early hor... U c already then say...\n",
            "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
            "...    ...                                                ...\n",
            "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
            "5568   ham               Will  b going to esplanade fr home?\n",
            "5569   ham  Pity, * was in mood for that. So...any other s...\n",
            "5570   ham  The guy did some bitching but I acted like i'd...\n",
            "5571   ham                         Rofl. Its true to its name\n",
            "\n",
            "[5572 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eifj-rpHtsZN",
        "outputId": "666bacec-f366-4d2c-f9bd-6c25f1d7ed62"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_balanced_dataset(df):\n",
        " num_spam = df[df[\"Label\"] == \"spam\"].shape[0] # Counts spam instances\n",
        " ham_subset = df[df[\"Label\"] == \"ham\"].sample(\n",
        " num_spam, random_state=123\n",
        " )\n",
        "\n",
        " balanced_df = pd.concat([\n",
        " ham_subset, df[df[\"Label\"] == \"spam\"]\n",
        " ])\n",
        " return balanced_df\n",
        "\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "print(balanced_df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb17TojltwJo",
        "outputId": "4713c508-bda4-4ba5-c4fe-02e88860f332"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     747\n",
            "spam    747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
      ],
      "metadata": {
        "id": "9uz9FKuotylC"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_split(df, train_frac, validation_frac):\n",
        "\n",
        " df = df.sample(\n",
        " frac=1, random_state=123\n",
        " ).reset_index(drop=True) #Shuffles the entire dataframe\n",
        " train_end = int(len(df) * train_frac) #Calculate split indices\n",
        " validation_end = train_end + int(len(df) * validation_frac)\n",
        "\n",
        " #Split dataframe\n",
        " train_df = df[:train_end]\n",
        " validation_df = df[train_end:validation_end]\n",
        " test_df = df[validation_end:]\n",
        " return train_df, validation_df, test_df\n",
        "\n",
        "train_df, validation_df, test_df = random_split(\n",
        " balanced_df, 0.7, 0.1)"
      ],
      "metadata": {
        "id": "1YQp93Vxt1wx"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ],
      "metadata": {
        "id": "aBN8E4uqt5B4"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGwgKsUjt7e2",
        "outputId": "5766ae31-0304-4037-801b-5d0acc2da35f"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Smm3dGhtuBFO",
        "outputId": "0d3d3e34-d4ba-4556-95dc-3bcf30e20017"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "gxAz7cD-uESY"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpamDataset(Dataset):\n",
        " def __init__(self, csv_file, tokenizer, max_length=None,\n",
        " pad_token_id=50256):\n",
        "  self.data = pd.read_csv(csv_file)\n",
        "\n",
        " #Pretokenizes text\n",
        "  self.encoded_texts = [\n",
        "  tokenizer.encode(text) for text in self.data[\"Text\"]\n",
        "  ]\n",
        "\n",
        "  if max_length is None:\n",
        "    self.max_length = self._longest_encoded_length()\n",
        "  else:\n",
        "    self.max_length = max_length\n",
        "\n",
        "  #Truncates sequences if they are longer than max length\n",
        "  self.encoded_texts = [\n",
        "  encoded_text[:self.max_length]\n",
        "  for encoded_text in self.encoded_texts\n",
        "  ]\n",
        "\n",
        "  self.encoded_texts = [\n",
        "    encoded_text + [pad_token_id] *\n",
        "    (self.max_length - len(encoded_text))\n",
        "    for encoded_text in self.encoded_texts\n",
        "    ]\n",
        "\n",
        " def __getitem__(self, index):\n",
        "  encoded = self.encoded_texts[index]\n",
        "  label = self.data.iloc[index][\"Label\"]\n",
        "  return (\n",
        "    torch.tensor(encoded, dtype=torch.long),\n",
        "    torch.tensor(label, dtype=torch.long)\n",
        "    )\n",
        "\n",
        " def __len__(self):\n",
        "  return len(self.data)\n",
        "\n",
        " def _longest_encoded_length(self):\n",
        "  max_length = 0\n",
        "  for encoded_text in self.encoded_texts:\n",
        "    encoded_length = len(encoded_text)\n",
        "    if encoded_length > max_length:\n",
        "      max_length = encoded_length\n",
        "  return max_length"
      ],
      "metadata": {
        "id": "yCN9qIzwuG3s"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SpamDataset(\n",
        " csv_file=\"train.csv\",\n",
        " max_length=None,\n",
        " tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "_RFZBDxbuLPR"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset.max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp9UQ_-xuN2g",
        "outputId": "5e144d3a-9b9a-4f62-a5ec-00d2783e8516"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = SpamDataset(\n",
        " csv_file=\"validation.csv\",\n",
        " max_length=train_dataset.max_length,\n",
        " tokenizer=tokenizer\n",
        ")\n",
        "test_dataset = SpamDataset(\n",
        " csv_file=\"test.csv\",\n",
        " max_length=train_dataset.max_length,\n",
        " tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "dZbpuTSCuQNW"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "torch.manual_seed(123)\n",
        "train_loader = DataLoader(\n",
        " dataset=train_dataset,\n",
        " batch_size=batch_size,\n",
        " shuffle=True,\n",
        " num_workers=num_workers,\n",
        " drop_last=True,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        " dataset=val_dataset,\n",
        " batch_size=batch_size,\n",
        " num_workers=num_workers,\n",
        " drop_last=False,\n",
        ")\n",
        "test_loader = DataLoader(\n",
        " dataset=test_dataset,\n",
        " batch_size=batch_size,\n",
        " num_workers=num_workers,\n",
        " drop_last=False,\n",
        ")"
      ],
      "metadata": {
        "id": "xLlZ1b16uS9d"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_batch, target_batch in train_loader:\n",
        " pass\n",
        "print(\"Input batch dimensions:\", input_batch.shape)\n",
        "print(\"Label batch dimensions\", target_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2a1IEoiuWcB",
        "outputId": "d20a87a8-48e4-4ae9-8da6-02559fcca27b"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch dimensions: torch.Size([8, 120])\n",
            "Label batch dimensions torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EExQZHwfuZrg",
        "outputId": "cfb1364b-fd12-4a4f-c814-0ddf042104f0"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 training batches\n",
            "19 validation batches\n",
            "38 test batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initializing pretrained weights**"
      ],
      "metadata": {
        "id": "VnHvGROqudCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "INPUT_PROMPT = \"Every effort moves\""
      ],
      "metadata": {
        "id": "uO4gNz7HucZQ"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_CONFIG = {\n",
        " \"vocab_size\": 50257,\n",
        " \"context_length\": 1024,\n",
        " \"drop_rate\": 0.0,\n",
        " \"qkv_bias\": True\n",
        "}\n",
        "model_configs = {\n",
        " \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        " \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        " \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        " \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
      ],
      "metadata": {
        "id": "GB0iNB-wulgV"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(\n",
        " model_size=model_size, models_dir=\"gpt2\"\n",
        ")\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_fc3t_7uonS",
        "outputId": "4648ac24-2f73-4767-a4bd-3369b4902828"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
            "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = \"Every effort moves you\"\n",
        "token_ids = generate_text_simple(\n",
        " model=model,\n",
        " idx=text_to_token_ids(text_1, tokenizer),\n",
        " max_new_tokens=25,\n",
        " context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jErPIIlYu1xM",
        "outputId": "aa7e6876-7792-45d7-a637-f1f032996476"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every effort moves you the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = (\n",
        " \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
        " \" 'You are a winner you have been specially\"\n",
        " \" selected to receive $1000 cash or a $2000 award.'\"\n",
        ")\n",
        "token_ids = generate_text_simple(\n",
        " model=model,\n",
        " idx=text_to_token_ids(text_2, tokenizer),\n",
        " max_new_tokens=23,\n",
        " context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2JhYcvnxy8P",
        "outputId": "615fae21-2890-4ea7-f3ab-23519f39ec9e"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.' the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding classification head**"
      ],
      "metadata": {
        "id": "FqvJf2soyecP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Architecture"
      ],
      "metadata": {
        "id": "CGFyvtkozLAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng-yWcEzyUp5",
        "outputId": "2dc3f794-cbc6-421d-ce67-ca0044b91ce6"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freeze the model"
      ],
      "metadata": {
        "id": "NXkyrho1z-qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        " param.requires_grad = False"
      ],
      "metadata": {
        "id": "9E3D7h59zRM5"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding a classification layer**"
      ],
      "metadata": {
        "id": "yl3G85nEpSrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "num_classes = 2\n",
        "model.out_head = torch.nn.Linear(\n",
        " in_features=BASE_CONFIG[\"emb_dim\"],\n",
        " out_features=num_classes\n",
        ")"
      ],
      "metadata": {
        "id": "ng1MYNOs0DCN"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "make the final LayerNorm and last transformer block trainable"
      ],
      "metadata": {
        "id": "faDWDOj8qaXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.trf_blocks[-1].parameters():\n",
        " param.requires_grad = True\n",
        "for param in model.final_norm.parameters():\n",
        " param.requires_grad = True"
      ],
      "metadata": {
        "id": "CTodtCLap5Rr"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer.encode(\"Do you have time\")\n",
        "inputs = torch.tensor(inputs).unsqueeze(0)\n",
        "print(\"Inputs:\", inputs)\n",
        "print(\"Inputs dimensions:\", inputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fv8Gvcrq3pW",
        "outputId": "d2c25bb2-e490-45d3-e2f7-928c57222412"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs: tensor([[5211,  345,  423,  640]])\n",
            "Inputs dimensions: torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ayBg9DMXrE3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pass the encoded token IDs to the model"
      ],
      "metadata": {
        "id": "AdoSK_BJrHvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        " outputs = model(inputs)\n",
        "print(\"Outputs:\\n\", outputs)\n",
        "print(\"Outputs dimensions:\", outputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E43L59pprGtN",
        "outputId": "8b9b989d-8c1d-4766-e570-16c60cc34515"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs:\n",
            " tensor([[[0.3708, 1.2060],\n",
            "         [0.2238, 1.4616],\n",
            "         [0.2839, 1.4423],\n",
            "         [0.2767, 1.3516]]])\n",
            "Outputs dimensions: torch.Size([1, 4, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Last output token:\", outputs[:, -1, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FALaR0sCriVl",
        "outputId": "631fb598-f6ef-4bbd-f50e-49757f47d708"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last output token: tensor([[0.2767, 1.3516]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "last token in a sequence accu\u0002mulates the most information since it is the only token with access to data from all the\n",
        "previous tokens. Therefore, in our spam classification task, we focus on this last token\n",
        "during the fine-tuning process."
      ],
      "metadata": {
        "id": "ge4wzNtTsjG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "83NxYq1pq3Bk"
      }
    }
  ]
}