{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/wo2tvhDcN1Lh57VKvMtp"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XLRV1dLWG1uE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention_v1(nn.Module):\n",
        "    def __init__(self, d_in, d_out):\n",
        "        super().__init__()\n",
        "        self.W_query = nn.Parameter(torch.randn(d_in, d_out))\n",
        "        self.W_key = nn.Parameter(torch.randn(d_in, d_out))\n",
        "        self.W_value = nn.Parameter(torch.randn(d_in, d_out))\n",
        "\n",
        "    def forward(self, x):\n",
        "        queries = x @ self.W_query\n",
        "        keys = x @ self.W_key\n",
        "        values = x @ self.W_value\n",
        "        attn_scores = queries @ keys.T\n",
        "        attn_weights = torch.softmax(\n",
        "            attn_scores / keys.shape[-1] ** 0.5, dim=-1)\n",
        "        context_vec = attn_weights @ values\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "raN90EABHB5W"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {\"Your\": 0, \"journey\": 1, \"starts\": 2, \"with\": 3, \"one\": 4, \"step\": 5}\n",
        "embedding_dim = 3\n",
        "tokenized_input = [\"Your\", \"journey\", \"starts\", \"with\", \"one\", \"step\"]"
      ],
      "metadata": {
        "id": "hHHjghPZQxel"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random embeddings\n",
        "torch.manual_seed(123)\n",
        "embeddings = torch.randn(len(vocab), embedding_dim)"
      ],
      "metadata": {
        "id": "-08nfrceQ3bS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert tokens to embeddings\n",
        "inputs = torch.stack([embeddings[vocab[word]] for word in tokenized_input])"
      ],
      "metadata": {
        "id": "2lRJP2RrQ9o2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and apply self-attention\n",
        "sa_v1 = SelfAttention_v1(d_in=3,d_out=2)\n",
        "print(sa_v1(inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi7z6EuHKNJK",
        "outputId": "925c1685-aafc-494e-ae46-fcce08a7998a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3322,  1.5411],\n",
            "        [ 0.9328,  3.1144],\n",
            "        [ 0.9211,  3.0893],\n",
            "        [-0.8639, -4.1216],\n",
            "        [-1.0136, -5.0366],\n",
            "        [-1.0167, -5.0538]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "md20Ms_QKkQe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}